# TradingAgents Documentation Combined

<!-- docs/README.md -->

# TradingAgents æ–‡æ¡£ (v0.1.4)

æ¬¢è¿æ¥åˆ° TradingAgents å¤šæ™ºèƒ½ä½“é‡‘èäº¤æ˜“æ¡†æ¶çš„æ–‡æ¡£ä¸­å¿ƒã€‚æœ¬æ–‡æ¡£é€‚ç”¨äºä¸­æ–‡å¢å¼ºç‰ˆ v0.1.4ï¼ŒåŒ…å«å®Œæ•´çš„Aè‚¡æ”¯æŒã€å›½äº§LLMé›†æˆå’ŒWebç•Œé¢åŠŸèƒ½ã€‚

## æ–‡æ¡£ç»“æ„

### ğŸ“‹ æ¦‚è§ˆæ–‡æ¡£
- [é¡¹ç›®æ¦‚è¿°](./overview/project-overview.md) - é¡¹ç›®çš„åŸºæœ¬ä»‹ç»å’Œç›®æ ‡
- [å¿«é€Ÿå¼€å§‹](./overview/quick-start.md) - å¿«é€Ÿä¸Šæ‰‹æŒ‡å—
- [å®‰è£…æŒ‡å—](./overview/installation.md) - è¯¦ç»†çš„å®‰è£…è¯´æ˜

### ğŸ—ï¸ æ¶æ„æ–‡æ¡£
- [ç³»ç»Ÿæ¶æ„](./architecture/system-architecture.md) - æ•´ä½“ç³»ç»Ÿæ¶æ„è®¾è®¡
- [æ™ºèƒ½ä½“æ¶æ„](./architecture/agent-architecture.md) - æ™ºèƒ½ä½“è®¾è®¡æ¨¡å¼
- [æ•°æ®æµæ¶æ„](./architecture/data-flow-architecture.md) - æ•°æ®å¤„ç†æµç¨‹
- [å›¾ç»“æ„è®¾è®¡](./architecture/graph-structure.md) - LangGraph å›¾ç»“æ„è®¾è®¡
- [é…ç½®ä¼˜åŒ–æŒ‡å—](./architecture/configuration-optimization.md) - v0.1.4æ¶æ„ä¼˜åŒ–è¯¦è§£ âœ¨

### ğŸ¤– æ™ºèƒ½ä½“æ–‡æ¡£
- [åˆ†æå¸ˆå›¢é˜Ÿ](./agents/analysts.md) - å„ç±»åˆ†æå¸ˆæ™ºèƒ½ä½“è¯¦è§£
- [ç ”ç©¶å‘˜å›¢é˜Ÿ](./agents/researchers.md) - ç ”ç©¶å‘˜æ™ºèƒ½ä½“è®¾è®¡
- [äº¤æ˜“å‘˜](./agents/trader.md) - äº¤æ˜“å†³ç­–æ™ºèƒ½ä½“
- [é£é™©ç®¡ç†](./agents/risk-management.md) - é£é™©ç®¡ç†æ™ºèƒ½ä½“
- [ç®¡ç†å±‚](./agents/managers.md) - ç®¡ç†å±‚æ™ºèƒ½ä½“

### ğŸ“Š æ•°æ®å¤„ç†
- [æ•°æ®æºé›†æˆ](./data/data-sources.md) - æ”¯æŒçš„æ•°æ®æºå’ŒAPI (å«Aè‚¡æ”¯æŒ) âœ¨
- [é€šè¾¾ä¿¡APIé›†æˆ](./data/tongdaxin-api-integration.md) - Aè‚¡æ•°æ®æºè¯¦è§£ âœ¨
- [æ•°æ®å¤„ç†æµç¨‹](./data/data-processing.md) - æ•°æ®è·å–å’Œå¤„ç†
- [ç¼“å­˜æœºåˆ¶](./data/caching.md) - æ•°æ®ç¼“å­˜ç­–ç•¥

### âš™ï¸ é…ç½®ä¸éƒ¨ç½²
- [é…ç½®è¯´æ˜](./configuration/config-guide.md) - é…ç½®æ–‡ä»¶è¯¦è§£
- [LLMé…ç½®](./configuration/llm-config.md) - å¤§è¯­è¨€æ¨¡å‹é…ç½®
- [Google AIé…ç½®](./configuration/google-ai-setup.md) - Google AI (Gemini)æ¨¡å‹é…ç½®æŒ‡å— âœ¨
- [Webç•Œé¢é…ç½®](../web/README.md) - Webç®¡ç†ç•Œé¢ä½¿ç”¨æŒ‡å— âœ¨
- [éƒ¨ç½²æŒ‡å—](./deployment/deployment-guide.md) - ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### ğŸ”§ å¼€å‘æŒ‡å—
- [å¼€å‘ç¯å¢ƒæ­å»º](./development/dev-setup.md) - å¼€å‘ç¯å¢ƒé…ç½®
- [ä»£ç ç»“æ„](./development/code-structure.md) - ä»£ç ç»„ç»‡ç»“æ„
- [æ‰©å±•å¼€å‘](./development/extending.md) - å¦‚ä½•æ‰©å±•æ¡†æ¶
- [æµ‹è¯•æŒ‡å—](./development/testing.md) - æµ‹è¯•ç­–ç•¥å’Œæ–¹æ³•

### ğŸ“š APIå‚è€ƒ
- [æ ¸å¿ƒAPI](./api/core-api.md) - æ ¸å¿ƒç±»å’Œæ–¹æ³•
- [æ™ºèƒ½ä½“API](./api/agents-api.md) - æ™ºèƒ½ä½“æ¥å£
- [æ•°æ®API](./api/data-api.md) - æ•°æ®å¤„ç†æ¥å£

### ğŸŒ ä½¿ç”¨æŒ‡å—
- [Webç•Œé¢æŒ‡å—](./usage/web-interface-guide.md) - Webç•Œé¢è¯¦ç»†ä½¿ç”¨æŒ‡å— âœ¨
- [æŠ•èµ„åˆ†ææŒ‡å—](./usage/investment_analysis_guide.md) - æŠ•èµ„åˆ†æå®Œæ•´æµç¨‹
- [Aè‚¡åˆ†ææŒ‡å—](./guides/a-share-analysis-guide.md) - Aè‚¡å¸‚åœºåˆ†æä¸“é¡¹æŒ‡å— âœ¨

### ğŸ’¡ ç¤ºä¾‹å’Œæ•™ç¨‹
- [åŸºç¡€ç¤ºä¾‹](./examples/basic-examples.md) - åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹
- [é«˜çº§ç¤ºä¾‹](./examples/advanced-examples.md) - é«˜çº§åŠŸèƒ½ç¤ºä¾‹
- [è‡ªå®šä¹‰æ™ºèƒ½ä½“](./examples/custom-agents.md) - åˆ›å»ºè‡ªå®šä¹‰æ™ºèƒ½ä½“

### â“ å¸¸è§é—®é¢˜
- [FAQ](./faq/faq.md) - å¸¸è§é—®é¢˜è§£ç­”
- [æ•…éšœæ’é™¤](./faq/troubleshooting.md) - é—®é¢˜è¯Šæ–­å’Œè§£å†³

## è´¡çŒ®æŒ‡å—

å¦‚æœæ‚¨æƒ³ä¸ºæ–‡æ¡£åšå‡ºè´¡çŒ®ï¼Œè¯·å‚è€ƒ [è´¡çŒ®æŒ‡å—](../CONTRIBUTING.md)ã€‚

## è”ç³»æˆ‘ä»¬

- GitHub: [TauricResearch/TradingAgents](https://github.com/TauricResearch/TradingAgents)
- Discord: [TradingResearch](https://discord.com/invite/hk9PGKShPK)
- å¾®ä¿¡: TauricResearch
- Twitter: [@TauricResearch](https://x.com/TauricResearch)


<!-- docs/STRUCTURE.md -->

# æ–‡æ¡£ç›®å½•ç»“æ„

```
docs/
â”œâ”€â”€ README.md                           # æ–‡æ¡£ä¸»é¡µå’Œå¯¼èˆª
â”œâ”€â”€ STRUCTURE.md                        # æœ¬æ–‡ä»¶ - æ–‡æ¡£ç»“æ„è¯´æ˜
â”‚
â”œâ”€â”€ overview/                           # ğŸ“‹ æ¦‚è§ˆæ–‡æ¡£
â”‚   â”œâ”€â”€ project-overview.md            # âœ… é¡¹ç›®æ¦‚è¿°
â”‚   â”œâ”€â”€ quick-start.md                 # âœ… å¿«é€Ÿå¼€å§‹æŒ‡å—
â”‚   â””â”€â”€ installation.md                # ğŸ”„ è¯¦ç»†å®‰è£…è¯´æ˜
â”‚
â”œâ”€â”€ architecture/                      # ğŸ—ï¸ æ¶æ„æ–‡æ¡£
â”‚   â”œâ”€â”€ system-architecture.md         # âœ… ç³»ç»Ÿæ¶æ„è®¾è®¡
â”‚   â”œâ”€â”€ agent-architecture.md          # âœ… æ™ºèƒ½ä½“æ¶æ„è®¾è®¡
â”‚   â”œâ”€â”€ data-flow-architecture.md      # âœ… æ•°æ®æµæ¶æ„
â”‚   â””â”€â”€ graph-structure.md             # âœ… LangGraph å›¾ç»“æ„è®¾è®¡
â”‚
â”œâ”€â”€ agents/                            # ğŸ¤– æ™ºèƒ½ä½“æ–‡æ¡£
â”‚   â”œâ”€â”€ analysts.md                    # âœ… åˆ†æå¸ˆå›¢é˜Ÿè¯¦è§£
â”‚   â”œâ”€â”€ researchers.md                 # ğŸ”„ ç ”ç©¶å‘˜å›¢é˜Ÿè®¾è®¡
â”‚   â”œâ”€â”€ trader.md                      # ğŸ”„ äº¤æ˜“å‘˜æ™ºèƒ½ä½“
â”‚   â”œâ”€â”€ risk-management.md             # ğŸ”„ é£é™©ç®¡ç†æ™ºèƒ½ä½“
â”‚   â””â”€â”€ managers.md                    # ğŸ”„ ç®¡ç†å±‚æ™ºèƒ½ä½“
â”‚
â”œâ”€â”€ data/                              # ğŸ“Š æ•°æ®å¤„ç†æ–‡æ¡£
â”‚   â”œâ”€â”€ data-sources.md                # ğŸ”„ æ”¯æŒçš„æ•°æ®æºå’ŒAPI
â”‚   â”œâ”€â”€ data-processing.md             # ğŸ”„ æ•°æ®è·å–å’Œå¤„ç†
â”‚   â””â”€â”€ caching.md                     # ğŸ”„ æ•°æ®ç¼“å­˜ç­–ç•¥
â”‚
â”œâ”€â”€ configuration/                     # âš™ï¸ é…ç½®ä¸éƒ¨ç½²
â”‚   â”œâ”€â”€ config-guide.md               # ğŸ”„ é…ç½®æ–‡ä»¶è¯¦è§£
â”‚   â””â”€â”€ llm-config.md                 # ğŸ”„ å¤§è¯­è¨€æ¨¡å‹é…ç½®
â”‚
â”œâ”€â”€ deployment/                        # ğŸš€ éƒ¨ç½²æ–‡æ¡£
â”‚   â””â”€â”€ deployment-guide.md           # ğŸ”„ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
â”‚
â”œâ”€â”€ development/                       # ğŸ”§ å¼€å‘æŒ‡å—
â”‚   â”œâ”€â”€ dev-setup.md                  # ğŸ”„ å¼€å‘ç¯å¢ƒæ­å»º
â”‚   â”œâ”€â”€ code-structure.md             # ğŸ”„ ä»£ç ç»„ç»‡ç»“æ„
â”‚   â”œâ”€â”€ extending.md                  # ğŸ”„ å¦‚ä½•æ‰©å±•æ¡†æ¶
â”‚   â””â”€â”€ testing.md                    # ğŸ”„ æµ‹è¯•ç­–ç•¥å’Œæ–¹æ³•
â”‚
â”œâ”€â”€ api/                               # ğŸ“š APIå‚è€ƒ
â”‚   â”œâ”€â”€ core-api.md                   # ğŸ”„ æ ¸å¿ƒç±»å’Œæ–¹æ³•
â”‚   â”œâ”€â”€ agents-api.md                 # ğŸ”„ æ™ºèƒ½ä½“æ¥å£
â”‚   â””â”€â”€ data-api.md                   # ğŸ”„ æ•°æ®å¤„ç†æ¥å£
â”‚
â”œâ”€â”€ examples/                          # ğŸ’¡ ç¤ºä¾‹å’Œæ•™ç¨‹
â”‚   â”œâ”€â”€ basic-examples.md             # ğŸ”„ åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹
â”‚   â”œâ”€â”€ advanced-examples.md          # ğŸ”„ é«˜çº§åŠŸèƒ½ç¤ºä¾‹
â”‚   â””â”€â”€ custom-agents.md              # ğŸ”„ åˆ›å»ºè‡ªå®šä¹‰æ™ºèƒ½ä½“
â”‚
â””â”€â”€ faq/                               # â“ å¸¸è§é—®é¢˜
    â”œâ”€â”€ faq.md                         # ğŸ”„ å¸¸è§é—®é¢˜è§£ç­”
    â””â”€â”€ troubleshooting.md             # ğŸ”„ é—®é¢˜è¯Šæ–­å’Œè§£å†³
```

## å›¾ä¾‹è¯´æ˜

- âœ… **å·²å®Œæˆ**: æ–‡æ¡£å·²åˆ›å»ºå¹¶åŒ…å«å®Œæ•´å†…å®¹
- ğŸ”„ **å¾…å®Œæˆ**: æ–‡æ¡£ç»“æ„å·²è§„åˆ’ï¼Œå†…å®¹å¾…è¡¥å……
- ğŸ“‹ **æ¦‚è§ˆç±»**: é¡¹ç›®ä»‹ç»å’Œå¿«é€Ÿä¸Šæ‰‹
- ğŸ—ï¸ **æ¶æ„ç±»**: ç³»ç»Ÿè®¾è®¡å’ŒæŠ€æœ¯æ¶æ„
- ğŸ¤– **æ™ºèƒ½ä½“ç±»**: å„ç±»æ™ºèƒ½ä½“çš„è¯¦ç»†è¯´æ˜
- ğŸ“Š **æ•°æ®ç±»**: æ•°æ®å¤„ç†å’Œç®¡ç†
- âš™ï¸ **é…ç½®ç±»**: ç³»ç»Ÿé…ç½®å’Œè®¾ç½®
- ğŸš€ **éƒ¨ç½²ç±»**: éƒ¨ç½²å’Œè¿ç»´
- ğŸ”§ **å¼€å‘ç±»**: å¼€å‘å’Œæ‰©å±•æŒ‡å—
- ğŸ“š **APIç±»**: æ¥å£å’Œæ–¹æ³•å‚è€ƒ
- ğŸ’¡ **ç¤ºä¾‹ç±»**: ä½¿ç”¨ç¤ºä¾‹å’Œæ•™ç¨‹
- â“ **å¸®åŠ©ç±»**: é—®é¢˜è§£ç­”å’Œæ•…éšœæ’é™¤

## æ–‡æ¡£ç¼–å†™è§„èŒƒ

### 1. æ–‡ä»¶å‘½å
- ä½¿ç”¨å°å†™å­—æ¯å’Œè¿å­—ç¬¦
- æ–‡ä»¶ååº”ç®€æ´æ˜äº†ï¼Œä½“ç°å†…å®¹ä¸»é¢˜
- ä½¿ç”¨ `.md` æ‰©å±•å

### 2. å†…å®¹ç»“æ„
- æ¯ä¸ªæ–‡æ¡£éƒ½åº”åŒ…å«æ¸…æ™°çš„æ ‡é¢˜å±‚æ¬¡
- ä½¿ç”¨é€‚å½“çš„Markdownè¯­æ³•
- åŒ…å«ä»£ç ç¤ºä¾‹å’Œå›¾è¡¨è¯´æ˜
- æä¾›ç›¸å…³é“¾æ¥å’Œå‚è€ƒ

### 3. ä»£ç ç¤ºä¾‹
- æä¾›å®Œæ•´å¯è¿è¡Œçš„ä»£ç ç¤ºä¾‹
- åŒ…å«å¿…è¦çš„æ³¨é‡Šå’Œè¯´æ˜
- ä½¿ç”¨ä¸€è‡´çš„ä»£ç é£æ ¼
- æä¾›é¢„æœŸçš„è¾“å‡ºç»“æœ

### 4. å›¾è¡¨å’Œå›¾åƒ
- ä½¿ç”¨Mermaidå›¾è¡¨å±•ç¤ºæ¶æ„å’Œæµç¨‹
- å›¾ç‰‡åº”å­˜å‚¨åœ¨é€‚å½“çš„ç›®å½•ä¸­
- æä¾›å›¾è¡¨çš„æ–‡å­—æè¿°
- ç¡®ä¿å›¾è¡¨åœ¨ä¸åŒè®¾å¤‡ä¸Šçš„å¯è¯»æ€§

## ç»´æŠ¤æŒ‡å—

### 1. å®šæœŸæ›´æ–°
- éšç€ä»£ç æ›´æ–°åŒæ­¥æ›´æ–°æ–‡æ¡£
- å®šæœŸæ£€æŸ¥é“¾æ¥çš„æœ‰æ•ˆæ€§
- æ›´æ–°è¿‡æ—¶çš„ä¿¡æ¯å’Œç¤ºä¾‹

### 2. è´¨é‡æ§åˆ¶
- ç¡®ä¿æ–‡æ¡£çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
- æ£€æŸ¥è¯­æ³•å’Œæ‹¼å†™é”™è¯¯
- éªŒè¯ä»£ç ç¤ºä¾‹çš„å¯æ‰§è¡Œæ€§

### 3. ç”¨æˆ·åé¦ˆ
- æ”¶é›†ç”¨æˆ·å¯¹æ–‡æ¡£çš„åé¦ˆ
- æ ¹æ®å¸¸è§é—®é¢˜å®Œå–„æ–‡æ¡£
- æŒç»­æ”¹è¿›æ–‡æ¡£çš„å¯è¯»æ€§

## è´¡çŒ®æŒ‡å—

### å¦‚ä½•è´¡çŒ®æ–‡æ¡£

1. **Fork é¡¹ç›®**: åœ¨GitHubä¸Šfork TradingAgentsé¡¹ç›®
2. **åˆ›å»ºåˆ†æ”¯**: ä¸ºæ–‡æ¡£æ›´æ–°åˆ›å»ºæ–°åˆ†æ”¯
3. **ç¼–å†™æ–‡æ¡£**: æŒ‰ç…§è§„èŒƒç¼–å†™æˆ–æ›´æ–°æ–‡æ¡£
4. **æäº¤PR**: æäº¤Pull Requestå¹¶æè¿°æ›´æ”¹å†…å®¹
5. **ä»£ç å®¡æŸ¥**: ç­‰å¾…ç»´æŠ¤è€…å®¡æŸ¥å’Œåˆå¹¶

### æ–‡æ¡£è´¡çŒ®ç±»å‹

- **æ–°å¢æ–‡æ¡£**: åˆ›å»ºç¼ºå¤±çš„æ–‡æ¡£å†…å®¹
- **å†…å®¹å®Œå–„**: è¡¥å……ç°æœ‰æ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯
- **é”™è¯¯ä¿®æ­£**: ä¿®å¤æ–‡æ¡£ä¸­çš„é”™è¯¯å’Œè¿‡æ—¶ä¿¡æ¯
- **ç¤ºä¾‹è¡¥å……**: æ·»åŠ æ›´å¤šä½¿ç”¨ç¤ºä¾‹å’Œæ•™ç¨‹
- **ç¿»è¯‘å·¥ä½œ**: å°†æ–‡æ¡£ç¿»è¯‘æˆå…¶ä»–è¯­è¨€

### è´¡çŒ®è€…è®¤å¯

æˆ‘ä»¬ä¼šåœ¨æ–‡æ¡£ä¸­è®¤å¯æ‰€æœ‰è´¡çŒ®è€…çš„å·¥ä½œï¼ŒåŒ…æ‹¬ï¼š
- åœ¨READMEä¸­åˆ—å‡ºè´¡çŒ®è€…
- åœ¨ç›¸å…³æ–‡æ¡£ä¸­æ ‡æ³¨ä½œè€…ä¿¡æ¯
- åœ¨å‘å¸ƒè¯´æ˜ä¸­æ„Ÿè°¢è´¡çŒ®è€…

## è”ç³»æ–¹å¼

å¦‚æœæ‚¨å¯¹æ–‡æ¡£æœ‰ä»»ä½•å»ºè®®æˆ–é—®é¢˜ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»æˆ‘ä»¬ï¼š

- **GitHub Issues**: [æäº¤æ–‡æ¡£ç›¸å…³é—®é¢˜](https://github.com/TauricResearch/TradingAgents/issues)
- **Discord**: [åŠ å…¥è®¨è®º](https://discord.com/invite/hk9PGKShPK)
- **é‚®ç®±**: docs@tauric.ai

æ„Ÿè°¢æ‚¨å¯¹TradingAgentsæ–‡æ¡£å»ºè®¾çš„å…³æ³¨å’Œæ”¯æŒï¼


<!-- docs/agents/analysts.md -->

# åˆ†æå¸ˆå›¢é˜Ÿè¯¦è§£

## æ¦‚è¿°

åˆ†æå¸ˆå›¢é˜Ÿæ˜¯ TradingAgents æ¡†æ¶çš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼Œè´Ÿè´£ä»ä¸åŒç»´åº¦åˆ†æå¸‚åœºæ•°æ®ã€‚æ¯ä¸ªåˆ†æå¸ˆéƒ½ä¸“æ³¨äºç‰¹å®šçš„åˆ†æé¢†åŸŸï¼Œé€šè¿‡ä¸“ä¸šåŒ–åˆ†å·¥ç¡®ä¿åˆ†æçš„æ·±åº¦å’Œå‡†ç¡®æ€§ã€‚

## åˆ†æå¸ˆæ¶æ„

### åŸºç¡€åˆ†æå¸ˆç±»

```python
class BaseAnalyst:
    """æ‰€æœ‰åˆ†æå¸ˆçš„åŸºç¡€ç±»"""
    
    def __init__(self, llm, config, tools=None):
        self.llm = llm
        self.config = config
        self.tools = tools or []
        self.memory = AnalystMemory()
        
    def analyze(self, state: AgentState) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ†æçš„ä¸»è¦æ–¹æ³•"""
        
        # 1. æ•°æ®é¢„å¤„ç†
        processed_data = self.preprocess_data(state)
        
        # 2. æ‰§è¡Œä¸“ä¸šåˆ†æ
        analysis_result = self.perform_analysis(processed_data)
        
        # 3. ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = self.generate_report(analysis_result)
        
        # 4. æ›´æ–°è®°å¿†
        self.memory.update(state.ticker, report)
        
        return report
    
    def preprocess_data(self, state: AgentState) -> Dict:
        """æ•°æ®é¢„å¤„ç† - å­ç±»å¯é‡å†™"""
        return state
    
    def perform_analysis(self, data: Dict) -> Dict:
        """æ‰§è¡Œåˆ†æ - å­ç±»å¿…é¡»å®ç°"""
        raise NotImplementedError
    
    def generate_report(self, analysis: Dict) -> Dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š - å­ç±»å¯é‡å†™"""
        return analysis
```

## 1. åŸºæœ¬é¢åˆ†æå¸ˆ (Fundamentals Analyst)

### èŒè´£ä¸åŠŸèƒ½
```python
class FundamentalsAnalyst(BaseAnalyst):
    """åŸºæœ¬é¢åˆ†æå¸ˆ - ä¸“æ³¨äºå…¬å¸è´¢åŠ¡å’ŒåŸºæœ¬é¢åˆ†æ"""
    
    ä¸“ä¸šé¢†åŸŸ:
    - è´¢åŠ¡æŠ¥è¡¨åˆ†æ
    - ä¼°å€¼æ¨¡å‹è®¡ç®—
    - è¡Œä¸šå¯¹æ¯”åˆ†æ
    - ç›ˆåˆ©èƒ½åŠ›è¯„ä¼°
    - è´¢åŠ¡å¥åº·åº¦è¯„ä¼°
    
    åˆ†æç»´åº¦:
    - æ”¶å…¥å¢é•¿ç‡
    - åˆ©æ¶¦ç‡è¶‹åŠ¿
    - èµ„äº§è´Ÿå€ºæ¯”ç‡
    - ç°é‡‘æµçŠ¶å†µ
    - ROE/ROA æŒ‡æ ‡
    - P/E, P/B ä¼°å€¼æ¯”ç‡
```

### æ ¸å¿ƒåˆ†ææ–¹æ³•
```python
def perform_analysis(self, data: Dict) -> Dict:
    """æ‰§è¡ŒåŸºæœ¬é¢åˆ†æ"""
    
    financial_data = data.get("financial_data", {})
    company_info = data.get("company_info", {})
    
    analysis = {
        "financial_health": self._assess_financial_health(financial_data),
        "valuation": self._calculate_valuation(financial_data),
        "growth_analysis": self._analyze_growth(financial_data),
        "profitability": self._assess_profitability(financial_data),
        "liquidity": self._assess_liquidity(financial_data),
        "leverage": self._assess_leverage(financial_data)
    }
    
    # ç»¼åˆè¯„åˆ†
    analysis["overall_score"] = self._calculate_overall_score(analysis)
    analysis["recommendation"] = self._generate_recommendation(analysis)
    
    return analysis

def _assess_financial_health(self, financial_data: Dict) -> Dict:
    """è¯„ä¼°è´¢åŠ¡å¥åº·åº¦"""
    
    # è®¡ç®—å…³é”®è´¢åŠ¡æ¯”ç‡
    current_ratio = financial_data.get("current_assets", 0) / max(
        financial_data.get("current_liabilities", 1), 1
    )
    
    debt_to_equity = financial_data.get("total_debt", 0) / max(
        financial_data.get("shareholders_equity", 1), 1
    )
    
    # è¯„ä¼°è´¢åŠ¡å¥åº·åº¦
    health_score = 0
    if current_ratio > 1.5:
        health_score += 0.3
    if debt_to_equity < 0.5:
        health_score += 0.3
    
    return {
        "current_ratio": current_ratio,
        "debt_to_equity": debt_to_equity,
        "health_score": health_score,
        "assessment": "Strong" if health_score > 0.5 else "Weak"
    }
```

### åˆ†æå·¥å…·
```python
åˆ†æå·¥å…·é›†:
- DCFä¼°å€¼æ¨¡å‹
- æ¯”è¾ƒä¼°å€¼æ³•
- è´¢åŠ¡æ¯”ç‡åˆ†æ
- è¡Œä¸šåŸºå‡†å¯¹æ¯”
- ç›ˆåˆ©è´¨é‡è¯„ä¼°
- ç°é‡‘æµåˆ†æ

æ•°æ®æº:
- è´¢åŠ¡æŠ¥è¡¨æ•°æ®
- è¡Œä¸šå¹³å‡æ•°æ®
- å®è§‚ç»æµæŒ‡æ ‡
- åŒè¡Œä¸šå…¬å¸æ•°æ®
```

## 2. æŠ€æœ¯åˆ†æå¸ˆ (Market/Technical Analyst)

### èŒè´£ä¸åŠŸèƒ½
```python
class MarketAnalyst(BaseAnalyst):
    """æŠ€æœ¯åˆ†æå¸ˆ - ä¸“æ³¨äºæŠ€æœ¯æŒ‡æ ‡å’Œä»·æ ¼è¶‹åŠ¿åˆ†æ"""
    
    ä¸“ä¸šé¢†åŸŸ:
    - æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
    - è¶‹åŠ¿è¯†åˆ«
    - æ”¯æ’‘é˜»åŠ›ä½åˆ†æ
    - äº¤æ˜“ä¿¡å·ç”Ÿæˆ
    - å¸‚åœºæƒ…ç»ªåˆ†æ
    
    æŠ€æœ¯æŒ‡æ ‡:
    - ç§»åŠ¨å¹³å‡çº¿ (MA, EMA)
    - ç›¸å¯¹å¼ºå¼±æŒ‡æ•° (RSI)
    - MACD æŒ‡æ ‡
    - å¸ƒæ—å¸¦ (Bollinger Bands)
    - æˆäº¤é‡æŒ‡æ ‡
    - åŠ¨é‡æŒ‡æ ‡
```

### æ ¸å¿ƒåˆ†ææ–¹æ³•
```python
def perform_analysis(self, data: Dict) -> Dict:
    """æ‰§è¡ŒæŠ€æœ¯åˆ†æ"""
    
    price_data = data.get("price_data", {})
    volume_data = data.get("volume_data", {})
    
    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    indicators = self._calculate_indicators(price_data, volume_data)
    
    # è¶‹åŠ¿åˆ†æ
    trend_analysis = self._analyze_trend(price_data, indicators)
    
    # æ”¯æ’‘é˜»åŠ›ä½
    support_resistance = self._find_support_resistance(price_data)
    
    # äº¤æ˜“ä¿¡å·
    signals = self._generate_signals(indicators, trend_analysis)
    
    analysis = {
        "indicators": indicators,
        "trend": trend_analysis,
        "support_resistance": support_resistance,
        "signals": signals,
        "momentum": self._assess_momentum(indicators),
        "volatility": self._assess_volatility(price_data)
    }
    
    # ç»¼åˆæŠ€æœ¯è¯„åˆ†
    analysis["technical_score"] = self._calculate_technical_score(analysis)
    analysis["recommendation"] = self._generate_technical_recommendation(analysis)
    
    return analysis

def _calculate_indicators(self, price_data: Dict, volume_data: Dict) -> Dict:
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
    
    prices = price_data.get("close", [])
    volumes = volume_data.get("volume", [])
    
    indicators = {}
    
    # RSI è®¡ç®—
    indicators["rsi"] = self._calculate_rsi(prices)
    
    # MACD è®¡ç®—
    indicators["macd"] = self._calculate_macd(prices)
    
    # ç§»åŠ¨å¹³å‡çº¿
    indicators["ma_20"] = self._calculate_ma(prices, 20)
    indicators["ma_50"] = self._calculate_ma(prices, 50)
    
    # å¸ƒæ—å¸¦
    indicators["bollinger"] = self._calculate_bollinger_bands(prices)
    
    # æˆäº¤é‡æŒ‡æ ‡
    indicators["volume_ma"] = self._calculate_ma(volumes, 20)
    
    return indicators
```

### ä¿¡å·ç”Ÿæˆ
```python
def _generate_signals(self, indicators: Dict, trend: Dict) -> Dict:
    """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
    
    signals = {
        "buy_signals": [],
        "sell_signals": [],
        "neutral_signals": []
    }
    
    # RSI ä¿¡å·
    rsi = indicators.get("rsi", 50)
    if rsi < 30:
        signals["buy_signals"].append("RSIè¶…å–")
    elif rsi > 70:
        signals["sell_signals"].append("RSIè¶…ä¹°")
    
    # MACD ä¿¡å·
    macd = indicators.get("macd", {})
    if macd.get("signal") == "bullish_crossover":
        signals["buy_signals"].append("MACDé‡‘å‰")
    elif macd.get("signal") == "bearish_crossover":
        signals["sell_signals"].append("MACDæ­»å‰")
    
    # è¶‹åŠ¿ä¿¡å·
    if trend.get("direction") == "uptrend":
        signals["buy_signals"].append("ä¸Šå‡è¶‹åŠ¿")
    elif trend.get("direction") == "downtrend":
        signals["sell_signals"].append("ä¸‹é™è¶‹åŠ¿")
    
    return signals
```

## 3. æ–°é—»åˆ†æå¸ˆ (News Analyst)

### èŒè´£ä¸åŠŸèƒ½
```python
class NewsAnalyst(BaseAnalyst):
    """æ–°é—»åˆ†æå¸ˆ - ä¸“æ³¨äºæ–°é—»äº‹ä»¶å’Œå®è§‚å› ç´ åˆ†æ"""
    
    ä¸“ä¸šé¢†åŸŸ:
    - æ–°é—»æƒ…æ„Ÿåˆ†æ
    - äº‹ä»¶å½±å“è¯„ä¼°
    - å®è§‚ç»æµåˆ†æ
    - æ”¿ç­–å½±å“åˆ†æ
    - è¡Œä¸šåŠ¨æ€åˆ†æ
    
    åˆ†æç»´åº¦:
    - æ–°é—»æƒ…æ„Ÿææ€§
    - äº‹ä»¶é‡è¦æ€§è¯„çº§
    - å½±å“æ—¶é—´èŒƒå›´
    - å¸‚åœºååº”é¢„æœŸ
    - é£é™©å› ç´ è¯†åˆ«
```

### æ ¸å¿ƒåˆ†ææ–¹æ³•
```python
def perform_analysis(self, data: Dict) -> Dict:
    """æ‰§è¡Œæ–°é—»åˆ†æ"""
    
    news_data = data.get("news_data", [])
    economic_data = data.get("economic_data", {})
    
    analysis = {
        "sentiment_analysis": self._analyze_sentiment(news_data),
        "event_impact": self._assess_event_impact(news_data),
        "macro_analysis": self._analyze_macro_factors(economic_data),
        "risk_factors": self._identify_risk_factors(news_data),
        "catalysts": self._identify_catalysts(news_data)
    }
    
    # ç»¼åˆæ–°é—»è¯„åˆ†
    analysis["news_score"] = self._calculate_news_score(analysis)
    analysis["market_impact"] = self._assess_market_impact(analysis)
    
    return analysis

def _analyze_sentiment(self, news_data: List[Dict]) -> Dict:
    """åˆ†ææ–°é—»æƒ…æ„Ÿ"""
    
    sentiments = []
    weighted_sentiment = 0
    total_weight = 0
    
    for news in news_data:
        # è®¡ç®—å•æ¡æ–°é—»æƒ…æ„Ÿ
        sentiment = self._calculate_news_sentiment(news["content"])
        importance = news.get("importance", 1.0)
        
        sentiments.append({
            "title": news["title"],
            "sentiment": sentiment,
            "importance": importance,
            "source": news.get("source", "Unknown")
        })
        
        # åŠ æƒå¹³å‡
        weighted_sentiment += sentiment * importance
        total_weight += importance
    
    overall_sentiment = weighted_sentiment / max(total_weight, 1)
    
    return {
        "individual_sentiments": sentiments,
        "overall_sentiment": overall_sentiment,
        "sentiment_distribution": self._calculate_sentiment_distribution(sentiments),
        "confidence": self._calculate_sentiment_confidence(sentiments)
    }
```

### äº‹ä»¶å½±å“è¯„ä¼°
```python
def _assess_event_impact(self, news_data: List[Dict]) -> Dict:
    """è¯„ä¼°äº‹ä»¶å½±å“"""
    
    impact_assessment = {
        "high_impact_events": [],
        "medium_impact_events": [],
        "low_impact_events": []
    }
    
    for news in news_data:
        impact_score = self._calculate_impact_score(news)
        
        event_info = {
            "title": news["title"],
            "impact_score": impact_score,
            "time_horizon": self._estimate_time_horizon(news),
            "affected_sectors": self._identify_affected_sectors(news)
        }
        
        if impact_score > 0.7:
            impact_assessment["high_impact_events"].append(event_info)
        elif impact_score > 0.4:
            impact_assessment["medium_impact_events"].append(event_info)
        else:
            impact_assessment["low_impact_events"].append(event_info)
    
    return impact_assessment
```

## 4. ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ (Social Media Analyst)

### èŒè´£ä¸åŠŸèƒ½
```python
class SocialMediaAnalyst(BaseAnalyst):
    """ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ - ä¸“æ³¨äºç¤¾äº¤åª’ä½“æƒ…ç»ªå’Œèˆ†è®ºåˆ†æ"""
    
    ä¸“ä¸šé¢†åŸŸ:
    - ç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æ
    - èˆ†è®ºè¶‹åŠ¿ç›‘æµ‹
    - çƒ­ç‚¹è¯é¢˜è¯†åˆ«
    - æŠ•èµ„è€…æƒ…ç»ªè¯„ä¼°
    - ç—…æ¯’å¼ä¼ æ’­åˆ†æ
    
    æ•°æ®æº:
    - Reddit è®¨è®º
    - Twitter æƒ…æ„Ÿ
    - æŠ•èµ„è®ºå›
    - æ–°é—»è¯„è®º
    - ç¤¾äº¤åª’ä½“æåŠ
```

### æ ¸å¿ƒåˆ†ææ–¹æ³•
```python
def perform_analysis(self, data: Dict) -> Dict:
    """æ‰§è¡Œç¤¾äº¤åª’ä½“åˆ†æ"""
    
    social_data = data.get("social_data", {})
    
    analysis = {
        "sentiment_trends": self._analyze_sentiment_trends(social_data),
        "discussion_volume": self._analyze_discussion_volume(social_data),
        "key_topics": self._extract_key_topics(social_data),
        "influencer_sentiment": self._analyze_influencer_sentiment(social_data),
        "viral_content": self._identify_viral_content(social_data)
    }
    
    # ç»¼åˆç¤¾äº¤åª’ä½“è¯„åˆ†
    analysis["social_score"] = self._calculate_social_score(analysis)
    analysis["crowd_sentiment"] = self._assess_crowd_sentiment(analysis)
    
    return analysis

def _analyze_sentiment_trends(self, social_data: Dict) -> Dict:
    """åˆ†ææƒ…æ„Ÿè¶‹åŠ¿"""
    
    reddit_data = social_data.get("reddit", [])
    twitter_data = social_data.get("twitter", [])
    
    # æ—¶é—´åºåˆ—æƒ…æ„Ÿåˆ†æ
    sentiment_timeline = self._build_sentiment_timeline(reddit_data, twitter_data)
    
    # è¶‹åŠ¿æ£€æµ‹
    trend_direction = self._detect_sentiment_trend(sentiment_timeline)
    
    return {
        "timeline": sentiment_timeline,
        "trend_direction": trend_direction,
        "momentum": self._calculate_sentiment_momentum(sentiment_timeline),
        "volatility": self._calculate_sentiment_volatility(sentiment_timeline)
    }
```

## åˆ†æå¸ˆåä½œæœºåˆ¶

### 1. åˆ†æç»“æœæ•´åˆ
```python
class AnalysisIntegrator:
    """åˆ†æç»“æœæ•´åˆå™¨"""
    
    def integrate_analyses(self, analyst_reports: Dict) -> Dict:
        """æ•´åˆæ‰€æœ‰åˆ†æå¸ˆçš„æŠ¥å‘Š"""
        
        integrated = {
            "fundamental_score": analyst_reports.get("fundamentals", {}).get("overall_score", 0.5),
            "technical_score": analyst_reports.get("technical", {}).get("technical_score", 0.5),
            "news_score": analyst_reports.get("news", {}).get("news_score", 0.5),
            "social_score": analyst_reports.get("social", {}).get("social_score", 0.5)
        }
        
        # åŠ æƒç»¼åˆè¯„åˆ†
        weights = self.config.get("analyst_weights", {
            "fundamentals": 0.3,
            "technical": 0.3,
            "news": 0.2,
            "social": 0.2
        })
        
        integrated["composite_score"] = sum(
            integrated[f"{analyst}_score"] * weights[analyst]
            for analyst in weights.keys()
        )
        
        # ä¸€è‡´æ€§åˆ†æ
        integrated["consensus_level"] = self._calculate_consensus(integrated)
        
        return integrated
```

### 2. è´¨é‡æ§åˆ¶
```python
class AnalysisQualityControl:
    """åˆ†æè´¨é‡æ§åˆ¶"""
    
    def validate_analysis(self, analysis: Dict, analyst_type: str) -> Tuple[bool, List[str]]:
        """éªŒè¯åˆ†æè´¨é‡"""
        
        errors = []
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = self._get_required_fields(analyst_type)
        for field in required_fields:
            if field not in analysis:
                errors.append(f"Missing required field: {field}")
        
        # æ£€æŸ¥æ•°å€¼èŒƒå›´
        if not self._validate_score_ranges(analysis):
            errors.append("Score values out of valid range")
        
        # æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§
        if not self._validate_logical_consistency(analysis):
            errors.append("Logical inconsistency detected")
        
        return len(errors) == 0, errors
```

åˆ†æå¸ˆå›¢é˜Ÿé€šè¿‡ä¸“ä¸šåŒ–åˆ†å·¥å’Œåä½œæœºåˆ¶ï¼Œä¸ºäº¤æ˜“å†³ç­–æä¾›å…¨é¢ã€å‡†ç¡®çš„å¸‚åœºåˆ†æï¼Œæ˜¯æ•´ä¸ª TradingAgents ç³»ç»Ÿçš„é‡è¦åŸºç¡€ã€‚


<!-- docs/agents/managers.md -->

# ç®¡ç†å±‚æ™ºèƒ½ä½“

## æ¦‚è¿°

ç®¡ç†å±‚æ™ºèƒ½ä½“æ˜¯ TradingAgents æ¡†æ¶çš„åè°ƒå’Œå†³ç­–ä¸­æ¢ï¼Œè´Ÿè´£ç»Ÿç­¹å„ä¸ªä¸“ä¸šå›¢é˜Ÿçš„å·¥ä½œï¼Œç¡®ä¿æ•´ä¸ªæŠ•èµ„å†³ç­–æµç¨‹çš„æœ‰åºè¿›è¡Œã€‚ç®¡ç†å±‚åŒ…æ‹¬ç ”ç©¶ç»ç†å’Œé£é™©ç»ç†ï¼Œåˆ†åˆ«è´Ÿè´£ç ”ç©¶æ´»åŠ¨çš„åè°ƒå’Œé£é™©ç®¡ç†çš„ç»Ÿç­¹ã€‚

## ç®¡ç†å±‚æ¶æ„

### ç®¡ç†å±‚ä½“ç³»è®¾è®¡

```python
class ManagementLayer:
    """ç®¡ç†å±‚ç³»ç»Ÿ - ç»Ÿç­¹åè°ƒå„ä¸“ä¸šå›¢é˜Ÿ"""
    
    def __init__(self, config):
        self.config = config
        self.research_manager = ResearchManager(config)
        self.risk_manager = RiskManager(config)
        self.decision_coordinator = DecisionCoordinator(config)
        
    def orchestrate_decision_process(self, analysis_data: Dict) -> Dict:
        """åè°ƒæ•´ä¸ªå†³ç­–æµç¨‹"""
        
        # 1. ç ”ç©¶é˜¶æ®µç®¡ç†
        research_results = self.research_manager.manage_research_process(analysis_data)
        
        # 2. é£é™©è¯„ä¼°ç®¡ç†
        risk_assessment = self.risk_manager.manage_risk_assessment(
            research_results, analysis_data
        )
        
        # 3. å†³ç­–åè°ƒ
        final_decision = self.decision_coordinator.coordinate_final_decision(
            research_results, risk_assessment
        )
        
        # 4. è´¨é‡æ§åˆ¶
        quality_check = self._conduct_quality_control(final_decision)
        
        return {
            "research_results": research_results,
            "risk_assessment": risk_assessment,
            "final_decision": final_decision,
            "quality_check": quality_check,
            "management_approval": self._provide_management_approval(final_decision, quality_check)
        }
```

## 1. ç ”ç©¶ç»ç† (Research Manager)

### èŒè´£ä¸åŠŸèƒ½
```python
class ResearchManager:
    """ç ”ç©¶ç»ç† - åè°ƒå’Œç®¡ç†ç ”ç©¶æ´»åŠ¨"""
    
    def __init__(self, config):
        self.config = config
        self.research_standards = ResearchStandards()
        self.quality_controller = ResearchQualityController()
        self.debate_moderator = DebateModerator()
        
    æ ¸å¿ƒèŒè´£:
    - åè°ƒåˆ†æå¸ˆå’Œç ”ç©¶å‘˜å·¥ä½œ
    - ä¸»æŒç ”ç©¶å‘˜è¾©è®º
    - ç¡®ä¿ç ”ç©¶è´¨é‡
    - å½¢æˆç ”ç©¶å…±è¯†
    - ç®¡ç†ç ”ç©¶æµç¨‹
    
    ç®¡ç†èŒƒå›´:
    - åˆ†æå¸ˆå›¢é˜Ÿåè°ƒ
    - ç ”ç©¶å‘˜è¾©è®ºç®¡ç†
    - ç ”ç©¶è´¨é‡æ§åˆ¶
    - å…±è¯†å½¢æˆæœºåˆ¶
    - ç ”ç©¶æ•ˆç‡ä¼˜åŒ–
```

### ç ”ç©¶æµç¨‹ç®¡ç†
```python
def manage_research_process(self, analysis_data: Dict) -> Dict:
    """ç®¡ç†ç ”ç©¶æµç¨‹"""
    
    # 1. åˆ†æå¸ˆå·¥ä½œåè°ƒ
    analyst_coordination = self._coordinate_analyst_work(analysis_data)
    
    # 2. åˆ†æè´¨é‡æ£€æŸ¥
    analysis_quality = self._check_analysis_quality(analyst_coordination)
    
    # 3. ç ”ç©¶å‘˜è¾©è®ºç®¡ç†
    debate_results = self._manage_researcher_debate(analyst_coordination)
    
    # 4. å…±è¯†å½¢æˆ
    research_consensus = self._facilitate_consensus_formation(debate_results)
    
    # 5. ç ”ç©¶æŠ¥å‘Šç”Ÿæˆ
    research_report = self._generate_research_report(
        analyst_coordination, debate_results, research_consensus
    )
    
    return {
        "analyst_coordination": analyst_coordination,
        "analysis_quality": analysis_quality,
        "debate_results": debate_results,
        "research_consensus": research_consensus,
        "research_report": research_report,
        "research_confidence": self._assess_research_confidence(research_consensus)
    }

def _coordinate_analyst_work(self, analysis_data: Dict) -> Dict:
    """åè°ƒåˆ†æå¸ˆå·¥ä½œ"""
    
    analyst_reports = analysis_data.get("analyst_reports", {})
    
    coordination_results = {
        "coverage_completeness": self._assess_coverage_completeness(analyst_reports),
        "analysis_consistency": self._check_analysis_consistency(analyst_reports),
        "data_quality": self._evaluate_data_quality(analyst_reports),
        "methodology_alignment": self._check_methodology_alignment(analyst_reports)
    }
    
    # è¯†åˆ«éœ€è¦è¡¥å……çš„åˆ†æ
    missing_analysis = self._identify_missing_analysis(analyst_reports)
    
    # åè°ƒè¡¥å……åˆ†æ
    if missing_analysis:
        coordination_results["supplementary_analysis"] = self._request_supplementary_analysis(
            missing_analysis
        )
    
    # åˆ†æå¸ˆå·¥ä½œè¯„ä¼°
    coordination_results["analyst_performance"] = self._evaluate_analyst_performance(
        analyst_reports
    )
    
    return coordination_results

def _manage_researcher_debate(self, analyst_coordination: Dict) -> Dict:
    """ç®¡ç†ç ”ç©¶å‘˜è¾©è®º"""
    
    # è®¾ç½®è¾©è®ºè®®é¢˜
    debate_agenda = self._set_debate_agenda(analyst_coordination)
    
    # åˆ†é…è¾©è®ºè§’è‰²
    debate_roles = self._assign_debate_roles()
    
    # ä¸»æŒè¾©è®ºè¿‡ç¨‹
    debate_process = self._moderate_debate_process(debate_agenda, debate_roles)
    
    # è¯„ä¼°è¾©è®ºè´¨é‡
    debate_quality = self._assess_debate_quality(debate_process)
    
    # æå–å…³é”®äº‰è®®ç‚¹
    key_disagreements = self._extract_key_disagreements(debate_process)
    
    return {
        "debate_agenda": debate_agenda,
        "debate_roles": debate_roles,
        "debate_process": debate_process,
        "debate_quality": debate_quality,
        "key_disagreements": key_disagreements,
        "debate_effectiveness": self._measure_debate_effectiveness(debate_process)
    }

def _facilitate_consensus_formation(self, debate_results: Dict) -> Dict:
    """ä¿ƒè¿›å…±è¯†å½¢æˆ"""
    
    # åˆ†æè¾©è®ºç»“æœ
    debate_analysis = self._analyze_debate_outcomes(debate_results)
    
    # è¯†åˆ«å…±åŒç‚¹
    common_ground = self._identify_common_ground(debate_analysis)
    
    # è°ƒè§£åˆ†æ­§
    mediated_disagreements = self._mediate_disagreements(
        debate_results["key_disagreements"]
    )
    
    # æƒè¡¡ä¸åŒè§‚ç‚¹
    balanced_perspective = self._create_balanced_perspective(
        common_ground, mediated_disagreements
    )
    
    # å½¢æˆæœ€ç»ˆå…±è¯†
    final_consensus = self._formulate_final_consensus(balanced_perspective)
    
    return {
        "common_ground": common_ground,
        "mediated_disagreements": mediated_disagreements,
        "balanced_perspective": balanced_perspective,
        "final_consensus": final_consensus,
        "consensus_strength": self._measure_consensus_strength(final_consensus),
        "remaining_uncertainties": self._identify_remaining_uncertainties(final_consensus)
    }
```

### ç ”ç©¶è´¨é‡æ§åˆ¶
```python
class ResearchQualityController:
    """ç ”ç©¶è´¨é‡æ§åˆ¶å™¨"""
    
    def __init__(self):
        self.quality_standards = self._define_quality_standards()
        self.evaluation_metrics = self._setup_evaluation_metrics()
    
    def evaluate_research_quality(self, research_data: Dict) -> Dict:
        """è¯„ä¼°ç ”ç©¶è´¨é‡"""
        
        quality_dimensions = {
            "data_quality": self._assess_data_quality(research_data),
            "methodology_rigor": self._assess_methodology_rigor(research_data),
            "analysis_depth": self._assess_analysis_depth(research_data),
            "logical_consistency": self._assess_logical_consistency(research_data),
            "evidence_strength": self._assess_evidence_strength(research_data),
            "bias_control": self._assess_bias_control(research_data)
        }
        
        # è®¡ç®—ç»¼åˆè´¨é‡è¯„åˆ†
        overall_quality = self._calculate_overall_quality(quality_dimensions)
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        improvement_suggestions = self._generate_improvement_suggestions(quality_dimensions)
        
        return {
            "quality_dimensions": quality_dimensions,
            "overall_quality": overall_quality,
            "quality_grade": self._assign_quality_grade(overall_quality),
            "improvement_suggestions": improvement_suggestions,
            "quality_certification": self._provide_quality_certification(overall_quality)
        }
    
    def _assess_data_quality(self, research_data: Dict) -> Dict:
        """è¯„ä¼°æ•°æ®è´¨é‡"""
        
        data_sources = research_data.get("data_sources", {})
        
        quality_factors = {
            "completeness": self._check_data_completeness(data_sources),
            "accuracy": self._verify_data_accuracy(data_sources),
            "timeliness": self._assess_data_timeliness(data_sources),
            "relevance": self._evaluate_data_relevance(data_sources),
            "reliability": self._assess_source_reliability(data_sources)
        }
        
        data_quality_score = sum(quality_factors.values()) / len(quality_factors)
        
        return {
            "quality_factors": quality_factors,
            "quality_score": data_quality_score,
            "quality_level": "é«˜" if data_quality_score > 0.8 else "ä¸­" if data_quality_score > 0.6 else "ä½"
        }
```

## 2. é£é™©ç»ç† (Risk Manager)

### èŒè´£ä¸åŠŸèƒ½
```python
class RiskManager:
    """é£é™©ç»ç† - ç»Ÿç­¹é£é™©ç®¡ç†æ´»åŠ¨"""
    
    def __init__(self, config):
        self.config = config
        self.risk_framework = RiskManagementFramework()
        self.risk_committee = RiskCommittee()
        self.risk_monitor = RiskMonitor()
        
    æ ¸å¿ƒèŒè´£:
    - åˆ¶å®šé£é™©ç®¡ç†æ”¿ç­–
    - åè°ƒé£é™©è¯„ä¼°æ´»åŠ¨
    - ç›‘ç£é£é™©æ§åˆ¶æ‰§è¡Œ
    - ç®¡ç†é£é™©å§”å‘˜ä¼š
    - åº”å¯¹é£é™©äº‹ä»¶
    
    ç®¡ç†èŒƒå›´:
    - é£é™©æ”¿ç­–åˆ¶å®š
    - é£é™©è¯„ä¼°åè°ƒ
    - é£é™©æ§åˆ¶ç›‘ç£
    - é£é™©æŠ¥å‘Šç®¡ç†
    - å±æœºåº”å¯¹å¤„ç†
```

### é£é™©ç®¡ç†æµç¨‹
```python
def manage_risk_assessment(self, research_results: Dict, market_data: Dict) -> Dict:
    """ç®¡ç†é£é™©è¯„ä¼°æµç¨‹"""
    
    # 1. é£é™©è¯†åˆ«
    risk_identification = self._conduct_risk_identification(research_results, market_data)
    
    # 2. é£é™©è¯„ä¼°åè°ƒ
    risk_assessment_coordination = self._coordinate_risk_assessments(risk_identification)
    
    # 3. é£é™©å§”å‘˜ä¼šå†³è®®
    risk_committee_decision = self._convene_risk_committee(risk_assessment_coordination)
    
    # 4. é£é™©æ§åˆ¶è®¾è®¡
    risk_controls = self._design_risk_controls(risk_committee_decision)
    
    # 5. é£é™©ç›‘æ§è®¾ç½®
    risk_monitoring = self._setup_risk_monitoring(risk_controls)
    
    return {
        "risk_identification": risk_identification,
        "risk_assessment": risk_assessment_coordination,
        "committee_decision": risk_committee_decision,
        "risk_controls": risk_controls,
        "risk_monitoring": risk_monitoring,
        "risk_approval": self._provide_risk_approval(risk_committee_decision)
    }

def _conduct_risk_identification(self, research_results: Dict, market_data: Dict) -> Dict:
    """è¿›è¡Œé£é™©è¯†åˆ«"""
    
    # ç³»ç»Ÿæ€§é£é™©è¯†åˆ«
    systematic_risks = self._identify_systematic_risks(market_data)
    
    # ç‰¹å®šé£é™©è¯†åˆ«
    specific_risks = self._identify_specific_risks(research_results)
    
    # æ“ä½œé£é™©è¯†åˆ«
    operational_risks = self._identify_operational_risks()
    
    # æµåŠ¨æ€§é£é™©è¯†åˆ«
    liquidity_risks = self._identify_liquidity_risks(market_data)
    
    # é£é™©ç›¸å…³æ€§åˆ†æ
    risk_correlations = self._analyze_risk_correlations(
        systematic_risks, specific_risks, operational_risks, liquidity_risks
    )
    
    return {
        "systematic_risks": systematic_risks,
        "specific_risks": specific_risks,
        "operational_risks": operational_risks,
        "liquidity_risks": liquidity_risks,
        "risk_correlations": risk_correlations,
        "risk_map": self._create_risk_map(systematic_risks, specific_risks, operational_risks)
    }

def _coordinate_risk_assessments(self, risk_identification: Dict) -> Dict:
    """åè°ƒé£é™©è¯„ä¼°"""
    
    # åˆ†é…è¯„ä¼°ä»»åŠ¡
    assessment_assignments = self._assign_assessment_tasks(risk_identification)
    
    # ç›‘ç£è¯„ä¼°è¿‡ç¨‹
    assessment_supervision = self._supervise_assessment_process(assessment_assignments)
    
    # æ•´åˆè¯„ä¼°ç»“æœ
    integrated_assessment = self._integrate_assessment_results(assessment_supervision)
    
    # äº¤å‰éªŒè¯
    cross_validation = self._conduct_cross_validation(integrated_assessment)
    
    # è¯„ä¼°è´¨é‡æ§åˆ¶
    quality_control = self._conduct_assessment_quality_control(integrated_assessment)
    
    return {
        "assignments": assessment_assignments,
        "supervision": assessment_supervision,
        "integrated_results": integrated_assessment,
        "cross_validation": cross_validation,
        "quality_control": quality_control,
        "assessment_confidence": self._calculate_assessment_confidence(integrated_assessment)
    }

def _convene_risk_committee(self, risk_assessment: Dict) -> Dict:
    """å¬é›†é£é™©å§”å‘˜ä¼š"""
    
    # å‡†å¤‡å§”å‘˜ä¼šææ–™
    committee_materials = self._prepare_committee_materials(risk_assessment)
    
    # è®¾ç½®è®®ç¨‹
    meeting_agenda = self._set_committee_agenda(risk_assessment)
    
    # ä¸»æŒå§”å‘˜ä¼šä¼šè®®
    committee_meeting = self._chair_committee_meeting(committee_materials, meeting_agenda)
    
    # ä¿ƒè¿›å†³ç­–å½¢æˆ
    decision_formation = self._facilitate_committee_decision(committee_meeting)
    
    # è®°å½•å†³è®®
    committee_resolution = self._document_committee_resolution(decision_formation)
    
    return {
        "materials": committee_materials,
        "agenda": meeting_agenda,
        "meeting_process": committee_meeting,
        "decision_process": decision_formation,
        "resolution": committee_resolution,
        "decision_rationale": self._document_decision_rationale(committee_resolution)
    }
```

### é£é™©æ”¿ç­–åˆ¶å®š
```python
class RiskPolicyFramework:
    """é£é™©æ”¿ç­–æ¡†æ¶"""
    
    def __init__(self):
        self.policy_templates = self._load_policy_templates()
        self.regulatory_requirements = self._load_regulatory_requirements()
    
    def develop_risk_policies(self, organization_context: Dict) -> Dict:
        """åˆ¶å®šé£é™©æ”¿ç­–"""
        
        # é£é™©å®¹å¿åº¦æ”¿ç­–
        risk_tolerance_policy = self._develop_risk_tolerance_policy(organization_context)
        
        # é£é™©é™é¢æ”¿ç­–
        risk_limits_policy = self._develop_risk_limits_policy(organization_context)
        
        # é£é™©ç›‘æ§æ”¿ç­–
        risk_monitoring_policy = self._develop_risk_monitoring_policy(organization_context)
        
        # é£é™©æŠ¥å‘Šæ”¿ç­–
        risk_reporting_policy = self._develop_risk_reporting_policy(organization_context)
        
        # åº”æ€¥å“åº”æ”¿ç­–
        emergency_response_policy = self._develop_emergency_response_policy(organization_context)
        
        return {
            "risk_tolerance": risk_tolerance_policy,
            "risk_limits": risk_limits_policy,
            "risk_monitoring": risk_monitoring_policy,
            "risk_reporting": risk_reporting_policy,
            "emergency_response": emergency_response_policy,
            "policy_integration": self._integrate_risk_policies([
                risk_tolerance_policy, risk_limits_policy, risk_monitoring_policy,
                risk_reporting_policy, emergency_response_policy
            ])
        }
```

## 3. å†³ç­–åè°ƒå™¨ (Decision Coordinator)

### èŒè´£ä¸åŠŸèƒ½
```python
class DecisionCoordinator:
    """å†³ç­–åè°ƒå™¨ - åè°ƒæœ€ç»ˆæŠ•èµ„å†³ç­–"""
    
    def __init__(self, config):
        self.config = config
        self.decision_framework = DecisionFramework()
        self.stakeholder_manager = StakeholderManager()
        
    def coordinate_final_decision(self, research_results: Dict, risk_assessment: Dict) -> Dict:
        """åè°ƒæœ€ç»ˆå†³ç­–"""
        
        # 1. ä¿¡æ¯æ•´åˆ
        integrated_information = self._integrate_all_information(research_results, risk_assessment)
        
        # 2. åˆ©ç›Šç›¸å…³è€…åè°ƒ
        stakeholder_alignment = self._coordinate_stakeholders(integrated_information)
        
        # 3. å†³ç­–é€‰é¡¹åˆ†æ
        decision_options = self._analyze_decision_options(integrated_information)
        
        # 4. å†³ç­–åˆ¶å®š
        final_decision = self._make_final_decision(decision_options, stakeholder_alignment)
        
        # 5. å†³ç­–æ²Ÿé€š
        decision_communication = self._communicate_decision(final_decision)
        
        return {
            "integrated_information": integrated_information,
            "stakeholder_alignment": stakeholder_alignment,
            "decision_options": decision_options,
            "final_decision": final_decision,
            "communication_plan": decision_communication,
            "implementation_roadmap": self._create_implementation_roadmap(final_decision)
        }

def _integrate_all_information(self, research_results: Dict, risk_assessment: Dict) -> Dict:
    """æ•´åˆæ‰€æœ‰ä¿¡æ¯"""
    
    # ç ”ç©¶ä¿¡æ¯æå–
    research_insights = self._extract_research_insights(research_results)
    
    # é£é™©ä¿¡æ¯æå–
    risk_insights = self._extract_risk_insights(risk_assessment)
    
    # ä¿¡æ¯ä¸€è‡´æ€§æ£€æŸ¥
    consistency_check = self._check_information_consistency(research_insights, risk_insights)
    
    # ä¿¡æ¯æƒé‡åˆ†é…
    information_weights = self._assign_information_weights(research_insights, risk_insights)
    
    # ç»¼åˆä¿¡æ¯è¯„åˆ†
    integrated_score = self._calculate_integrated_score(
        research_insights, risk_insights, information_weights
    )
    
    return {
        "research_insights": research_insights,
        "risk_insights": risk_insights,
        "consistency_check": consistency_check,
        "information_weights": information_weights,
        "integrated_score": integrated_score,
        "information_quality": self._assess_information_quality(research_insights, risk_insights)
    }

def _analyze_decision_options(self, integrated_information: Dict) -> Dict:
    """åˆ†æå†³ç­–é€‰é¡¹"""
    
    # ç”Ÿæˆå†³ç­–é€‰é¡¹
    options = self._generate_decision_options(integrated_information)
    
    # é€‰é¡¹è¯„ä¼°
    option_evaluations = {}
    for option_name, option_details in options.items():
        option_evaluations[option_name] = self._evaluate_decision_option(
            option_details, integrated_information
        )
    
    # é€‰é¡¹æ¯”è¾ƒ
    option_comparison = self._compare_decision_options(option_evaluations)
    
    # æ¨èé€‰é¡¹
    recommended_option = self._recommend_best_option(option_comparison)
    
    return {
        "available_options": options,
        "option_evaluations": option_evaluations,
        "option_comparison": option_comparison,
        "recommended_option": recommended_option,
        "decision_rationale": self._explain_option_selection(recommended_option, option_comparison)
    }
```

### ç®¡ç†å±‚ç›‘ç£æœºåˆ¶
```python
class ManagementOversight:
    """ç®¡ç†å±‚ç›‘ç£æœºåˆ¶"""
    
    def __init__(self):
        self.oversight_standards = self._define_oversight_standards()
        self.performance_metrics = self._setup_performance_metrics()
    
    def conduct_oversight_review(self, decision_process: Dict) -> Dict:
        """è¿›è¡Œç›‘ç£å®¡æŸ¥"""
        
        # æµç¨‹åˆè§„æ€§æ£€æŸ¥
        compliance_check = self._check_process_compliance(decision_process)
        
        # å†³ç­–è´¨é‡è¯„ä¼°
        decision_quality = self._assess_decision_quality(decision_process)
        
        # é£é™©ç®¡ç†æœ‰æ•ˆæ€§è¯„ä¼°
        risk_management_effectiveness = self._assess_risk_management_effectiveness(decision_process)
        
        # å›¢é˜Ÿåä½œè¯„ä¼°
        team_collaboration = self._assess_team_collaboration(decision_process)
        
        # æ”¹è¿›å»ºè®®
        improvement_recommendations = self._generate_improvement_recommendations(
            compliance_check, decision_quality, risk_management_effectiveness, team_collaboration
        )
        
        return {
            "compliance_check": compliance_check,
            "decision_quality": decision_quality,
            "risk_management_effectiveness": risk_management_effectiveness,
            "team_collaboration": team_collaboration,
            "improvement_recommendations": improvement_recommendations,
            "oversight_rating": self._calculate_oversight_rating(
                compliance_check, decision_quality, risk_management_effectiveness
            )
        }
```

ç®¡ç†å±‚æ™ºèƒ½ä½“é€šè¿‡æœ‰æ•ˆçš„åè°ƒã€ç›‘ç£å’Œå†³ç­–æœºåˆ¶ï¼Œç¡®ä¿æ•´ä¸ªæŠ•èµ„å†³ç­–æµç¨‹çš„ä¸“ä¸šæ€§ã€åˆè§„æ€§å’Œæœ‰æ•ˆæ€§ï¼Œä¸ºæŠ•èµ„æˆåŠŸæä¾›å¼ºæœ‰åŠ›çš„ç®¡ç†ä¿éšœã€‚


<!-- docs/agents/researchers.md -->

# ç ”ç©¶å‘˜å›¢é˜Ÿè®¾è®¡

## æ¦‚è¿°

ç ”ç©¶å‘˜å›¢é˜Ÿæ˜¯ TradingAgents æ¡†æ¶ä¸­çš„å…³é”®ç»„ä»¶ï¼Œè´Ÿè´£å¯¹åˆ†æå¸ˆå›¢é˜Ÿçš„æŠ¥å‘Šè¿›è¡Œæ·±åº¦ç ”ç©¶å’Œè¾©è®ºã€‚é€šè¿‡çœ‹æ¶¨å’Œçœ‹è·Œç ”ç©¶å‘˜ä¹‹é—´çš„ç»“æ„åŒ–è¾©è®ºï¼Œç³»ç»Ÿèƒ½å¤Ÿä»å¤šä¸ªè§’åº¦è¯„ä¼°æŠ•èµ„æœºä¼šï¼Œå½¢æˆæ›´åŠ å¹³è¡¡å’Œå…¨é¢çš„æŠ•èµ„è§‚ç‚¹ã€‚

## ç ”ç©¶å‘˜æ¶æ„

### åŸºç¡€ç ”ç©¶å‘˜ç±»

```python
class BaseResearcher:
    """æ‰€æœ‰ç ”ç©¶å‘˜çš„åŸºç¡€ç±»"""
    
    def __init__(self, llm, config, stance="neutral"):
        self.llm = llm
        self.config = config
        self.stance = stance  # "bullish", "bearish", "neutral"
        self.memory = ResearcherMemory()
        self.debate_history = []
        
    def research(self, analyst_reports: Dict, context: Dict = None) -> Dict:
        """æ‰§è¡Œç ”ç©¶åˆ†æ"""
        
        # 1. åˆ†æå¸ˆæŠ¥å‘Šè§£è¯»
        interpretation = self.interpret_reports(analyst_reports)
        
        # 2. ç«‹åœºåˆ†æ
        stance_analysis = self.analyze_from_stance(interpretation)
        
        # 3. ç”Ÿæˆç ”ç©¶è§‚ç‚¹
        research_view = self.generate_research_view(stance_analysis)
        
        # 4. å‡†å¤‡è¾©è®ºè¦ç‚¹
        debate_points = self.prepare_debate_points(research_view)
        
        return {
            "interpretation": interpretation,
            "stance_analysis": stance_analysis,
            "research_view": research_view,
            "debate_points": debate_points,
            "confidence": self.calculate_confidence(research_view)
        }
    
    def debate(self, opponent_view: Dict, round_number: int) -> Dict:
        """å‚ä¸è¾©è®º"""
        
        # 1. åˆ†æå¯¹æ‰‹è§‚ç‚¹
        opponent_analysis = self.analyze_opponent_view(opponent_view)
        
        # 2. å‡†å¤‡åé©³
        counter_arguments = self.prepare_counter_arguments(opponent_analysis)
        
        # 3. å¼ºåŒ–è‡ªå·±è§‚ç‚¹
        reinforced_view = self.reinforce_own_view(counter_arguments)
        
        # 4. ç”Ÿæˆè¾©è®ºå›åº”
        debate_response = self.generate_debate_response(
            counter_arguments, reinforced_view, round_number
        )
        
        # 5. æ›´æ–°è¾©è®ºå†å²
        self.debate_history.append({
            "round": round_number,
            "opponent_view": opponent_view,
            "response": debate_response
        })
        
        return debate_response
```

## 1. çœ‹æ¶¨ç ”ç©¶å‘˜ (Bull Researcher)

### èŒè´£ä¸ç‰¹ç‚¹
```python
class BullResearcher(BaseResearcher):
    """çœ‹æ¶¨ç ”ç©¶å‘˜ - ä»ä¹è§‚è§’åº¦è¯„ä¼°æŠ•èµ„æœºä¼š"""
    
    def __init__(self, llm, config):
        super().__init__(llm, config, stance="bullish")
        
    ä¸“ä¸šç‰¹ç‚¹:
    - ç§¯æå¯»æ‰¾å¢é•¿æœºä¼š
    - å¼ºè°ƒæ­£é¢å‚¬åŒ–å‰‚
    - å…³æ³¨ä¸Šæ¶¨æ½œåŠ›
    - æŒ‘æˆ˜æ‚²è§‚è§‚ç‚¹
    
    åˆ†æé‡ç‚¹:
    - æ”¶å…¥å¢é•¿é©±åŠ¨å› ç´ 
    - å¸‚åœºæ‰©å¼ æœºä¼š
    - ç«äº‰ä¼˜åŠ¿åˆ†æ
    - ä¼°å€¼å¸å¼•åŠ›
    - æŠ€æœ¯åˆ›æ–°æ½œåŠ›
    - ç®¡ç†å±‚æ‰§è¡ŒåŠ›
```

### æ ¸å¿ƒç ”ç©¶æ–¹æ³•
```python
def analyze_from_stance(self, interpretation: Dict) -> Dict:
    """ä»çœ‹æ¶¨è§’åº¦åˆ†æ"""
    
    bullish_factors = []
    growth_opportunities = []
    positive_catalysts = []
    
    # åŸºæœ¬é¢çœ‹æ¶¨å› ç´ 
    fundamental_data = interpretation.get("fundamental_analysis", {})
    if fundamental_data.get("revenue_growth", 0) > 0.1:  # 10%ä»¥ä¸Šå¢é•¿
        bullish_factors.append("å¼ºåŠ²çš„æ”¶å…¥å¢é•¿")
    
    if fundamental_data.get("profit_margin_trend") == "improving":
        bullish_factors.append("åˆ©æ¶¦ç‡æ”¹å–„è¶‹åŠ¿")
    
    # æŠ€æœ¯é¢çœ‹æ¶¨ä¿¡å·
    technical_data = interpretation.get("technical_analysis", {})
    if technical_data.get("trend_direction") == "uptrend":
        bullish_factors.append("æŠ€æœ¯é¢ä¸Šå‡è¶‹åŠ¿")
    
    if technical_data.get("momentum") == "positive":
        bullish_factors.append("æ­£é¢åŠ¨é‡ä¿¡å·")
    
    # æ–°é—»é¢ç§¯æå› ç´ 
    news_data = interpretation.get("news_analysis", {})
    if news_data.get("sentiment_score", 0) > 0.6:
        positive_catalysts.append("ç§¯æçš„æ–°é—»æƒ…ç»ª")
    
    # è¯†åˆ«å¢é•¿æœºä¼š
    growth_opportunities = self._identify_growth_opportunities(interpretation)
    
    return {
        "bullish_factors": bullish_factors,
        "growth_opportunities": growth_opportunities,
        "positive_catalysts": positive_catalysts,
        "upside_potential": self._calculate_upside_potential(interpretation),
        "risk_mitigation": self._identify_risk_mitigation_factors(interpretation)
    }

def _identify_growth_opportunities(self, interpretation: Dict) -> List[str]:
    """è¯†åˆ«å¢é•¿æœºä¼š"""
    
    opportunities = []
    
    # å¸‚åœºæ‰©å¼ æœºä¼š
    if interpretation.get("market_size_growth", 0) > 0.05:
        opportunities.append("å¸‚åœºè§„æ¨¡æŒç»­æ‰©å¼ ")
    
    # æ–°äº§å“/æœåŠ¡æœºä¼š
    if interpretation.get("new_product_pipeline"):
        opportunities.append("ä¸°å¯Œçš„æ–°äº§å“ç®¡çº¿")
    
    # å›½é™…åŒ–æœºä¼š
    if interpretation.get("international_expansion"):
        opportunities.append("å›½é™…å¸‚åœºæ‰©å¼ æ½œåŠ›")
    
    # æŠ€æœ¯åˆ›æ–°æœºä¼š
    if interpretation.get("innovation_score", 0) > 0.7:
        opportunities.append("æŠ€æœ¯åˆ›æ–°é¢†å…ˆä¼˜åŠ¿")
    
    return opportunities

def prepare_debate_points(self, research_view: Dict) -> Dict:
    """å‡†å¤‡è¾©è®ºè¦ç‚¹"""
    
    return {
        "main_arguments": [
            "åŸºæœ¬é¢æ•°æ®æ˜¾ç¤ºå¼ºåŠ²å¢é•¿æ½œåŠ›",
            "æŠ€æœ¯æŒ‡æ ‡æ”¯æŒä¸Šæ¶¨è¶‹åŠ¿",
            "å¸‚åœºæƒ…ç»ªç§¯æå‘å¥½",
            "ä¼°å€¼ä»æœ‰ä¸Šå‡ç©ºé—´"
        ],
        "supporting_evidence": research_view.get("bullish_factors", []),
        "growth_thesis": research_view.get("growth_opportunities", []),
        "risk_responses": self._prepare_risk_responses(research_view),
        "target_scenarios": self._develop_bull_scenarios(research_view)
    }
```

### è¾©è®ºç­–ç•¥
```python
def generate_debate_response(self, counter_args: Dict, reinforced_view: Dict, round_num: int) -> Dict:
    """ç”Ÿæˆè¾©è®ºå›åº”"""
    
    response_strategy = self._determine_response_strategy(round_num)
    
    if response_strategy == "aggressive":
        return self._aggressive_response(counter_args, reinforced_view)
    elif response_strategy == "defensive":
        return self._defensive_response(counter_args, reinforced_view)
    else:
        return self._balanced_response(counter_args, reinforced_view)

def _aggressive_response(self, counter_args: Dict, reinforced_view: Dict) -> Dict:
    """ç§¯æè¿›æ”»å‹å›åº”"""
    
    return {
        "response_type": "aggressive",
        "main_points": [
            "å¯¹æ‰‹è¿‡åº¦å…³æ³¨çŸ­æœŸé£é™©ï¼Œå¿½è§†é•¿æœŸä»·å€¼",
            "å¸‚åœºææ…Œæƒ…ç»ªåˆ›é€ äº†ç»ä½³ä¹°å…¥æœºä¼š",
            "åŸºæœ¬é¢æ”¹å–„è¶‹åŠ¿ä¸å¯é€†è½¬",
            "å½“å‰ä¼°å€¼æ˜æ˜¾ä½ä¼°çœŸå®ä»·å€¼"
        ],
        "evidence_reinforcement": reinforced_view.get("strengthened_evidence", []),
        "opponent_weaknesses": self._identify_opponent_weaknesses(counter_args),
        "confidence_boost": "é«˜åº¦ç¡®ä¿¡çœ‹æ¶¨è§‚ç‚¹çš„æ­£ç¡®æ€§"
    }

def _defensive_response(self, counter_args: Dict, reinforced_view: Dict) -> Dict:
    """é˜²å®ˆå‹å›åº”"""
    
    return {
        "response_type": "defensive",
        "risk_acknowledgment": "æ‰¿è®¤å­˜åœ¨ä¸€å®šé£é™©ï¼Œä½†é£é™©å¯æ§",
        "mitigation_strategies": [
            "åˆ†æ•£æŠ•èµ„é™ä½å•ä¸€é£é™©",
            "è®¾ç½®åˆç†æ­¢æŸä½",
            "å…³æ³¨åŸºæœ¬é¢å˜åŒ–",
            "åŠ¨æ€è°ƒæ•´ä»“ä½"
        ],
        "qualified_optimism": "åœ¨é£é™©å¯æ§å‰æä¸‹ä¿æŒä¹è§‚",
        "evidence_reaffirmation": reinforced_view.get("core_evidence", [])
    }
```

## 2. çœ‹è·Œç ”ç©¶å‘˜ (Bear Researcher)

### èŒè´£ä¸ç‰¹ç‚¹
```python
class BearResearcher(BaseResearcher):
    """çœ‹è·Œç ”ç©¶å‘˜ - ä»æ‚²è§‚è§’åº¦è¯„ä¼°æŠ•èµ„é£é™©"""
    
    def __init__(self, llm, config):
        super().__init__(llm, config, stance="bearish")
        
    ä¸“ä¸šç‰¹ç‚¹:
    - ä¸“æ³¨é£é™©è¯†åˆ«
    - è´¨ç–‘ä¹è§‚å‡è®¾
    - å…³æ³¨ä¸‹è·Œé£é™©
    - æŒ‘æˆ˜çœ‹æ¶¨è§‚ç‚¹
    
    åˆ†æé‡ç‚¹:
    - æ½œåœ¨é£é™©å› ç´ 
    - ä¼°å€¼è¿‡é«˜é£é™©
    - ç«äº‰å¨èƒåˆ†æ
    - å®è§‚ç»æµé£é™©
    - è¡Œä¸šå‘¨æœŸæ€§é£é™©
    - å…¬å¸æ²»ç†é—®é¢˜
```

### æ ¸å¿ƒç ”ç©¶æ–¹æ³•
```python
def analyze_from_stance(self, interpretation: Dict) -> Dict:
    """ä»çœ‹è·Œè§’åº¦åˆ†æ"""
    
    bearish_factors = []
    risk_factors = []
    negative_catalysts = []
    
    # åŸºæœ¬é¢é£é™©å› ç´ 
    fundamental_data = interpretation.get("fundamental_analysis", {})
    if fundamental_data.get("debt_to_equity", 0) > 0.6:
        bearish_factors.append("é«˜è´Ÿå€ºæ¯”ç‡é£é™©")
    
    if fundamental_data.get("profit_margin_trend") == "declining":
        bearish_factors.append("åˆ©æ¶¦ç‡ä¸‹é™è¶‹åŠ¿")
    
    # æŠ€æœ¯é¢çœ‹è·Œä¿¡å·
    technical_data = interpretation.get("technical_analysis", {})
    if technical_data.get("trend_direction") == "downtrend":
        bearish_factors.append("æŠ€æœ¯é¢ä¸‹é™è¶‹åŠ¿")
    
    if technical_data.get("volume_trend") == "declining":
        bearish_factors.append("æˆäº¤é‡èç¼©ä¿¡å·")
    
    # æ–°é—»é¢è´Ÿé¢å› ç´ 
    news_data = interpretation.get("news_analysis", {})
    if news_data.get("sentiment_score", 0) < 0.4:
        negative_catalysts.append("è´Ÿé¢æ–°é—»æƒ…ç»ª")
    
    # è¯†åˆ«é£é™©å› ç´ 
    risk_factors = self._identify_risk_factors(interpretation)
    
    return {
        "bearish_factors": bearish_factors,
        "risk_factors": risk_factors,
        "negative_catalysts": negative_catalysts,
        "downside_potential": self._calculate_downside_potential(interpretation),
        "valuation_concerns": self._assess_valuation_risks(interpretation)
    }

def _identify_risk_factors(self, interpretation: Dict) -> List[Dict]:
    """è¯†åˆ«é£é™©å› ç´ """
    
    risks = []
    
    # å¸‚åœºé£é™©
    if interpretation.get("market_volatility", 0) > 0.3:
        risks.append({
            "type": "market_risk",
            "description": "å¸‚åœºæ³¢åŠ¨æ€§è¿‡é«˜",
            "severity": "high",
            "probability": 0.7
        })
    
    # è¡Œä¸šé£é™©
    if interpretation.get("industry_headwinds"):
        risks.append({
            "type": "industry_risk",
            "description": "è¡Œä¸šé¢ä¸´é€†é£",
            "severity": "medium",
            "probability": 0.6
        })
    
    # å…¬å¸ç‰¹å®šé£é™©
    if interpretation.get("company_specific_issues"):
        risks.append({
            "type": "company_risk",
            "description": "å…¬å¸ç‰¹å®šé—®é¢˜",
            "severity": "high",
            "probability": 0.8
        })
    
    return risks

def prepare_debate_points(self, research_view: Dict) -> Dict:
    """å‡†å¤‡è¾©è®ºè¦ç‚¹"""
    
    return {
        "main_arguments": [
            "ä¼°å€¼è¿‡é«˜ï¼Œç¼ºä¹å®‰å…¨è¾¹é™…",
            "åŸºæœ¬é¢æ¶åŒ–è¶‹åŠ¿æ˜æ˜¾",
            "æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºä¸‹è·Œé£é™©",
            "å®è§‚ç¯å¢ƒä¸åˆ©äºå¢é•¿"
        ],
        "risk_evidence": research_view.get("risk_factors", []),
        "valuation_concerns": research_view.get("valuation_concerns", []),
        "scenario_analysis": self._develop_bear_scenarios(research_view),
        "contrarian_points": self._prepare_contrarian_arguments(research_view)
    }
```

### é£é™©è¯„ä¼°ä¸“é•¿
```python
def _assess_valuation_risks(self, interpretation: Dict) -> Dict:
    """è¯„ä¼°ä¼°å€¼é£é™©"""
    
    valuation_data = interpretation.get("fundamental_analysis", {})
    
    concerns = []
    
    # P/E æ¯”ç‡åˆ†æ
    pe_ratio = valuation_data.get("pe_ratio", 0)
    industry_avg_pe = valuation_data.get("industry_avg_pe", 0)
    
    if pe_ratio > industry_avg_pe * 1.5:
        concerns.append("P/Eæ¯”ç‡æ˜¾è‘—é«˜äºè¡Œä¸šå¹³å‡")
    
    # P/B æ¯”ç‡åˆ†æ
    pb_ratio = valuation_data.get("pb_ratio", 0)
    if pb_ratio > 3.0:
        concerns.append("P/Bæ¯”ç‡è¿‡é«˜ï¼Œå­˜åœ¨æ³¡æ²«é£é™©")
    
    # å¢é•¿ç‡ä¸ä¼°å€¼åŒ¹é…åº¦
    growth_rate = valuation_data.get("growth_rate", 0)
    peg_ratio = pe_ratio / max(growth_rate * 100, 1)
    
    if peg_ratio > 2.0:
        concerns.append("PEGæ¯”ç‡è¿‡é«˜ï¼Œå¢é•¿ä¸è¶³ä»¥æ”¯æ’‘ä¼°å€¼")
    
    return {
        "concerns": concerns,
        "overvaluation_risk": "high" if len(concerns) >= 2 else "medium",
        "fair_value_estimate": self._calculate_conservative_fair_value(valuation_data),
        "downside_protection": self._assess_downside_protection(valuation_data)
    }
```

## 3. è¾©è®ºæœºåˆ¶è®¾è®¡

### è¾©è®ºç®¡ç†å™¨
```python
class DebateManager:
    """è¾©è®ºç®¡ç†å™¨ - åè°ƒç ”ç©¶å‘˜ä¹‹é—´çš„è¾©è®º"""
    
    def __init__(self, config):
        self.config = config
        self.max_rounds = config.get("max_debate_rounds", 3)
        self.consensus_threshold = config.get("consensus_threshold", 0.8)
        
    def conduct_debate(self, bull_researcher: BullResearcher, 
                      bear_researcher: BearResearcher,
                      analyst_reports: Dict) -> Dict:
        """ä¸»æŒè¾©è®ºè¿‡ç¨‹"""
        
        # åˆå§‹ç ”ç©¶
        bull_initial = bull_researcher.research(analyst_reports)
        bear_initial = bear_researcher.research(analyst_reports)
        
        debate_history = []
        current_round = 1
        
        while current_round <= self.max_rounds:
            print(f"=== è¾©è®ºç¬¬ {current_round} è½® ===")
            
            # çœ‹æ¶¨æ–¹è¾©è®º
            bull_response = bull_researcher.debate(bear_initial, current_round)
            
            # çœ‹è·Œæ–¹è¾©è®º
            bear_response = bear_researcher.debate(bull_initial, current_round)
            
            # è®°å½•è¾©è®º
            round_record = {
                "round": current_round,
                "bull_response": bull_response,
                "bear_response": bear_response,
                "consensus_level": self._calculate_consensus(bull_response, bear_response)
            }
            
            debate_history.append(round_record)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾æˆå…±è¯†æˆ–éœ€è¦ç»§ç»­
            if self._should_continue_debate(round_record, current_round):
                current_round += 1
                # æ›´æ–°è§‚ç‚¹ç”¨äºä¸‹ä¸€è½®
                bull_initial = bull_response
                bear_initial = bear_response
            else:
                break
        
        # ç”Ÿæˆæœ€ç»ˆå…±è¯†
        final_consensus = self._generate_consensus(debate_history, bull_initial, bear_initial)
        
        return {
            "debate_history": debate_history,
            "final_consensus": final_consensus,
            "total_rounds": current_round,
            "consensus_quality": self._assess_consensus_quality(final_consensus)
        }
    
    def _calculate_consensus(self, bull_view: Dict, bear_view: Dict) -> float:
        """è®¡ç®—å…±è¯†æ°´å¹³"""
        
        # æå–å…³é”®è§‚ç‚¹
        bull_confidence = bull_view.get("confidence", 0.5)
        bear_confidence = bear_view.get("confidence", 0.5)
        
        # è®¡ç®—è§‚ç‚¹å·®å¼‚
        confidence_diff = abs(bull_confidence - bear_confidence)
        
        # å…±è¯†æ°´å¹³ = 1 - è§‚ç‚¹å·®å¼‚
        consensus_level = 1.0 - confidence_diff
        
        return max(0.0, min(1.0, consensus_level))
    
    def _should_continue_debate(self, round_record: Dict, current_round: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­è¾©è®º"""
        
        # è¾¾åˆ°æœ€å¤§è½®æ¬¡
        if current_round >= self.max_rounds:
            return False
        
        # è¾¾æˆè¶³å¤Ÿå…±è¯†
        if round_record["consensus_level"] >= self.consensus_threshold:
            return False
        
        # è§‚ç‚¹åˆ†æ­§ä»ç„¶è¾ƒå¤§ï¼Œç»§ç»­è¾©è®º
        return True
    
    def _generate_consensus(self, debate_history: List[Dict], 
                          final_bull: Dict, final_bear: Dict) -> Dict:
        """ç”Ÿæˆæœ€ç»ˆå…±è¯†"""
        
        # ç»¼åˆåŒæ–¹è§‚ç‚¹
        consensus_points = []
        
        # æå–å…±åŒè®¤å¯çš„è¦ç‚¹
        bull_factors = set(final_bull.get("main_points", []))
        bear_factors = set(final_bear.get("main_points", []))
        
        common_points = bull_factors.intersection(bear_factors)
        consensus_points.extend(list(common_points))
        
        # å¹³è¡¡é£é™©å’Œæœºä¼š
        opportunities = final_bull.get("growth_opportunities", [])
        risks = final_bear.get("risk_factors", [])
        
        # ç”Ÿæˆå¹³è¡¡çš„æŠ•èµ„å»ºè®®
        if len(opportunities) > len(risks):
            recommendation = "è°¨æ…ä¹è§‚"
            confidence = 0.6
        elif len(risks) > len(opportunities):
            recommendation = "è°¨æ…æ‚²è§‚"
            confidence = 0.4
        else:
            recommendation = "ä¸­æ€§è§‚æœ›"
            confidence = 0.5
        
        return {
            "consensus_points": consensus_points,
            "balanced_view": {
                "opportunities": opportunities[:3],  # å‰3ä¸ªæœºä¼š
                "risks": risks[:3],  # å‰3ä¸ªé£é™©
            },
            "recommendation": recommendation,
            "confidence": confidence,
            "key_factors_to_watch": self._identify_key_factors(final_bull, final_bear)
        }
```

### è¾©è®ºè´¨é‡è¯„ä¼°
```python
class DebateQualityAssessor:
    """è¾©è®ºè´¨é‡è¯„ä¼°å™¨"""
    
    def assess_debate_quality(self, debate_result: Dict) -> Dict:
        """è¯„ä¼°è¾©è®ºè´¨é‡"""
        
        quality_metrics = {
            "depth_score": self._assess_depth(debate_result),
            "balance_score": self._assess_balance(debate_result),
            "evidence_quality": self._assess_evidence_quality(debate_result),
            "logical_consistency": self._assess_logical_consistency(debate_result),
            "consensus_quality": self._assess_consensus_quality(debate_result)
        }
        
        overall_quality = sum(quality_metrics.values()) / len(quality_metrics)
        
        return {
            "quality_metrics": quality_metrics,
            "overall_quality": overall_quality,
            "quality_grade": self._assign_quality_grade(overall_quality),
            "improvement_suggestions": self._generate_improvement_suggestions(quality_metrics)
        }
```

ç ”ç©¶å‘˜å›¢é˜Ÿé€šè¿‡ç»“æ„åŒ–çš„è¾©è®ºæœºåˆ¶ï¼Œç¡®ä¿æŠ•èµ„å†³ç­–è€ƒè™‘äº†å¤šä¸ªè§’åº¦å’Œæ½œåœ¨é£é™©ï¼Œæé«˜äº†å†³ç­–çš„è´¨é‡å’Œå¯é æ€§ã€‚


<!-- docs/agents/risk-management.md -->

# é£é™©ç®¡ç†æ™ºèƒ½ä½“

## æ¦‚è¿°

é£é™©ç®¡ç†æ™ºèƒ½ä½“æ˜¯ TradingAgents æ¡†æ¶çš„å®‰å…¨å®ˆæŠ¤è€…ï¼Œè´Ÿè´£è¯†åˆ«ã€è¯„ä¼°å’Œæ§åˆ¶æŠ•èµ„é£é™©ã€‚é€šè¿‡å¤šå±‚æ¬¡çš„é£é™©è¯„ä¼°æœºåˆ¶ï¼Œç¡®ä¿äº¤æ˜“å†³ç­–åœ¨å¯æ¥å—çš„é£é™©èŒƒå›´å†…ï¼Œä¿æŠ¤æŠ•èµ„ç»„åˆå…å—é‡å¤§æŸå¤±ã€‚

## é£é™©ç®¡ç†æ¶æ„

### é£é™©ç®¡ç†ä½“ç³»

```python
class RiskManagementSystem:
    """é£é™©ç®¡ç†ç³»ç»Ÿ - ç»Ÿç­¹æ‰€æœ‰é£é™©ç®¡ç†æ´»åŠ¨"""
    
    def __init__(self, config):
        self.config = config
        self.risk_assessors = self._initialize_risk_assessors()
        self.risk_monitor = RiskMonitor()
        self.risk_controller = RiskController()
        
    def _initialize_risk_assessors(self):
        """åˆå§‹åŒ–é£é™©è¯„ä¼°æ™ºèƒ½ä½“"""
        return {
            "aggressive": AggressiveRiskAssessor(self.config),
            "conservative": ConservativeRiskAssessor(self.config),
            "neutral": NeutralRiskAssessor(self.config)
        }
    
    def assess_trading_risk(self, trading_decision: Dict, market_data: Dict) -> Dict:
        """è¯„ä¼°äº¤æ˜“é£é™©"""
        
        # 1. å¤šè§’åº¦é£é™©è¯„ä¼°
        risk_assessments = {}
        for assessor_type, assessor in self.risk_assessors.items():
            risk_assessments[assessor_type] = assessor.assess_risk(
                trading_decision, market_data
            )
        
        # 2. ç»¼åˆé£é™©è¯„ä¼°
        consolidated_risk = self._consolidate_risk_assessments(risk_assessments)
        
        # 3. é£é™©ç­‰çº§åˆ†ç±»
        risk_classification = self._classify_risk_level(consolidated_risk)
        
        # 4. é£é™©æ§åˆ¶å»ºè®®
        control_recommendations = self._generate_control_recommendations(
            consolidated_risk, risk_classification
        )
        
        return {
            "individual_assessments": risk_assessments,
            "consolidated_risk": consolidated_risk,
            "risk_classification": risk_classification,
            "control_recommendations": control_recommendations,
            "approval_status": self._determine_approval_status(risk_classification)
        }
```

## 1. æ¿€è¿›é£é™©è¯„ä¼°æ™ºèƒ½ä½“

### ç‰¹ç‚¹ä¸èŒè´£
```python
class AggressiveRiskAssessor:
    """æ¿€è¿›é£é™©è¯„ä¼° - æ”¯æŒé«˜é£é™©é«˜æ”¶ç›Šç­–ç•¥"""
    
    def __init__(self, config):
        self.config = config
        self.risk_appetite = "high"
        self.return_focus = "high"
        
    ä¸“ä¸šç‰¹ç‚¹:
    - é«˜é£é™©å®¹å¿åº¦
    - å…³æ³¨æ”¶ç›Šæœ€å¤§åŒ–
    - æ”¯æŒæ æ†ä½¿ç”¨
    - é¼“åŠ±æœºä¼šæŠŠæ¡
    
    è¯„ä¼°é‡ç‚¹:
    - æ”¶ç›Šæ½œåŠ›åˆ†æ
    - æœºä¼šæˆæœ¬è¯„ä¼°
    - å¸‚åœºæ—¶æœºæŠŠæ¡
    - ç«äº‰ä¼˜åŠ¿åˆ©ç”¨
```

### é£é™©è¯„ä¼°æ–¹æ³•
```python
def assess_risk(self, trading_decision: Dict, market_data: Dict) -> Dict:
    """æ¿€è¿›è§’åº¦çš„é£é™©è¯„ä¼°"""
    
    # åŸºç¡€é£é™©æŒ‡æ ‡
    base_risk_metrics = self._calculate_base_risk_metrics(trading_decision, market_data)
    
    # æ¿€è¿›è°ƒæ•´å› å­
    aggressive_adjustments = {
        "volatility_tolerance": 1.5,      # é«˜æ³¢åŠ¨å®¹å¿åº¦
        "drawdown_tolerance": 1.3,        # é«˜å›æ’¤å®¹å¿åº¦
        "leverage_acceptance": 1.2,       # æ¥å—é€‚åº¦æ æ†
        "opportunity_weight": 1.4         # é«˜æœºä¼šæƒé‡
    }
    
    # è°ƒæ•´é£é™©è¯„ä¼°
    adjusted_risk = self._apply_aggressive_adjustments(
        base_risk_metrics, aggressive_adjustments
    )
    
    # æ”¶ç›Šé£é™©æ¯”åˆ†æ
    return_risk_analysis = self._analyze_return_risk_ratio(
        trading_decision, adjusted_risk
    )
    
    # æœºä¼šæˆæœ¬è¯„ä¼°
    opportunity_cost = self._assess_opportunity_cost(trading_decision, market_data)
    
    return {
        "risk_score": adjusted_risk["overall_risk"],
        "return_potential": return_risk_analysis["return_potential"],
        "risk_adjusted_return": return_risk_analysis["risk_adjusted_return"],
        "opportunity_cost": opportunity_cost,
        "recommendation": self._generate_aggressive_recommendation(
            adjusted_risk, return_risk_analysis, opportunity_cost
        ),
        "key_considerations": [
            "é«˜æ”¶ç›Šæ½œåŠ›å€¼å¾—æ‰¿æ‹…ç›¸åº”é£é™©",
            "å¸‚åœºæœºä¼šç¨çºµå³é€ï¼Œåº”æœæ–­è¡ŒåŠ¨",
            "é€‚åº¦é£é™©æ˜¯è·å¾—è¶…é¢æ”¶ç›Šçš„å¿…è¦æ¡ä»¶",
            "é£é™©å¯é€šè¿‡ä¸»åŠ¨ç®¡ç†å¾—åˆ°æ§åˆ¶"
        ]
    }

def _analyze_return_risk_ratio(self, decision: Dict, risk_metrics: Dict) -> Dict:
    """åˆ†ææ”¶ç›Šé£é™©æ¯”"""
    
    expected_return = decision.get("take_profit", 0.1)
    risk_level = risk_metrics.get("overall_risk", 0.5)
    
    # æ¿€è¿›è§†è§’ä¸‹çš„æ”¶ç›Šé£é™©æ¯”è®¡ç®—
    # æ›´çœ‹é‡æ”¶ç›Šæ½œåŠ›ï¼Œå¯¹é£é™©ç›¸å¯¹å®½å®¹
    risk_adjusted_return = expected_return / max(risk_level * 0.8, 0.1)
    
    return_potential_score = min(expected_return * 10, 1.0)  # æ”¶ç›Šæ½œåŠ›è¯„åˆ†
    
    return {
        "return_potential": return_potential_score,
        "risk_adjusted_return": risk_adjusted_return,
        "return_risk_ratio": expected_return / max(risk_level, 0.1),
        "attractiveness": "é«˜" if risk_adjusted_return > 1.5 else "ä¸­" if risk_adjusted_return > 1.0 else "ä½"
    }

def _assess_opportunity_cost(self, decision: Dict, market_data: Dict) -> Dict:
    """è¯„ä¼°æœºä¼šæˆæœ¬"""
    
    # ä¸è¡ŒåŠ¨çš„æœºä¼šæˆæœ¬
    inaction_cost = self._calculate_inaction_cost(decision, market_data)
    
    # å»¶è¿Ÿè¡ŒåŠ¨çš„æˆæœ¬
    delay_cost = self._calculate_delay_cost(decision, market_data)
    
    # ä¿å®ˆç­–ç•¥çš„æœºä¼šæˆæœ¬
    conservative_cost = self._calculate_conservative_cost(decision)
    
    total_opportunity_cost = inaction_cost + delay_cost + conservative_cost
    
    return {
        "inaction_cost": inaction_cost,
        "delay_cost": delay_cost,
        "conservative_cost": conservative_cost,
        "total_cost": total_opportunity_cost,
        "urgency_level": "é«˜" if total_opportunity_cost > 0.1 else "ä¸­" if total_opportunity_cost > 0.05 else "ä½"
    }
```

## 2. ä¿å®ˆé£é™©è¯„ä¼°æ™ºèƒ½ä½“

### ç‰¹ç‚¹ä¸èŒè´£
```python
class ConservativeRiskAssessor:
    """ä¿å®ˆé£é™©è¯„ä¼° - å¼ºè°ƒé£é™©æ§åˆ¶å’Œèµ„æœ¬ä¿æŠ¤"""
    
    def __init__(self, config):
        self.config = config
        self.risk_appetite = "low"
        self.capital_preservation_focus = True
        
    ä¸“ä¸šç‰¹ç‚¹:
    - ä½é£é™©å®¹å¿åº¦
    - å¼ºè°ƒèµ„æœ¬ä¿æŠ¤
    - è°¨æ…çš„ä»“ä½ç®¡ç†
    - ä¸¥æ ¼çš„é£é™©æ§åˆ¶
    
    è¯„ä¼°é‡ç‚¹:
    - ä¸‹è¡Œé£é™©ä¿æŠ¤
    - æœ€å¤§å›æ’¤æ§åˆ¶
    - æµåŠ¨æ€§é£é™©ç®¡ç†
    - å°¾éƒ¨é£é™©é˜²èŒƒ
```

### é£é™©è¯„ä¼°æ–¹æ³•
```python
def assess_risk(self, trading_decision: Dict, market_data: Dict) -> Dict:
    """ä¿å®ˆè§’åº¦çš„é£é™©è¯„ä¼°"""
    
    # åŸºç¡€é£é™©æŒ‡æ ‡
    base_risk_metrics = self._calculate_base_risk_metrics(trading_decision, market_data)
    
    # ä¿å®ˆè°ƒæ•´å› å­
    conservative_adjustments = {
        "volatility_penalty": 1.5,        # é«˜æ³¢åŠ¨æƒ©ç½š
        "drawdown_penalty": 1.8,          # é«˜å›æ’¤æƒ©ç½š
        "liquidity_requirement": 1.3,     # é«˜æµåŠ¨æ€§è¦æ±‚
        "safety_margin": 1.4              # é«˜å®‰å…¨è¾¹é™…
    }
    
    # è°ƒæ•´é£é™©è¯„ä¼°
    adjusted_risk = self._apply_conservative_adjustments(
        base_risk_metrics, conservative_adjustments
    )
    
    # ä¸‹è¡Œé£é™©åˆ†æ
    downside_risk = self._analyze_downside_risk(trading_decision, market_data)
    
    # å°¾éƒ¨é£é™©è¯„ä¼°
    tail_risk = self._assess_tail_risk(trading_decision, market_data)
    
    # æµåŠ¨æ€§é£é™©è¯„ä¼°
    liquidity_risk = self._assess_liquidity_risk(trading_decision, market_data)
    
    return {
        "risk_score": adjusted_risk["overall_risk"],
        "downside_risk": downside_risk,
        "tail_risk": tail_risk,
        "liquidity_risk": liquidity_risk,
        "capital_at_risk": self._calculate_capital_at_risk(adjusted_risk),
        "recommendation": self._generate_conservative_recommendation(
            adjusted_risk, downside_risk, tail_risk
        ),
        "risk_mitigation_measures": [
            "ä¸¥æ ¼è®¾ç½®æ­¢æŸä½ï¼Œæ§åˆ¶æœ€å¤§æŸå¤±",
            "åˆ†æ•£æŠ•èµ„ï¼Œé™ä½å•ä¸€èµ„äº§é£é™©",
            "ä¿æŒå……è¶³ç°é‡‘å‚¨å¤‡",
            "å®šæœŸé‡æ–°è¯„ä¼°é£é™©çŠ¶å†µ",
            "é¿å…è¿‡åº¦é›†ä¸­å’Œæ æ†"
        ]
    }

def _analyze_downside_risk(self, decision: Dict, market_data: Dict) -> Dict:
    """åˆ†æä¸‹è¡Œé£é™©"""
    
    stop_loss = decision.get("stop_loss", 0.05)
    position_size = decision.get("quantity", 0.05)
    
    # æœ€å¤§å¯èƒ½æŸå¤±
    max_loss = stop_loss * position_size
    
    # ä¸‹è¡Œæ³¢åŠ¨ç‡
    downside_volatility = market_data.get("downside_volatility", 0.2)
    
    # VaR è®¡ç®— (95% ç½®ä¿¡åº¦)
    var_95 = position_size * downside_volatility * 1.65  # 95% VaR
    
    # CVaR è®¡ç®— (æ¡ä»¶é£é™©ä»·å€¼)
    cvar_95 = var_95 * 1.3  # ä¼°ç®— CVaR
    
    return {
        "max_loss": max_loss,
        "var_95": var_95,
        "cvar_95": cvar_95,
        "downside_volatility": downside_volatility,
        "risk_level": "é«˜" if max_loss > 0.02 else "ä¸­" if max_loss > 0.01 else "ä½"
    }

def _assess_tail_risk(self, decision: Dict, market_data: Dict) -> Dict:
    """è¯„ä¼°å°¾éƒ¨é£é™©"""
    
    # æç«¯å¸‚åœºæƒ…å†µä¸‹çš„é£é™©
    market_stress_scenarios = {
        "market_crash": {"probability": 0.05, "impact": -0.3},
        "liquidity_crisis": {"probability": 0.03, "impact": -0.2},
        "sector_collapse": {"probability": 0.08, "impact": -0.25},
        "black_swan": {"probability": 0.01, "impact": -0.5}
    }
    
    position_size = decision.get("quantity", 0.05)
    
    tail_risk_exposure = 0
    scenario_impacts = {}
    
    for scenario, params in market_stress_scenarios.items():
        scenario_loss = position_size * abs(params["impact"])
        expected_loss = scenario_loss * params["probability"]
        tail_risk_exposure += expected_loss
        
        scenario_impacts[scenario] = {
            "potential_loss": scenario_loss,
            "expected_loss": expected_loss,
            "probability": params["probability"]
        }
    
    return {
        "total_tail_risk": tail_risk_exposure,
        "scenario_impacts": scenario_impacts,
        "tail_risk_level": "é«˜" if tail_risk_exposure > 0.01 else "ä¸­" if tail_risk_exposure > 0.005 else "ä½",
        "mitigation_priority": "é«˜" if tail_risk_exposure > 0.01 else "ä¸­"
    }
```

## 3. ä¸­æ€§é£é™©è¯„ä¼°æ™ºèƒ½ä½“

### ç‰¹ç‚¹ä¸èŒè´£
```python
class NeutralRiskAssessor:
    """ä¸­æ€§é£é™©è¯„ä¼° - å¹³è¡¡é£é™©å’Œæ”¶ç›Š"""
    
    def __init__(self, config):
        self.config = config
        self.risk_appetite = "medium"
        self.balanced_approach = True
        
    ä¸“ä¸šç‰¹ç‚¹:
    - å¹³è¡¡çš„é£é™©è§‚
    - ç†æ€§çš„æ”¶ç›Šé¢„æœŸ
    - é€‚åº¦çš„é£é™©æ‰¿æ‹…
    - å…¨é¢çš„é£é™©è€ƒé‡
    
    è¯„ä¼°é‡ç‚¹:
    - é£é™©æ”¶ç›Šå¹³è¡¡
    - å¤šç»´åº¦é£é™©åˆ†æ
    - æƒ…æ™¯åˆ†æ
    - æ¦‚ç‡åŠ æƒè¯„ä¼°
```

### é£é™©è¯„ä¼°æ–¹æ³•
```python
def assess_risk(self, trading_decision: Dict, market_data: Dict) -> Dict:
    """ä¸­æ€§è§’åº¦çš„é£é™©è¯„ä¼°"""
    
    # å…¨é¢é£é™©åˆ†æ
    comprehensive_risk = self._conduct_comprehensive_risk_analysis(
        trading_decision, market_data
    )
    
    # æƒ…æ™¯åˆ†æ
    scenario_analysis = self._conduct_scenario_analysis(trading_decision, market_data)
    
    # é£é™©æ”¶ç›Šå¹³è¡¡è¯„ä¼°
    risk_return_balance = self._assess_risk_return_balance(
        trading_decision, comprehensive_risk
    )
    
    # æ¦‚ç‡åŠ æƒé£é™©è¯„ä¼°
    probability_weighted_risk = self._calculate_probability_weighted_risk(
        scenario_analysis
    )
    
    return {
        "comprehensive_risk": comprehensive_risk,
        "scenario_analysis": scenario_analysis,
        "risk_return_balance": risk_return_balance,
        "probability_weighted_risk": probability_weighted_risk,
        "overall_assessment": self._generate_balanced_assessment(
            comprehensive_risk, scenario_analysis, risk_return_balance
        ),
        "balanced_recommendation": self._generate_balanced_recommendation(
            comprehensive_risk, risk_return_balance
        )
    }

def _conduct_scenario_analysis(self, decision: Dict, market_data: Dict) -> Dict:
    """è¿›è¡Œæƒ…æ™¯åˆ†æ"""
    
    scenarios = {
        "bull_case": {"probability": 0.3, "return": 0.15, "risk": 0.1},
        "base_case": {"probability": 0.4, "return": 0.08, "risk": 0.15},
        "bear_case": {"probability": 0.3, "return": -0.05, "risk": 0.25}
    }
    
    position_size = decision.get("quantity", 0.05)
    
    scenario_outcomes = {}
    expected_return = 0
    expected_risk = 0
    
    for scenario_name, params in scenarios.items():
        scenario_return = params["return"] * position_size
        scenario_risk = params["risk"] * position_size
        probability = params["probability"]
        
        expected_return += scenario_return * probability
        expected_risk += scenario_risk * probability
        
        scenario_outcomes[scenario_name] = {
            "return": scenario_return,
            "risk": scenario_risk,
            "probability": probability,
            "risk_adjusted_return": scenario_return / max(scenario_risk, 0.01)
        }
    
    return {
        "scenarios": scenario_outcomes,
        "expected_return": expected_return,
        "expected_risk": expected_risk,
        "risk_return_ratio": expected_return / max(expected_risk, 0.01),
        "scenario_dispersion": self._calculate_scenario_dispersion(scenario_outcomes)
    }

def _assess_risk_return_balance(self, decision: Dict, risk_metrics: Dict) -> Dict:
    """è¯„ä¼°é£é™©æ”¶ç›Šå¹³è¡¡"""
    
    expected_return = decision.get("take_profit", 0.1)
    expected_risk = risk_metrics.get("overall_risk", 0.5)
    
    # å¤æ™®æ¯”ç‡ä¼°ç®—
    risk_free_rate = 0.02  # å‡è®¾æ— é£é™©åˆ©ç‡
    excess_return = expected_return - risk_free_rate
    sharpe_ratio = excess_return / max(expected_risk, 0.01)
    
    # é£é™©è°ƒæ•´åæ”¶ç›Š
    risk_adjusted_return = expected_return / max(expected_risk, 0.01)
    
    # å¹³è¡¡è¯„åˆ†
    balance_score = self._calculate_balance_score(sharpe_ratio, risk_adjusted_return)
    
    return {
        "sharpe_ratio": sharpe_ratio,
        "risk_adjusted_return": risk_adjusted_return,
        "balance_score": balance_score,
        "balance_assessment": self._assess_balance_quality(balance_score),
        "optimization_suggestions": self._suggest_balance_optimization(
            expected_return, expected_risk, balance_score
        )
    }
```

## 4. é£é™©ç®¡ç†å†³ç­–

### é£é™©å†³ç­–æ¡†æ¶
```python
class RiskDecisionFramework:
    """é£é™©å†³ç­–æ¡†æ¶"""
    
    def make_risk_decision(self, risk_assessments: Dict, trading_decision: Dict) -> Dict:
        """åˆ¶å®šé£é™©ç®¡ç†å†³ç­–"""
        
        # 1. é£é™©å…±è¯†åˆ†æ
        risk_consensus = self._analyze_risk_consensus(risk_assessments)
        
        # 2. é£é™©ç­‰çº§ç¡®å®š
        final_risk_level = self._determine_final_risk_level(risk_assessments, risk_consensus)
        
        # 3. å†³ç­–å»ºè®®ç”Ÿæˆ
        decision_recommendation = self._generate_decision_recommendation(
            final_risk_level, risk_consensus, trading_decision
        )
        
        # 4. é£é™©æ§åˆ¶æªæ–½
        risk_controls = self._design_risk_controls(final_risk_level, trading_decision)
        
        # 5. ç›‘æ§è¦æ±‚
        monitoring_requirements = self._define_monitoring_requirements(
            final_risk_level, trading_decision
        )
        
        return {
            "risk_consensus": risk_consensus,
            "final_risk_level": final_risk_level,
            "decision": decision_recommendation,
            "risk_controls": risk_controls,
            "monitoring": monitoring_requirements,
            "approval_status": self._determine_final_approval(decision_recommendation)
        }
    
    def _analyze_risk_consensus(self, assessments: Dict) -> Dict:
        """åˆ†æé£é™©è¯„ä¼°å…±è¯†"""
        
        risk_scores = [
            assessments["aggressive"]["risk_score"],
            assessments["conservative"]["risk_score"],
            assessments["neutral"]["comprehensive_risk"]["overall_risk"]
        ]
        
        # è®¡ç®—å…±è¯†æŒ‡æ ‡
        avg_risk = sum(risk_scores) / len(risk_scores)
        risk_std = np.std(risk_scores)
        consensus_level = 1.0 - min(risk_std / avg_risk, 1.0) if avg_risk > 0 else 0.0
        
        # åˆ†æåˆ†æ­§ç‚¹
        disagreement_areas = self._identify_disagreement_areas(assessments)
        
        return {
            "average_risk_score": avg_risk,
            "risk_score_std": risk_std,
            "consensus_level": consensus_level,
            "disagreement_areas": disagreement_areas,
            "consensus_quality": "é«˜" if consensus_level > 0.8 else "ä¸­" if consensus_level > 0.6 else "ä½"
        }
    
    def _generate_decision_recommendation(self, risk_level: str, consensus: Dict, decision: Dict) -> Dict:
        """ç”Ÿæˆå†³ç­–å»ºè®®"""
        
        consensus_level = consensus["consensus_level"]
        avg_risk = consensus["average_risk_score"]
        
        if risk_level == "low" and consensus_level > 0.7:
            recommendation = "approve"
            confidence = 0.9
        elif risk_level == "medium" and consensus_level > 0.6:
            recommendation = "approve_with_conditions"
            confidence = 0.7
        elif risk_level == "high" and consensus_level > 0.8:
            recommendation = "approve_with_strict_controls"
            confidence = 0.6
        else:
            recommendation = "reject"
            confidence = 0.8
        
        return {
            "recommendation": recommendation,
            "confidence": confidence,
            "reasoning": self._explain_recommendation_reasoning(
                risk_level, consensus_level, avg_risk, recommendation
            ),
            "conditions": self._define_approval_conditions(recommendation, risk_level)
        }
```

### é£é™©ç›‘æ§ç³»ç»Ÿ
```python
class RiskMonitor:
    """é£é™©ç›‘æ§ç³»ç»Ÿ"""
    
    def __init__(self):
        self.active_positions = {}
        self.risk_alerts = []
        self.monitoring_rules = self._setup_monitoring_rules()
    
    def monitor_position_risk(self, position_id: str, current_data: Dict) -> Dict:
        """ç›‘æ§ä»“ä½é£é™©"""
        
        position = self.active_positions.get(position_id)
        if not position:
            return {"status": "position_not_found"}
        
        # å®æ—¶é£é™©è®¡ç®—
        current_risk = self._calculate_current_risk(position, current_data)
        
        # é£é™©é˜ˆå€¼æ£€æŸ¥
        risk_alerts = self._check_risk_thresholds(position, current_risk)
        
        # æ­¢æŸæ­¢ç›ˆæ£€æŸ¥
        exit_signals = self._check_exit_conditions(position, current_data)
        
        # æ›´æ–°ç›‘æ§çŠ¶æ€
        monitoring_status = self._update_monitoring_status(
            position, current_risk, risk_alerts, exit_signals
        )
        
        return {
            "position_id": position_id,
            "current_risk": current_risk,
            "risk_alerts": risk_alerts,
            "exit_signals": exit_signals,
            "monitoring_status": monitoring_status,
            "recommended_actions": self._recommend_risk_actions(
                current_risk, risk_alerts, exit_signals
            )
        }
```

é£é™©ç®¡ç†æ™ºèƒ½ä½“é€šè¿‡å¤šè§’åº¦è¯„ä¼°ã€ä¸¥æ ¼æ§åˆ¶å’ŒæŒç»­ç›‘æ§ï¼Œç¡®ä¿äº¤æ˜“æ´»åŠ¨åœ¨å¯æ§çš„é£é™©èŒƒå›´å†…è¿›è¡Œï¼Œä¿æŠ¤æŠ•èµ„ç»„åˆçš„å®‰å…¨ã€‚


<!-- docs/agents/trader.md -->

# äº¤æ˜“å‘˜æ™ºèƒ½ä½“

## æ¦‚è¿°

äº¤æ˜“å‘˜æ™ºèƒ½ä½“æ˜¯ TradingAgents æ¡†æ¶çš„æ ¸å¿ƒå†³ç­–ç»„ä»¶ï¼Œè´Ÿè´£ç»¼åˆåˆ†æå¸ˆæŠ¥å‘Šå’Œç ”ç©¶å‘˜è¾©è®ºç»“æœï¼Œåˆ¶å®šæœ€ç»ˆçš„äº¤æ˜“å†³ç­–ã€‚äº¤æ˜“å‘˜æ™ºèƒ½ä½“å…·å¤‡ä¸“ä¸šçš„äº¤æ˜“çŸ¥è¯†å’Œé£é™©æ„è¯†ï¼Œèƒ½å¤Ÿåœ¨å¤æ‚çš„å¸‚åœºç¯å¢ƒä¸­åšå‡ºæ˜æ™ºçš„æŠ•èµ„å†³ç­–ã€‚

## äº¤æ˜“å‘˜æ¶æ„

### åŸºç¡€äº¤æ˜“å‘˜ç±»

```python
class Trader:
    """äº¤æ˜“å‘˜æ™ºèƒ½ä½“ - è´Ÿè´£æœ€ç»ˆäº¤æ˜“å†³ç­–"""
    
    def __init__(self, llm, config):
        self.llm = llm
        self.config = config
        self.trading_style = config.get("trading_style", "balanced")
        self.risk_tolerance = config.get("risk_tolerance", "medium")
        self.memory = TradingMemory()
        self.position_manager = PositionManager()
        
    def make_decision(self, analysis_data: Dict) -> Dict:
        """åˆ¶å®šäº¤æ˜“å†³ç­–"""
        
        # 1. ç»¼åˆåˆ†ææ‰€æœ‰è¾“å…¥
        comprehensive_analysis = self.synthesize_analysis(analysis_data)
        
        # 2. è¯„ä¼°å¸‚åœºæ¡ä»¶
        market_assessment = self.assess_market_conditions(analysis_data)
        
        # 3. åˆ¶å®šäº¤æ˜“ç­–ç•¥
        trading_strategy = self.develop_trading_strategy(
            comprehensive_analysis, market_assessment
        )
        
        # 4. ç¡®å®šä»“ä½å¤§å°
        position_size = self.calculate_position_size(trading_strategy)
        
        # 5. è®¾ç½®é£é™©ç®¡ç†å‚æ•°
        risk_parameters = self.set_risk_parameters(trading_strategy)
        
        # 6. ç”Ÿæˆæœ€ç»ˆå†³ç­–
        final_decision = self.generate_final_decision(
            trading_strategy, position_size, risk_parameters
        )
        
        # 7. æ›´æ–°äº¤æ˜“è®°å¿†
        self.memory.update_decision(final_decision)
        
        return final_decision
```

## æ ¸å¿ƒåŠŸèƒ½æ¨¡å—

### 1. åˆ†æç»¼åˆæ¨¡å—

```python
def synthesize_analysis(self, analysis_data: Dict) -> Dict:
    """ç»¼åˆåˆ†ææ‰€æœ‰è¾“å…¥æ•°æ®"""
    
    # æå–å„ç±»åˆ†æç»“æœ
    analyst_reports = analysis_data.get("analyst_reports", {})
    research_consensus = analysis_data.get("research_consensus", {})
    market_data = analysis_data.get("market_data", {})
    
    # åˆ†æå¸ˆæŠ¥å‘Šæƒé‡
    analyst_weights = self.config.get("analyst_weights", {
        "fundamentals": 0.3,
        "technical": 0.3,
        "news": 0.2,
        "social": 0.2
    })
    
    # è®¡ç®—åŠ æƒåˆ†æè¯„åˆ†
    weighted_scores = {}
    total_score = 0
    
    for analyst_type, weight in analyst_weights.items():
        if analyst_type in analyst_reports:
            score = analyst_reports[analyst_type].get("overall_score", 0.5)
            weighted_scores[analyst_type] = score * weight
            total_score += weighted_scores[analyst_type]
    
    # ç ”ç©¶å‘˜å…±è¯†å½±å“
    consensus_impact = self._assess_consensus_impact(research_consensus)
    
    # ç»¼åˆè¯„ä¼°
    synthesis = {
        "analyst_scores": weighted_scores,
        "total_analyst_score": total_score,
        "consensus_impact": consensus_impact,
        "adjusted_score": self._adjust_score_with_consensus(total_score, consensus_impact),
        "confidence_level": self._calculate_overall_confidence(analyst_reports, research_consensus),
        "key_factors": self._extract_key_factors(analyst_reports, research_consensus)
    }
    
    return synthesis

def _assess_consensus_impact(self, research_consensus: Dict) -> Dict:
    """è¯„ä¼°ç ”ç©¶å‘˜å…±è¯†çš„å½±å“"""
    
    consensus_strength = research_consensus.get("consensus_level", 0.5)
    recommendation = research_consensus.get("recommendation", "neutral")
    
    # å…±è¯†å¼ºåº¦å½±å“æƒé‡
    if consensus_strength > 0.8:
        impact_weight = 0.3  # é«˜å…±è¯†ï¼Œé«˜å½±å“
    elif consensus_strength > 0.6:
        impact_weight = 0.2  # ä¸­ç­‰å…±è¯†ï¼Œä¸­ç­‰å½±å“
    else:
        impact_weight = 0.1  # ä½å…±è¯†ï¼Œä½å½±å“
    
    # æ¨èæ–¹å‘å½±å“
    direction_impact = {
        "è°¨æ…ä¹è§‚": 0.15,
        "è°¨æ…æ‚²è§‚": -0.15,
        "ä¸­æ€§è§‚æœ›": 0.0
    }.get(recommendation, 0.0)
    
    return {
        "strength": consensus_strength,
        "weight": impact_weight,
        "direction": direction_impact,
        "net_impact": direction_impact * impact_weight
    }
```

### 2. å¸‚åœºæ¡ä»¶è¯„ä¼°

```python
def assess_market_conditions(self, analysis_data: Dict) -> Dict:
    """è¯„ä¼°å½“å‰å¸‚åœºæ¡ä»¶"""
    
    market_indicators = {
        "volatility": self._assess_volatility(analysis_data),
        "liquidity": self._assess_liquidity(analysis_data),
        "sentiment": self._assess_market_sentiment(analysis_data),
        "trend": self._assess_market_trend(analysis_data),
        "correlation": self._assess_market_correlation(analysis_data)
    }
    
    # å¸‚åœºç¯å¢ƒåˆ†ç±»
    market_regime = self._classify_market_regime(market_indicators)
    
    # äº¤æ˜“é€‚å®œæ€§è¯„ä¼°
    trading_suitability = self._assess_trading_suitability(market_indicators)
    
    return {
        "indicators": market_indicators,
        "regime": market_regime,
        "suitability": trading_suitability,
        "risk_level": self._calculate_market_risk_level(market_indicators)
    }

def _classify_market_regime(self, indicators: Dict) -> str:
    """åˆ†ç±»å¸‚åœºç¯å¢ƒ"""
    
    volatility = indicators["volatility"]["level"]
    trend = indicators["trend"]["direction"]
    sentiment = indicators["sentiment"]["score"]
    
    if volatility == "low" and trend == "uptrend" and sentiment > 0.6:
        return "bull_market"
    elif volatility == "high" and trend == "downtrend" and sentiment < 0.4:
        return "bear_market"
    elif volatility == "high":
        return "volatile_market"
    else:
        return "sideways_market"

def _assess_trading_suitability(self, indicators: Dict) -> Dict:
    """è¯„ä¼°äº¤æ˜“é€‚å®œæ€§"""
    
    suitability_score = 0.5
    factors = []
    
    # æ³¢åŠ¨æ€§å½±å“
    if indicators["volatility"]["level"] == "low":
        suitability_score += 0.1
        factors.append("ä½æ³¢åŠ¨æ€§æœ‰åˆ©äºäº¤æ˜“")
    elif indicators["volatility"]["level"] == "high":
        suitability_score -= 0.1
        factors.append("é«˜æ³¢åŠ¨æ€§å¢åŠ äº¤æ˜“é£é™©")
    
    # æµåŠ¨æ€§å½±å“
    if indicators["liquidity"]["level"] == "high":
        suitability_score += 0.1
        factors.append("é«˜æµåŠ¨æ€§ä¾¿äºè¿›å‡º")
    
    # è¶‹åŠ¿æ˜ç¡®æ€§å½±å“
    if indicators["trend"]["strength"] > 0.7:
        suitability_score += 0.1
        factors.append("è¶‹åŠ¿æ˜ç¡®æœ‰åˆ©äºäº¤æ˜“")
    
    return {
        "score": max(0.0, min(1.0, suitability_score)),
        "factors": factors,
        "recommendation": "é€‚å®œ" if suitability_score > 0.6 else "è°¨æ…" if suitability_score > 0.4 else "ä¸é€‚å®œ"
    }
```

### 3. äº¤æ˜“ç­–ç•¥åˆ¶å®š

```python
def develop_trading_strategy(self, analysis: Dict, market_conditions: Dict) -> Dict:
    """åˆ¶å®šäº¤æ˜“ç­–ç•¥"""
    
    # åŸºäºåˆ†æç»“æœç¡®å®šåŸºæœ¬æ–¹å‘
    base_signal = self._determine_base_signal(analysis)
    
    # æ ¹æ®å¸‚åœºæ¡ä»¶è°ƒæ•´ç­–ç•¥
    adjusted_strategy = self._adjust_for_market_conditions(base_signal, market_conditions)
    
    # é€‰æ‹©äº¤æ˜“ç±»å‹
    trade_type = self._select_trade_type(adjusted_strategy, market_conditions)
    
    # è®¾å®šæ—¶é—´æ¡†æ¶
    time_horizon = self._determine_time_horizon(adjusted_strategy, market_conditions)
    
    # åˆ¶å®šè¿›å‡ºåœºç­–ç•¥
    entry_exit_strategy = self._develop_entry_exit_strategy(adjusted_strategy)
    
    return {
        "base_signal": base_signal,
        "adjusted_signal": adjusted_strategy,
        "trade_type": trade_type,
        "time_horizon": time_horizon,
        "entry_strategy": entry_exit_strategy["entry"],
        "exit_strategy": entry_exit_strategy["exit"],
        "confidence": self._calculate_strategy_confidence(analysis, market_conditions)
    }

def _determine_base_signal(self, analysis: Dict) -> Dict:
    """ç¡®å®šåŸºæœ¬äº¤æ˜“ä¿¡å·"""
    
    adjusted_score = analysis.get("adjusted_score", 0.5)
    confidence = analysis.get("confidence_level", 0.5)
    
    # ä¿¡å·å¼ºåº¦é˜ˆå€¼
    strong_buy_threshold = 0.7
    buy_threshold = 0.6
    sell_threshold = 0.4
    strong_sell_threshold = 0.3
    
    if adjusted_score >= strong_buy_threshold and confidence > 0.7:
        signal = "strong_buy"
    elif adjusted_score >= buy_threshold:
        signal = "buy"
    elif adjusted_score <= strong_sell_threshold and confidence > 0.7:
        signal = "strong_sell"
    elif adjusted_score <= sell_threshold:
        signal = "sell"
    else:
        signal = "hold"
    
    return {
        "action": signal,
        "strength": abs(adjusted_score - 0.5) * 2,  # 0-1 scale
        "confidence": confidence,
        "score": adjusted_score
    }

def _select_trade_type(self, strategy: Dict, market_conditions: Dict) -> str:
    """é€‰æ‹©äº¤æ˜“ç±»å‹"""
    
    signal_strength = strategy.get("strength", 0.5)
    market_regime = market_conditions.get("regime", "sideways_market")
    volatility = market_conditions["indicators"]["volatility"]["level"]
    
    # æ ¹æ®ä¿¡å·å¼ºåº¦å’Œå¸‚åœºæ¡ä»¶é€‰æ‹©äº¤æ˜“ç±»å‹
    if signal_strength > 0.8 and market_regime in ["bull_market", "bear_market"]:
        return "momentum_trade"  # åŠ¨é‡äº¤æ˜“
    elif signal_strength > 0.6 and volatility == "low":
        return "swing_trade"     # æ³¢æ®µäº¤æ˜“
    elif market_regime == "sideways_market":
        return "range_trade"     # åŒºé—´äº¤æ˜“
    else:
        return "position_trade"  # ä»“ä½äº¤æ˜“
```

### 4. ä»“ä½ç®¡ç†

```python
def calculate_position_size(self, strategy: Dict) -> Dict:
    """è®¡ç®—ä»“ä½å¤§å°"""
    
    # åŸºç¡€ä»“ä½å¤§å° (åŸºäºä¿¡å·å¼ºåº¦)
    signal_strength = strategy.get("strength", 0.5)
    base_position = signal_strength * self.config.get("max_position_size", 0.1)
    
    # é£é™©è°ƒæ•´
    risk_adjustment = self._calculate_risk_adjustment(strategy)
    
    # å¸‚åœºæ¡ä»¶è°ƒæ•´
    market_adjustment = self._calculate_market_adjustment(strategy)
    
    # æœ€ç»ˆä»“ä½å¤§å°
    final_position = base_position * risk_adjustment * market_adjustment
    
    # ç¡®ä¿åœ¨é™åˆ¶èŒƒå›´å†…
    max_position = self.config.get("max_position_size", 0.1)
    min_position = self.config.get("min_position_size", 0.01)
    
    final_position = max(min_position, min(max_position, final_position))
    
    return {
        "base_size": base_position,
        "risk_adjustment": risk_adjustment,
        "market_adjustment": market_adjustment,
        "final_size": final_position,
        "size_rationale": self._explain_position_sizing(
            base_position, risk_adjustment, market_adjustment
        )
    }

def _calculate_risk_adjustment(self, strategy: Dict) -> float:
    """è®¡ç®—é£é™©è°ƒæ•´ç³»æ•°"""
    
    confidence = strategy.get("confidence", 0.5)
    trade_type = strategy.get("trade_type", "position_trade")
    
    # åŸºäºç½®ä¿¡åº¦çš„è°ƒæ•´
    confidence_adjustment = 0.5 + (confidence - 0.5)
    
    # åŸºäºäº¤æ˜“ç±»å‹çš„è°ƒæ•´
    type_adjustments = {
        "momentum_trade": 1.2,    # åŠ¨é‡äº¤æ˜“å¯ä»¥ç¨å¤§ä»“ä½
        "swing_trade": 1.0,       # æ³¢æ®µäº¤æ˜“æ ‡å‡†ä»“ä½
        "range_trade": 0.8,       # åŒºé—´äº¤æ˜“è¾ƒå°ä»“ä½
        "position_trade": 0.9     # ä»“ä½äº¤æ˜“ä¸­ç­‰ä»“ä½
    }
    
    type_adjustment = type_adjustments.get(trade_type, 1.0)
    
    return confidence_adjustment * type_adjustment
```

### 5. é£é™©ç®¡ç†å‚æ•°

```python
def set_risk_parameters(self, strategy: Dict) -> Dict:
    """è®¾ç½®é£é™©ç®¡ç†å‚æ•°"""
    
    trade_type = strategy.get("trade_type", "position_trade")
    signal_strength = strategy.get("strength", 0.5)
    time_horizon = strategy.get("time_horizon", "medium")
    
    # æ­¢æŸè®¾ç½®
    stop_loss = self._calculate_stop_loss(trade_type, signal_strength)
    
    # æ­¢ç›ˆè®¾ç½®
    take_profit = self._calculate_take_profit(trade_type, signal_strength)
    
    # é£é™©æ”¶ç›Šæ¯”
    risk_reward_ratio = take_profit / stop_loss if stop_loss > 0 else 0
    
    # æœ€å¤§æŒæœ‰æ—¶é—´
    max_holding_period = self._determine_max_holding_period(time_horizon)
    
    return {
        "stop_loss": stop_loss,
        "take_profit": take_profit,
        "risk_reward_ratio": risk_reward_ratio,
        "max_holding_period": max_holding_period,
        "position_monitoring": self._setup_position_monitoring(strategy),
        "exit_conditions": self._define_exit_conditions(strategy)
    }

def _calculate_stop_loss(self, trade_type: str, signal_strength: float) -> float:
    """è®¡ç®—æ­¢æŸæ°´å¹³"""
    
    base_stop_loss = {
        "momentum_trade": 0.03,   # 3% æ­¢æŸ
        "swing_trade": 0.05,      # 5% æ­¢æŸ
        "range_trade": 0.02,      # 2% æ­¢æŸ
        "position_trade": 0.08    # 8% æ­¢æŸ
    }.get(trade_type, 0.05)
    
    # æ ¹æ®ä¿¡å·å¼ºåº¦è°ƒæ•´
    # ä¿¡å·è¶Šå¼ºï¼Œå¯ä»¥å®¹å¿æ›´å¤§çš„å›æ’¤
    strength_adjustment = 1.0 + (signal_strength - 0.5) * 0.5
    
    return base_stop_loss * strength_adjustment

def _calculate_take_profit(self, trade_type: str, signal_strength: float) -> float:
    """è®¡ç®—æ­¢ç›ˆæ°´å¹³"""
    
    base_take_profit = {
        "momentum_trade": 0.08,   # 8% æ­¢ç›ˆ
        "swing_trade": 0.12,      # 12% æ­¢ç›ˆ
        "range_trade": 0.04,      # 4% æ­¢ç›ˆ
        "position_trade": 0.20    # 20% æ­¢ç›ˆ
    }.get(trade_type, 0.10)
    
    # æ ¹æ®ä¿¡å·å¼ºåº¦è°ƒæ•´
    strength_adjustment = 1.0 + signal_strength * 0.5
    
    return base_take_profit * strength_adjustment
```

### 6. æœ€ç»ˆå†³ç­–ç”Ÿæˆ

```python
def generate_final_decision(self, strategy: Dict, position: Dict, risk_params: Dict) -> Dict:
    """ç”Ÿæˆæœ€ç»ˆäº¤æ˜“å†³ç­–"""
    
    action = strategy["adjusted_signal"]["action"]
    
    # æ„å»ºå†³ç­–ç»“æ„
    decision = {
        "action": action,
        "quantity": position["final_size"],
        "confidence": strategy["confidence"],
        "strategy_type": strategy["trade_type"],
        "time_horizon": strategy["time_horizon"],
        
        # é£é™©ç®¡ç†
        "stop_loss": risk_params["stop_loss"],
        "take_profit": risk_params["take_profit"],
        "risk_reward_ratio": risk_params["risk_reward_ratio"],
        
        # æ‰§è¡Œç»†èŠ‚
        "entry_strategy": strategy["entry_strategy"],
        "exit_strategy": strategy["exit_strategy"],
        "max_holding_period": risk_params["max_holding_period"],
        
        # å†³ç­–ä¾æ®
        "reasoning": self._generate_decision_reasoning(strategy, position, risk_params),
        "key_factors": strategy.get("key_factors", []),
        
        # ç›‘æ§è¦æ±‚
        "monitoring_requirements": risk_params["position_monitoring"],
        "exit_conditions": risk_params["exit_conditions"],
        
        # å…ƒæ•°æ®
        "decision_timestamp": datetime.now().isoformat(),
        "decision_id": self._generate_decision_id(),
        "trader_style": self.trading_style,
        "risk_tolerance": self.risk_tolerance
    }
    
    return decision

def _generate_decision_reasoning(self, strategy: Dict, position: Dict, risk_params: Dict) -> str:
    """ç”Ÿæˆå†³ç­–æ¨ç†è¯´æ˜"""
    
    action = strategy["adjusted_signal"]["action"]
    confidence = strategy["confidence"]
    trade_type = strategy["trade_type"]
    
    reasoning_parts = []
    
    # åŸºæœ¬å†³ç­–é€»è¾‘
    if action in ["buy", "strong_buy"]:
        reasoning_parts.append(f"åŸºäºç»¼åˆåˆ†æï¼Œå»ºè®®{action}è¯¥è‚¡ç¥¨")
    elif action in ["sell", "strong_sell"]:
        reasoning_parts.append(f"åŸºäºç»¼åˆåˆ†æï¼Œå»ºè®®{action}è¯¥è‚¡ç¥¨")
    else:
        reasoning_parts.append("å½“å‰åˆ†æç»“æœå»ºè®®æŒæœ‰è§‚æœ›")
    
    # ç½®ä¿¡åº¦è¯´æ˜
    if confidence > 0.8:
        reasoning_parts.append(f"å†³ç­–ç½®ä¿¡åº¦å¾ˆé«˜({confidence:.1%})")
    elif confidence > 0.6:
        reasoning_parts.append(f"å†³ç­–ç½®ä¿¡åº¦è¾ƒé«˜({confidence:.1%})")
    else:
        reasoning_parts.append(f"å†³ç­–ç½®ä¿¡åº¦ä¸­ç­‰({confidence:.1%})ï¼Œå»ºè®®è°¨æ…æ“ä½œ")
    
    # äº¤æ˜“ç±»å‹è¯´æ˜
    reasoning_parts.append(f"é‡‡ç”¨{trade_type}ç­–ç•¥")
    
    # é£é™©ç®¡ç†è¯´æ˜
    reasoning_parts.append(
        f"è®¾ç½®{risk_params['stop_loss']:.1%}æ­¢æŸå’Œ{risk_params['take_profit']:.1%}æ­¢ç›ˆ"
    )
    
    # ä»“ä½è¯´æ˜
    reasoning_parts.append(f"å»ºè®®ä»“ä½å¤§å°ä¸º{position['final_size']:.1%}")
    
    return "ã€‚".join(reasoning_parts) + "ã€‚"
```

### 7. äº¤æ˜“è®°å¿†ç®¡ç†

```python
class TradingMemory:
    """äº¤æ˜“è®°å¿†ç®¡ç†"""
    
    def __init__(self):
        self.decision_history = []
        self.performance_metrics = {}
        self.learning_insights = []
    
    def update_decision(self, decision: Dict):
        """æ›´æ–°å†³ç­–è®°å½•"""
        self.decision_history.append(decision)
        
        # ä¿æŒæœ€è¿‘100ä¸ªå†³ç­–
        if len(self.decision_history) > 100:
            self.decision_history = self.decision_history[-100:]
    
    def learn_from_outcomes(self, decision_id: str, outcome: Dict):
        """ä»äº¤æ˜“ç»“æœä¸­å­¦ä¹ """
        
        # æ‰¾åˆ°å¯¹åº”çš„å†³ç­–
        decision = self._find_decision(decision_id)
        if not decision:
            return
        
        # åˆ†æå†³ç­–è´¨é‡
        decision_quality = self._analyze_decision_quality(decision, outcome)
        
        # æå–å­¦ä¹ è¦ç‚¹
        insights = self._extract_learning_insights(decision, outcome, decision_quality)
        
        # æ›´æ–°å­¦ä¹ è®°å½•
        self.learning_insights.extend(insights)
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        self._update_performance_metrics(decision, outcome)
    
    def get_relevant_experience(self, current_situation: Dict) -> List[Dict]:
        """è·å–ç›¸å…³çš„å†å²ç»éªŒ"""
        
        relevant_decisions = []
        
        for decision in self.decision_history:
            similarity = self._calculate_situation_similarity(
                current_situation, decision
            )
            
            if similarity > 0.7:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                relevant_decisions.append({
                    "decision": decision,
                    "similarity": similarity
                })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        relevant_decisions.sort(key=lambda x: x["similarity"], reverse=True)
        
        return relevant_decisions[:5]  # è¿”å›æœ€ç›¸ä¼¼çš„5ä¸ªå†³ç­–
```

äº¤æ˜“å‘˜æ™ºèƒ½ä½“é€šè¿‡ç»¼åˆåˆ†æã€ç­–ç•¥åˆ¶å®šã€é£é™©ç®¡ç†å’ŒæŒç»­å­¦ä¹ ï¼Œç¡®ä¿åœ¨å¤æ‚çš„å¸‚åœºç¯å¢ƒä¸­åšå‡ºæ˜æ™ºçš„æŠ•èµ„å†³ç­–ã€‚


<!-- docs/architecture/agent-architecture.md -->

# æ™ºèƒ½ä½“æ¶æ„è®¾è®¡

## æ¦‚è¿°

TradingAgents æ¡†æ¶é‡‡ç”¨ä¸“ä¸šåŒ–çš„å¤šæ™ºèƒ½ä½“æ¶æ„ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éƒ½æœ‰æ˜ç¡®çš„èŒè´£å’Œä¸“ä¸šé¢†åŸŸã€‚æ™ºèƒ½ä½“ä¹‹é—´é€šè¿‡ç»“æ„åŒ–çš„é€šä¿¡åè®®è¿›è¡Œåä½œï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„é‡‘èå†³ç­–ç³»ç»Ÿã€‚

## æ™ºèƒ½ä½“è®¾è®¡æ¨¡å¼

### åŸºç¡€æ™ºèƒ½ä½“ç±»

```python
class BaseAgent:
    """æ‰€æœ‰æ™ºèƒ½ä½“çš„åŸºç¡€ç±»"""
    
    def __init__(self, llm, config):
        self.llm = llm
        self.config = config
        self.memory = AgentMemory()
        self.tools = self._initialize_tools()
    
    def process(self, state: AgentState) -> AgentState:
        """å¤„ç†è¾“å…¥çŠ¶æ€å¹¶è¿”å›æ›´æ–°åçš„çŠ¶æ€"""
        pass
    
    def _initialize_tools(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“ä¸“ç”¨å·¥å…·"""
        pass
```

### æ™ºèƒ½ä½“çŠ¶æ€ç®¡ç†

```python
class AgentState:
    """æ™ºèƒ½ä½“çŠ¶æ€æ•°æ®ç»“æ„"""
    
    ticker: str                    # è‚¡ç¥¨ä»£ç 
    date: str                     # åˆ†ææ—¥æœŸ
    analyst_reports: Dict         # åˆ†æå¸ˆæŠ¥å‘Š
    research_reports: Dict        # ç ”ç©¶å‘˜æŠ¥å‘Š
    trader_decision: Dict         # äº¤æ˜“å†³ç­–
    risk_assessment: Dict         # é£é™©è¯„ä¼°
    portfolio_decision: Dict      # æŠ•èµ„ç»„åˆå†³ç­–
    messages: List[BaseMessage]   # æ¶ˆæ¯å†å²
```

## æ™ºèƒ½ä½“åˆ†ç±»ä¸èŒè´£

### 1. åˆ†æå¸ˆå›¢é˜Ÿ (Analysts)

#### åŸºæœ¬é¢åˆ†æå¸ˆ (Fundamentals Analyst)
```python
class FundamentalsAnalyst(BaseAgent):
    """åŸºæœ¬é¢åˆ†æå¸ˆ - åˆ†æå…¬å¸è´¢åŠ¡å’ŒåŸºæœ¬é¢æ•°æ®"""
    
    ä¸“ä¸šé¢†åŸŸ:
    - è´¢åŠ¡æŠ¥è¡¨åˆ†æ
    - ä¼°å€¼æ¨¡å‹è®¡ç®—
    - è¡Œä¸šå¯¹æ¯”åˆ†æ
    - ç›ˆåˆ©èƒ½åŠ›è¯„ä¼°
    
    è¾“å…¥æ•°æ®:
    - è´¢åŠ¡æŠ¥è¡¨æ•°æ®
    - è¡Œä¸šæ•°æ®
    - å®è§‚ç»æµæŒ‡æ ‡
    
    è¾“å‡ºç»“æœ:
    - åŸºæœ¬é¢è¯„åˆ†
    - ä¼°å€¼å»ºè®®
    - è´¢åŠ¡å¥åº·åº¦è¯„ä¼°
```

#### æŠ€æœ¯åˆ†æå¸ˆ (Market Analyst)
```python
class MarketAnalyst(BaseAgent):
    """æŠ€æœ¯åˆ†æå¸ˆ - åˆ†ææŠ€æœ¯æŒ‡æ ‡å’Œä»·æ ¼è¶‹åŠ¿"""
    
    ä¸“ä¸šé¢†åŸŸ:
    - æŠ€æœ¯æŒ‡æ ‡è®¡ç®— (RSI, MACD, å¸ƒæ—å¸¦ç­‰)
    - è¶‹åŠ¿åˆ†æ
    - æ”¯æ’‘é˜»åŠ›ä½è¯†åˆ«
    - äº¤æ˜“ä¿¡å·ç”Ÿæˆ
    
    è¾“å…¥æ•°æ®:
    - å†å²ä»·æ ¼æ•°æ®
    - äº¤æ˜“é‡æ•°æ®
    - æŠ€æœ¯æŒ‡æ ‡æ•°æ®
    
    è¾“å‡ºç»“æœ:
    - æŠ€æœ¯åˆ†æè¯„åˆ†
    - è¶‹åŠ¿æ–¹å‘åˆ¤æ–­
    - å…³é”®ä»·ä½è¯†åˆ«
```

#### æ–°é—»åˆ†æå¸ˆ (News Analyst)
```python
class NewsAnalyst(BaseAgent):
    """æ–°é—»åˆ†æå¸ˆ - åˆ†ææ–°é—»äº‹ä»¶å’Œå®è§‚å› ç´ """
    
    ä¸“ä¸šé¢†åŸŸ:
    - æ–°é—»æƒ…æ„Ÿåˆ†æ
    - äº‹ä»¶å½±å“è¯„ä¼°
    - å®è§‚ç»æµåˆ†æ
    - æ”¿ç­–å½±å“åˆ†æ
    
    è¾“å…¥æ•°æ®:
    - æ–°é—»æ–‡ç« 
    - ç»æµæ•°æ®å‘å¸ƒ
    - æ”¿ç­–å…¬å‘Š
    
    è¾“å‡ºç»“æœ:
    - æ–°é—»æƒ…æ„Ÿè¯„åˆ†
    - äº‹ä»¶å½±å“è¯„ä¼°
    - å®è§‚è¶‹åŠ¿åˆ¤æ–­
```

#### ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ (Social Media Analyst)
```python
class SocialMediaAnalyst(BaseAgent):
    """ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ - åˆ†æç¤¾äº¤åª’ä½“æƒ…ç»ª"""
    
    ä¸“ä¸šé¢†åŸŸ:
    - ç¤¾äº¤åª’ä½“æƒ…æ„Ÿåˆ†æ
    - èˆ†è®ºè¶‹åŠ¿ç›‘æµ‹
    - çƒ­ç‚¹è¯é¢˜è¯†åˆ«
    - æŠ•èµ„è€…æƒ…ç»ªè¯„ä¼°
    
    è¾“å…¥æ•°æ®:
    - Reddit è®¨è®ºæ•°æ®
    - Twitter æƒ…æ„Ÿæ•°æ®
    - è®ºå›è®¨è®ºå†…å®¹
    
    è¾“å‡ºç»“æœ:
    - ç¤¾äº¤æƒ…æ„Ÿè¯„åˆ†
    - èˆ†è®ºè¶‹åŠ¿åˆ†æ
    - æŠ•èµ„è€…æƒ…ç»ªæŒ‡æ ‡
```

### 2. ç ”ç©¶å‘˜å›¢é˜Ÿ (Researchers)

#### çœ‹æ¶¨ç ”ç©¶å‘˜ (Bull Researcher)
```python
class BullResearcher(BaseAgent):
    """çœ‹æ¶¨ç ”ç©¶å‘˜ - ä»ä¹è§‚è§’åº¦è¯„ä¼°æŠ•èµ„æœºä¼š"""
    
    èŒè´£:
    - è¯†åˆ«ç§¯æå› ç´ 
    - è¯„ä¼°ä¸Šæ¶¨æ½œåŠ›
    - æä¾›ä¹è§‚é¢„æœŸ
    - æŒ‘æˆ˜æ‚²è§‚è§‚ç‚¹
    
    åˆ†æé‡ç‚¹:
    - å¢é•¿æœºä¼š
    - å¸‚åœºä¼˜åŠ¿
    - æ­£é¢å‚¬åŒ–å‰‚
    - ä¼°å€¼å¸å¼•åŠ›
```

#### çœ‹è·Œç ”ç©¶å‘˜ (Bear Researcher)
```python
class BearResearcher(BaseAgent):
    """çœ‹è·Œç ”ç©¶å‘˜ - ä»æ‚²è§‚è§’åº¦è¯„ä¼°æŠ•èµ„é£é™©"""
    
    èŒè´£:
    - è¯†åˆ«é£é™©å› ç´ 
    - è¯„ä¼°ä¸‹è·Œé£é™©
    - æä¾›è°¨æ…é¢„æœŸ
    - æŒ‘æˆ˜ä¹è§‚è§‚ç‚¹
    
    åˆ†æé‡ç‚¹:
    - æ½œåœ¨é£é™©
    - å¸‚åœºå¨èƒ
    - è´Ÿé¢å‚¬åŒ–å‰‚
    - ä¼°å€¼è¿‡é«˜é£é™©
```

### 3. äº¤æ˜“æ‰§è¡Œ (Trader)

#### äº¤æ˜“å‘˜ (Trader)
```python
class Trader(BaseAgent):
    """äº¤æ˜“å‘˜ - åˆ¶å®šæœ€ç»ˆäº¤æ˜“å†³ç­–"""
    
    èŒè´£:
    - ç»¼åˆå„æ–¹åˆ†æ
    - åˆ¶å®šäº¤æ˜“ç­–ç•¥
    - ç¡®å®šä»“ä½å¤§å°
    - è®¾ç½®æ­¢æŸæ­¢ç›ˆ
    
    å†³ç­–å› ç´ :
    - åˆ†æå¸ˆæŠ¥å‘Š
    - ç ”ç©¶å‘˜è¾©è®ºç»“æœ
    - é£é™©è¯„ä¼°
    - å¸‚åœºæ¡ä»¶
```

### 4. é£é™©ç®¡ç†å›¢é˜Ÿ (Risk Management)

#### é£é™©è¯„ä¼°æ™ºèƒ½ä½“
```python
class RiskDebator(BaseAgent):
    """é£é™©è¯„ä¼°æ™ºèƒ½ä½“åŸºç±»"""
    
    é£é™©è¯„ä¼°ç»´åº¦:
    - å¸‚åœºé£é™©
    - æµåŠ¨æ€§é£é™©
    - ä¿¡ç”¨é£é™©
    - æ“ä½œé£é™©
    
    è¯„ä¼°æ–¹æ³•:
    - VaR è®¡ç®—
    - å‹åŠ›æµ‹è¯•
    - æƒ…æ™¯åˆ†æ
    - ç›¸å…³æ€§åˆ†æ
```

- **æ¿€è¿›é£é™©è¯„ä¼°**: æ”¯æŒé«˜é£é™©é«˜æ”¶ç›Šç­–ç•¥
- **ä¿å®ˆé£é™©è¯„ä¼°**: å¼ºè°ƒé£é™©æ§åˆ¶å’Œèµ„æœ¬ä¿æŠ¤
- **ä¸­æ€§é£é™©è¯„ä¼°**: å¹³è¡¡é£é™©å’Œæ”¶ç›Š

### 5. ç®¡ç†å±‚ (Managers)

#### ç ”ç©¶ç»ç† (Research Manager)
```python
class ResearchManager(BaseAgent):
    """ç ”ç©¶ç»ç† - åè°ƒç ”ç©¶å‘˜å›¢é˜Ÿå·¥ä½œ"""
    
    èŒè´£:
    - ç»„ç»‡ç ”ç©¶å‘˜è¾©è®º
    - å¹³è¡¡ä¸åŒè§‚ç‚¹
    - å½¢æˆç ”ç©¶å…±è¯†
    - è´¨é‡æ§åˆ¶
```

#### é£é™©ç»ç† (Risk Manager)
```python
class RiskManager(BaseAgent):
    """é£é™©ç»ç† - ç®¡ç†æ•´ä½“é£é™©æ§åˆ¶"""
    
    èŒè´£:
    - åè°ƒé£é™©è¯„ä¼°
    - åˆ¶å®šé£é™©æ”¿ç­–
    - ç›‘æ§é£é™©æŒ‡æ ‡
    - æœ€ç»ˆé£é™©å†³ç­–
```

## æ™ºèƒ½ä½“äº¤äº’æ¨¡å¼

### 1. å¹¶è¡Œåˆ†æé˜¶æ®µ
```mermaid
graph LR
    Input[å¸‚åœºæ•°æ®] --> FA[åŸºæœ¬é¢åˆ†æå¸ˆ]
    Input --> MA[æŠ€æœ¯åˆ†æå¸ˆ]
    Input --> NA[æ–°é—»åˆ†æå¸ˆ]
    Input --> SA[ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ]
    
    FA --> Reports[åˆ†ææŠ¥å‘Š]
    MA --> Reports
    NA --> Reports
    SA --> Reports
```

### 2. ç ”ç©¶è¾©è®ºé˜¶æ®µ
```mermaid
graph TB
    Reports[åˆ†ææŠ¥å‘Š] --> RM[ç ”ç©¶ç»ç†]
    RM --> BR[çœ‹æ¶¨ç ”ç©¶å‘˜]
    RM --> BEAR[çœ‹è·Œç ”ç©¶å‘˜]
    
    BR --> Debate[ç»“æ„åŒ–è¾©è®º]
    BEAR --> Debate
    
    Debate --> Consensus[ç ”ç©¶å…±è¯†]
```

### 3. äº¤æ˜“å†³ç­–é˜¶æ®µ
```mermaid
graph TB
    Consensus[ç ”ç©¶å…±è¯†] --> Trader[äº¤æ˜“å‘˜]
    Trader --> Decision[äº¤æ˜“å†³ç­–]
    
    Decision --> RiskTeam[é£é™©ç®¡ç†å›¢é˜Ÿ]
    RiskTeam --> RiskManager[é£é™©ç»ç†]
    RiskManager --> FinalDecision[æœ€ç»ˆå†³ç­–]
```

## æ™ºèƒ½ä½“é€šä¿¡åè®®

### æ¶ˆæ¯æ ¼å¼
```python
class AgentMessage:
    sender: str           # å‘é€è€…ID
    receiver: str         # æ¥æ”¶è€…ID
    message_type: str     # æ¶ˆæ¯ç±»å‹
    content: Dict         # æ¶ˆæ¯å†…å®¹
    timestamp: datetime   # æ—¶é—´æˆ³
    priority: int         # ä¼˜å…ˆçº§
```

### é€šä¿¡ç±»å‹
1. **åˆ†ææŠ¥å‘Š**: åˆ†æå¸ˆå‘ç³»ç»Ÿæäº¤åˆ†æç»“æœ
2. **è¾©è®ºæ¶ˆæ¯**: ç ”ç©¶å‘˜ä¹‹é—´çš„è§‚ç‚¹äº¤æ¢
3. **å†³ç­–è¯·æ±‚**: è¯·æ±‚å…¶ä»–æ™ºèƒ½ä½“æä¾›æ„è§
4. **é£é™©è­¦å‘Š**: é£é™©ç®¡ç†å›¢é˜Ÿçš„é£é™©æé†’
5. **æœ€ç»ˆå†³ç­–**: æœ€ç»ˆçš„äº¤æ˜“å†³ç­–é€šçŸ¥

## æ™ºèƒ½ä½“é…ç½®

### é…ç½®å‚æ•°
```python
agent_config = {
    "llm_model": "gpt-4o",           # ä½¿ç”¨çš„LLMæ¨¡å‹
    "temperature": 0.1,              # ç”Ÿæˆæ¸©åº¦
    "max_tokens": 2000,              # æœ€å¤§tokenæ•°
    "tools_enabled": True,           # æ˜¯å¦å¯ç”¨å·¥å…·
    "memory_enabled": True,          # æ˜¯å¦å¯ç”¨è®°å¿†
    "debate_rounds": 3,              # è¾©è®ºè½®æ•°
    "confidence_threshold": 0.7,     # ç½®ä¿¡åº¦é˜ˆå€¼
}
```

### ä¸“ä¸šåŒ–é…ç½®
æ¯ä¸ªæ™ºèƒ½ä½“éƒ½æœ‰ç‰¹å®šçš„é…ç½®å‚æ•°ï¼Œä»¥ä¼˜åŒ–å…¶ä¸“ä¸šé¢†åŸŸçš„è¡¨ç°ï¼š

- **åˆ†æå¸ˆ**: ä¸“æ³¨äºæ•°æ®åˆ†æå’Œæ¨¡å¼è¯†åˆ«
- **ç ”ç©¶å‘˜**: ä¼˜åŒ–è¾©è®ºå’Œæ‰¹åˆ¤æ€§æ€ç»´
- **äº¤æ˜“å‘˜**: å¼ºåŒ–å†³ç­–åˆ¶å®šå’Œé£é™©è¯„ä¼°
- **é£é™©ç®¡ç†**: ä¸“æ³¨äºé£é™©è¯†åˆ«å’Œé‡åŒ–

è¿™ç§ä¸“ä¸šåŒ–çš„æ™ºèƒ½ä½“æ¶æ„ç¡®ä¿äº†ç³»ç»Ÿèƒ½å¤Ÿä»å¤šä¸ªè§’åº¦å…¨é¢åˆ†æå¸‚åœºï¼Œå¹¶é€šè¿‡åä½œæœºåˆ¶å½¢æˆé«˜è´¨é‡çš„æŠ•èµ„å†³ç­–ã€‚


<!-- docs/architecture/configuration-optimization.md -->

# é…ç½®ç®¡ç†å’Œæ•°æ®åº“æ¶æ„ä¼˜åŒ–æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†TradingAgentsé¡¹ç›®åœ¨v0.1.2ç‰ˆæœ¬ä¸­è¿›è¡Œçš„é‡å¤§æ¶æ„ä¼˜åŒ–ï¼Œä¸»è¦è§£å†³äº†é…ç½®ç®¡ç†æ··ä¹±å’Œæ•°æ®åº“ç®¡ç†å™¨é‡å¤çš„é—®é¢˜ã€‚

## ğŸ¯ ä¼˜åŒ–ç›®æ ‡

### è§£å†³çš„é—®é¢˜
1. **é…ç½®ç®¡ç†æ··ä¹±**ï¼šå¤šä¸ªé…ç½®æºï¼ˆ.envã€default_config.pyã€JSONæ–‡ä»¶ï¼‰å¯¼è‡´é…ç½®å†²çª
2. **æ•°æ®åº“ç®¡ç†å™¨é‡å¤**ï¼šä¸¤ä¸ªåŠŸèƒ½é‡å çš„æ•°æ®åº“ç®¡ç†å™¨é€ æˆç»´æŠ¤å›°éš¾
3. **å¯ç”¨å¼€å…³å¤±æ•ˆ**ï¼šæ•°æ®åº“å¯ç”¨å¼€å…³ä¸ç”Ÿæ•ˆï¼Œå³ä½¿ç¦ç”¨ä»ä¼šè¿æ¥
4. **å¸ƒå°”å€¼åˆ¤æ–­é”™è¯¯**ï¼šMongoDBå¯¹è±¡å¸ƒå°”å€¼åˆ¤æ–­å¯¼è‡´è¿è¡Œæ—¶é”™è¯¯

### ä¼˜åŒ–æˆæœ
- âœ… **é…ç½®ç®¡ç†ç»Ÿä¸€**ï¼šåªä½¿ç”¨.envæ–‡ä»¶ç®¡ç†æ•°æ®åº“é…ç½®
- âœ… **æ•°æ®åº“ç®¡ç†å™¨ç»Ÿä¸€**ï¼šç§»é™¤é‡å¤ç»„ä»¶ï¼Œä½¿ç”¨å•ä¸€ç®¡ç†å™¨
- âœ… **å¯ç”¨å¼€å…³ç”Ÿæ•ˆ**ï¼šæ­£ç¡®éµå®ˆMONGODB_ENABLEDå’ŒREDIS_ENABLEDè®¾ç½®
- âœ… **é”™è¯¯ä¿®å¤**ï¼šè§£å†³æ‰€æœ‰MongoDBå¸ƒå°”å€¼åˆ¤æ–­é”™è¯¯

## ğŸ—ï¸ æ¶æ„å˜æ›´

### ä¼˜åŒ–å‰çš„æ¶æ„é—®é¢˜

```
é…ç½®ç®¡ç†æ··ä¹±ï¼š
.envæ–‡ä»¶ â”€â”€â”
           â”œâ”€â†’ é…ç½®å†²çªå’Œä¼˜å…ˆçº§ä¸æ˜
default_config.py â”€â”€â”˜

æ•°æ®åº“ç®¡ç†å™¨é‡å¤ï¼š
tradingagents.config.database_manager â”€â”€â”
                                        â”œâ”€â†’ åŠŸèƒ½é‡å 
tradingagents.dataflows.database_manager â”€â”€â”˜
```

### ä¼˜åŒ–åçš„æ¸…æ™°æ¶æ„

```
ç»Ÿä¸€é…ç½®ç®¡ç†ï¼š
.envæ–‡ä»¶ (å”¯ä¸€é…ç½®æº)
    â†“
tradingagents.config.database_manager (ç»Ÿä¸€ç®¡ç†å™¨)
    â†“
è‡ªåŠ¨æ£€æµ‹ + æ™ºèƒ½é™çº§
    â†“
æ–‡ä»¶ç¼“å­˜ / MongoDB / Redis
```

## ğŸ“ é…ç½®ç®¡ç†ä¼˜åŒ–

### 1. ç§»é™¤default_config.pyä¸­çš„æ•°æ®åº“é…ç½®

**ä¼˜åŒ–å‰**ï¼š
```python
# tradingagents/default_config.py
"database": {
    "mongodb": {
        "enabled": True,  # ç¡¬ç¼–ç ï¼Œæ— æ³•é€šè¿‡.envæ§åˆ¶
        "host": os.getenv("MONGODB_HOST", "localhost"),
        # ...
    }
}
```

**ä¼˜åŒ–å**ï¼š
```python
# tradingagents/default_config.py
# Note: Database configuration is now managed by .env file and config.database_manager
# No database settings in default config to avoid configuration conflicts
```

### 2. ç»Ÿä¸€ä½¿ç”¨.envæ–‡ä»¶ç®¡ç†æ•°æ®åº“é…ç½®

**é…ç½®ç¤ºä¾‹**ï¼š
```env
# æ•°æ®åº“å¯ç”¨å¼€å…³ (é»˜è®¤ç¦ç”¨)
MONGODB_ENABLED=false
REDIS_ENABLED=false

# MongoDBé…ç½®
MONGODB_HOST=localhost
MONGODB_PORT=27018
MONGODB_USERNAME=admin
MONGODB_PASSWORD=tradingagents123
MONGODB_DATABASE=tradingagents
MONGODB_AUTH_SOURCE=admin

# Redisé…ç½®
REDIS_HOST=localhost
REDIS_PORT=6380
REDIS_PASSWORD=tradingagents123
REDIS_DB=0
```

## ğŸ”§ æ•°æ®åº“ç®¡ç†å™¨ç»Ÿä¸€

### 1. ç§»é™¤æ—§çš„æ•°æ®åº“ç®¡ç†å™¨

**åˆ é™¤çš„æ–‡ä»¶**ï¼š
- `tradingagents/dataflows/database_manager.py`

**ä¿ç•™çš„ç»Ÿä¸€ç®¡ç†å™¨**ï¼š
- `tradingagents/config/database_manager.py`

### 2. æ›´æ–°æ‰€æœ‰å¼•ç”¨

**æ›´æ–°çš„æ–‡ä»¶**ï¼š
```
tradingagents/dataflows/tdx_utils.py
tradingagents/dataflows/stock_data_service.py
scripts/setup/setup_databases.py
scripts/setup/init_database.py
tests/test_database_fix.py
docs/database_setup.md
```

**å¯¼å…¥æ›´æ”¹**ï¼š
```python
# ä¿®æ”¹å‰
from tradingagents.dataflows.database_manager import get_database_manager

# ä¿®æ”¹å
from tradingagents.config.database_manager import get_database_manager
```

## ğŸ› ï¸ å¸ƒå°”å€¼åˆ¤æ–­é”™è¯¯ä¿®å¤

### é—®é¢˜è¯´æ˜
PyMongoçš„æ•°æ®åº“å¯¹è±¡é‡å†™äº†`__bool__`æ–¹æ³•ï¼Œç›´æ¥è¿›è¡Œå¸ƒå°”å€¼åˆ¤æ–­ä¼šæŠ›å‡º`NotImplementedError`ã€‚

### ä¿®å¤æ–¹æ¡ˆ

**é”™è¯¯çš„åˆ¤æ–­æ–¹å¼**ï¼š
```python
if mongodb_db:  # âŒ ä¼šæŠ›å‡ºNotImplementedError
    # æ‰§è¡Œæ“ä½œ
```

**æ­£ç¡®çš„åˆ¤æ–­æ–¹å¼**ï¼š
```python
# æ–¹å¼1ï¼šä½¿ç”¨is not None
if mongodb_db is not None:  # âœ… å®‰å…¨
    # æ‰§è¡Œæ“ä½œ

# æ–¹å¼2ï¼šä½¿ç”¨ä¸“é—¨çš„æ–¹æ³•
if db_manager.is_mongodb_available():  # âœ… æ¨è
    # æ‰§è¡Œæ“ä½œ
```

## ğŸ“‹ ä½¿ç”¨æŒ‡å—

### 1. åŸºæœ¬é…ç½®

ç¼–è¾‘é¡¹ç›®æ ¹ç›®å½•çš„`.env`æ–‡ä»¶ï¼š

```env
# ç¦ç”¨æ‰€æœ‰æ•°æ®åº“ï¼ˆé»˜è®¤é…ç½®ï¼‰
MONGODB_ENABLED=false
REDIS_ENABLED=false

# å¯ç”¨MongoDB
MONGODB_ENABLED=true
MONGODB_HOST=localhost
MONGODB_PORT=27018
# ... å…¶ä»–MongoDBé…ç½®

# å¯ç”¨Redis
REDIS_ENABLED=true
REDIS_HOST=localhost
REDIS_PORT=6380
# ... å…¶ä»–Redisé…ç½®
```

### 2. ä»£ç ä½¿ç”¨

```python
from tradingagents.config.database_manager import get_database_manager

# è·å–ç»Ÿä¸€æ•°æ®åº“ç®¡ç†å™¨
db_manager = get_database_manager()

# æ£€æŸ¥æ•°æ®åº“å¯ç”¨æ€§
if db_manager.is_mongodb_available():
    print("MongoDBå¯ç”¨")

if db_manager.is_redis_available():
    print("Rediså¯ç”¨")

# è·å–ç¼“å­˜åç«¯ä¿¡æ¯
backend = db_manager.get_cache_backend()  # "file", "mongodb", "redis"

# è·å–æ•°æ®åº“å®¢æˆ·ç«¯
mongodb_client = db_manager.get_mongodb_client()
redis_client = db_manager.get_redis_client()
```

### 3. ç³»ç»Ÿè¡Œä¸º

**å½“æ•°æ®åº“ç¦ç”¨æ—¶**ï¼š
- âœ… ç³»ç»Ÿä¸ä¼šå°è¯•è¿æ¥æ•°æ®åº“
- âœ… è‡ªåŠ¨ä½¿ç”¨æ–‡ä»¶ç¼“å­˜
- âœ… ä¸ä¼šå‡ºç°è¿æ¥é”™è¯¯æ¶ˆæ¯
- âœ… æ‰€æœ‰åŠŸèƒ½æ­£å¸¸å·¥ä½œ

**å½“æ•°æ®åº“å¯ç”¨ä½†ä¸å¯ç”¨æ—¶**ï¼š
- âœ… ç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹è¿æ¥å¤±è´¥
- âœ… è‡ªåŠ¨é™çº§åˆ°æ–‡ä»¶ç¼“å­˜
- âœ… è®°å½•è­¦å‘Šæ—¥å¿—ä½†ä¸å½±å“åŠŸèƒ½

## ğŸ” éªŒè¯ä¼˜åŒ–æ•ˆæœ

### 1. æ£€æŸ¥é…ç½®ç”Ÿæ•ˆ

```bash
# è®¾ç½®ç¦ç”¨æ•°æ®åº“
echo "MONGODB_ENABLED=false" >> .env
echo "REDIS_ENABLED=false" >> .env

# è¿è¡Œç³»ç»Ÿï¼Œåº”è¯¥çœ‹åˆ°ï¼š
# - æ²¡æœ‰æ•°æ®åº“è¿æ¥æ¶ˆæ¯
# - ä½¿ç”¨æ–‡ä»¶ç¼“å­˜
# - æ²¡æœ‰å¸ƒå°”å€¼åˆ¤æ–­é”™è¯¯
```

### 2. æ£€æŸ¥å¯ç”¨å¼€å…³

```python
import os
from tradingagents.config.database_manager import get_database_manager

# æ£€æŸ¥ç¯å¢ƒå˜é‡
print(f"MONGODB_ENABLED: {os.getenv('MONGODB_ENABLED', 'false')}")
print(f"REDIS_ENABLED: {os.getenv('REDIS_ENABLED', 'false')}")

# æ£€æŸ¥ç®¡ç†å™¨çŠ¶æ€
db_manager = get_database_manager()
print(f"MongoDBå¯ç”¨: {db_manager.is_mongodb_available()}")
print(f"Rediså¯ç”¨: {db_manager.is_redis_available()}")

# ä¸¤è€…åº”è¯¥ä¸€è‡´
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [æ•°æ®åº“é…ç½®æŒ‡å—](../database_setup.md)
- [ç¯å¢ƒé…ç½®è¯´æ˜](../configuration/environment-setup.md)
- [ç¼“å­˜ç³»ç»Ÿæ–‡æ¡£](../caching/cache-system.md)

## ğŸ‰ æ€»ç»“

æœ¬æ¬¡æ¶æ„ä¼˜åŒ–æ˜¾è‘—æå‡äº†é¡¹ç›®çš„å¯ç»´æŠ¤æ€§å’Œç”¨æˆ·ä½“éªŒï¼š

1. **é…ç½®æ›´ç®€å•**ï¼šåªéœ€ç¼–è¾‘.envæ–‡ä»¶
2. **è¡Œä¸ºæ›´å¯é¢„æµ‹**ï¼šå¯ç”¨å¼€å…³çœŸæ­£ç”Ÿæ•ˆ
3. **æ¶æ„æ›´æ¸…æ™°**ï¼šç§»é™¤é‡å¤ç»„ä»¶
4. **é”™è¯¯æ›´å°‘**ï¼šä¿®å¤äº†æ‰€æœ‰å·²çŸ¥çš„å¸ƒå°”å€¼åˆ¤æ–­é—®é¢˜

è¿™äº›æ”¹è¿›ä¸ºé¡¹ç›®çš„åç»­å‘å±•å¥ å®šäº†æ›´åŠ ç¨³å›ºçš„åŸºç¡€ã€‚


<!-- docs/architecture/data-flow-architecture.md -->

# æ•°æ®æµæ¶æ„

## æ¦‚è¿°

TradingAgents çš„æ•°æ®æµæ¶æ„è®¾è®¡ç”¨äºé«˜æ•ˆåœ°è·å–ã€å¤„ç†å’Œåˆ†å‘é‡‘èæ•°æ®ã€‚ç³»ç»Ÿæ”¯æŒå¤šç§æ•°æ®æºï¼Œå®ç°äº†ç»Ÿä¸€çš„æ•°æ®æ¥å£ï¼Œå¹¶æä¾›äº†å¼ºå¤§çš„ç¼“å­˜å’Œå¤„ç†æœºåˆ¶ã€‚

## æ•°æ®æµæ¶æ„å›¾

```mermaid
graph TB
    subgraph "å¤–éƒ¨æ•°æ®æº"
        FINNHUB[FinnHub API<br/>å®æ—¶é‡‘èæ•°æ®]
        YAHOO[Yahoo Finance<br/>å†å²ä»·æ ¼æ•°æ®]
        REDDIT[Reddit API<br/>ç¤¾äº¤åª’ä½“æ•°æ®]
        GNEWS[Google News<br/>æ–°é—»æ•°æ®]
        CUSTOM[è‡ªå®šä¹‰æ•°æ®æº<br/>æ‰©å±•æ¥å£]
    end
    
    subgraph "æ•°æ®è·å–å±‚"
        FUTILS[FinnHub Utils]
        YUTILS[YFinance Utils]
        RUTILS[Reddit Utils]
        NUTILS[News Utils]
        SUTILS[StockStats Utils]
    end
    
    subgraph "æ•°æ®å¤„ç†å±‚"
        INTERFACE[Data Interface]
        PROCESSOR[Data Processor]
        VALIDATOR[Data Validator]
        TRANSFORMER[Data Transformer]
    end
    
    subgraph "ç¼“å­˜å±‚"
        CACHE[Data Cache]
        REDIS[Redis Cache]
        LOCAL[Local Cache]
        MEMORY[Memory Cache]
    end
    
    subgraph "æ•°æ®åˆ†å‘å±‚"
        DISPATCHER[Data Dispatcher]
        ROUTER[Data Router]
        FORMATTER[Data Formatter]
    end
    
    subgraph "æ™ºèƒ½ä½“æ¶ˆè´¹å±‚"
        ANALYSTS[åˆ†æå¸ˆå›¢é˜Ÿ]
        RESEARCHERS[ç ”ç©¶å‘˜å›¢é˜Ÿ]
        TRADER[äº¤æ˜“å‘˜]
        RISK[é£é™©ç®¡ç†]
    end
    
    FINNHUB --> FUTILS
    YAHOO --> YUTILS
    REDDIT --> RUTILS
    GNEWS --> NUTILS
    CUSTOM --> SUTILS
    
    FUTILS --> INTERFACE
    YUTILS --> INTERFACE
    RUTILS --> INTERFACE
    NUTILS --> INTERFACE
    SUTILS --> INTERFACE
    
    INTERFACE --> PROCESSOR
    PROCESSOR --> VALIDATOR
    VALIDATOR --> TRANSFORMER
    
    TRANSFORMER --> CACHE
    CACHE --> REDIS
    CACHE --> LOCAL
    CACHE --> MEMORY
    
    CACHE --> DISPATCHER
    DISPATCHER --> ROUTER
    ROUTER --> FORMATTER
    
    FORMATTER --> ANALYSTS
    FORMATTER --> RESEARCHERS
    FORMATTER --> TRADER
    FORMATTER --> RISK
```

## æ•°æ®æºè¯¦è§£

### 1. FinnHub API
```python
class FinnHubUtils:
    """FinnHub æ•°æ®è·å–å·¥å…·"""
    
    æ”¯æŒçš„æ•°æ®ç±»å‹:
    - å®æ—¶è‚¡ä»·æ•°æ®
    - å…¬å¸åŸºæœ¬ä¿¡æ¯
    - è´¢åŠ¡æŠ¥è¡¨æ•°æ®
    - æ–°é—»å’Œå…¬å‘Š
    - æŠ€æœ¯æŒ‡æ ‡
    - å¸‚åœºæƒ…ç»ªæŒ‡æ ‡
    
    APIé™åˆ¶:
    - å…è´¹ç‰ˆ: 60 calls/minute
    - ä»˜è´¹ç‰ˆ: æ›´é«˜é¢‘ç‡é™åˆ¶
    
    æ•°æ®æ ¼å¼:
    {
        "symbol": "AAPL",
        "price": 150.25,
        "change": 2.15,
        "changePercent": 1.45,
        "timestamp": 1640995200
    }
```

### 2. Yahoo Finance
```python
class YFinanceUtils:
    """Yahoo Finance æ•°æ®è·å–å·¥å…·"""
    
    æ”¯æŒçš„æ•°æ®ç±»å‹:
    - å†å²ä»·æ ¼æ•°æ®
    - è‚¡ç¥¨åˆ†å‰²ä¿¡æ¯
    - è‚¡æ¯æ•°æ®
    - æœŸæƒæ•°æ®
    - è´¢åŠ¡æŒ‡æ ‡
    
    ä¼˜åŠ¿:
    - å…è´¹ä½¿ç”¨
    - æ•°æ®è¦†ç›–é¢å¹¿
    - å†å²æ•°æ®ä¸°å¯Œ
    
    æ•°æ®æ ¼å¼:
    {
        "Date": "2024-01-01",
        "Open": 148.50,
        "High": 152.30,
        "Low": 147.80,
        "Close": 150.25,
        "Volume": 45678900
    }
```

### 3. Reddit API
```python
class RedditUtils:
    """Reddit ç¤¾äº¤åª’ä½“æ•°æ®è·å–å·¥å…·"""
    
    æ”¯æŒçš„æ•°æ®ç±»å‹:
    - çƒ­é—¨å¸–å­
    - è¯„è®ºæƒ…æ„Ÿ
    - ç”¨æˆ·è®¨è®ºçƒ­åº¦
    - å…³é”®è¯æåŠé¢‘ç‡
    
    åˆ†æç»´åº¦:
    - æƒ…æ„Ÿææ€§ (æ­£é¢/è´Ÿé¢/ä¸­æ€§)
    - è®¨è®ºçƒ­åº¦
    - ç”¨æˆ·å‚ä¸åº¦
    - è¯é¢˜è¶‹åŠ¿
    
    æ•°æ®æ ¼å¼:
    {
        "post_id": "abc123",
        "title": "AAPL earnings discussion",
        "score": 1250,
        "comments": 89,
        "sentiment": 0.65,
        "timestamp": 1640995200
    }
```

### 4. Google News
```python
class GoogleNewsUtils:
    """Google News æ–°é—»æ•°æ®è·å–å·¥å…·"""
    
    æ”¯æŒçš„æ•°æ®ç±»å‹:
    - ç›¸å…³æ–°é—»æ–‡ç« 
    - æ–°é—»æƒ…æ„Ÿåˆ†æ
    - äº‹ä»¶æ—¶é—´çº¿
    - å½±å“åŠ›è¯„ä¼°
    
    å¤„ç†æµç¨‹:
    1. å…³é”®è¯æœç´¢
    2. æ–°é—»ç­›é€‰
    3. å†…å®¹æå–
    4. æƒ…æ„Ÿåˆ†æ
    5. å½±å“åŠ›è¯„ä¼°
    
    æ•°æ®æ ¼å¼:
    {
        "title": "Apple reports strong Q4 earnings",
        "source": "Reuters",
        "published": "2024-01-01T10:00:00Z",
        "sentiment": 0.8,
        "relevance": 0.95,
        "impact_score": 0.7
    }
```

## æ•°æ®å¤„ç†æµç¨‹

### 1. æ•°æ®è·å–é˜¶æ®µ
```python
class DataAcquisition:
    """æ•°æ®è·å–åè°ƒå™¨"""
    
    def fetch_data(self, symbol: str, date: str) -> Dict:
        """è·å–æŒ‡å®šè‚¡ç¥¨å’Œæ—¥æœŸçš„æ‰€æœ‰æ•°æ®"""
        
        # å¹¶è¡Œè·å–å„ç±»æ•°æ®
        tasks = [
            self.fetch_price_data(symbol, date),
            self.fetch_fundamental_data(symbol),
            self.fetch_news_data(symbol, date),
            self.fetch_social_data(symbol, date),
            self.fetch_technical_data(symbol, date)
        ]
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks)
        
        # æ•´åˆæ•°æ®
        return self.integrate_data(results)
```

### 2. æ•°æ®éªŒè¯é˜¶æ®µ
```python
class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""
    
    éªŒè¯è§„åˆ™:
    - æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
    - æ•°æ®ç±»å‹éªŒè¯
    - æ•°å€¼èŒƒå›´æ£€æŸ¥
    - æ—¶é—´æˆ³éªŒè¯
    - å¼‚å¸¸å€¼æ£€æµ‹
    
    def validate(self, data: Dict) -> Tuple[bool, List[str]]:
        """éªŒè¯æ•°æ®è´¨é‡"""
        errors = []
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if not self.check_required_fields(data):
            errors.append("Missing required fields")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if not self.check_data_types(data):
            errors.append("Invalid data types")
        
        # æ£€æŸ¥æ•°å€¼èŒƒå›´
        if not self.check_value_ranges(data):
            errors.append("Values out of range")
        
        return len(errors) == 0, errors
```

### 3. æ•°æ®è½¬æ¢é˜¶æ®µ
```python
class DataTransformer:
    """æ•°æ®è½¬æ¢å™¨"""
    
    è½¬æ¢åŠŸèƒ½:
    - æ•°æ®æ ‡å‡†åŒ–
    - å•ä½ç»Ÿä¸€
    - æ ¼å¼è½¬æ¢
    - ç‰¹å¾å·¥ç¨‹
    - æ•°æ®èšåˆ
    
    def transform(self, raw_data: Dict) -> Dict:
        """è½¬æ¢åŸå§‹æ•°æ®ä¸ºæ ‡å‡†æ ¼å¼"""
        
        transformed = {}
        
        # ä»·æ ¼æ•°æ®æ ‡å‡†åŒ–
        transformed['price_data'] = self.normalize_prices(
            raw_data['price_data']
        )
        
        # è´¢åŠ¡æ•°æ®è½¬æ¢
        transformed['financial_data'] = self.convert_financials(
            raw_data['financial_data']
        )
        
        # æƒ…æ„Ÿæ•°æ®èšåˆ
        transformed['sentiment_data'] = self.aggregate_sentiment(
            raw_data['news_data'],
            raw_data['social_data']
        )
        
        return transformed
```

## ç¼“å­˜ç­–ç•¥

### 1. å¤šå±‚ç¼“å­˜æ¶æ„
```python
class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    ç¼“å­˜å±‚æ¬¡:
    1. å†…å­˜ç¼“å­˜ (æœ€å¿«è®¿é—®)
    2. æœ¬åœ°æ–‡ä»¶ç¼“å­˜ (æŒä¹…åŒ–)
    3. Redisç¼“å­˜ (åˆ†å¸ƒå¼)
    4. æ•°æ®åº“ç¼“å­˜ (é•¿æœŸå­˜å‚¨)
    
    def get_data(self, key: str) -> Optional[Dict]:
        """æŒ‰ä¼˜å…ˆçº§è·å–ç¼“å­˜æ•°æ®"""
        
        # 1. æ£€æŸ¥å†…å­˜ç¼“å­˜
        if data := self.memory_cache.get(key):
            return data
        
        # 2. æ£€æŸ¥æœ¬åœ°ç¼“å­˜
        if data := self.local_cache.get(key):
            self.memory_cache.set(key, data)
            return data
        
        # 3. æ£€æŸ¥Redisç¼“å­˜
        if data := self.redis_cache.get(key):
            self.local_cache.set(key, data)
            self.memory_cache.set(key, data)
            return data
        
        return None
```

### 2. ç¼“å­˜ç­–ç•¥
```python
ç¼“å­˜é…ç½®:
{
    "price_data": {
        "ttl": 300,        # 5åˆ†é’Ÿè¿‡æœŸ
        "refresh": "auto"   # è‡ªåŠ¨åˆ·æ–°
    },
    "fundamental_data": {
        "ttl": 86400,      # 24å°æ—¶è¿‡æœŸ
        "refresh": "manual" # æ‰‹åŠ¨åˆ·æ–°
    },
    "news_data": {
        "ttl": 3600,       # 1å°æ—¶è¿‡æœŸ
        "refresh": "auto"   # è‡ªåŠ¨åˆ·æ–°
    },
    "social_data": {
        "ttl": 1800,       # 30åˆ†é’Ÿè¿‡æœŸ
        "refresh": "auto"   # è‡ªåŠ¨åˆ·æ–°
    }
}
```

## æ•°æ®åˆ†å‘æœºåˆ¶

### 1. æ•°æ®è·¯ç”±
```python
class DataRouter:
    """æ•°æ®è·¯ç”±å™¨"""
    
    è·¯ç”±è§„åˆ™:
    - åŸºæœ¬é¢æ•°æ® â†’ åŸºæœ¬é¢åˆ†æå¸ˆ
    - æŠ€æœ¯æ•°æ® â†’ æŠ€æœ¯åˆ†æå¸ˆ
    - æ–°é—»æ•°æ® â†’ æ–°é—»åˆ†æå¸ˆ
    - ç¤¾äº¤æ•°æ® â†’ ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ
    - ç»¼åˆæ•°æ® â†’ æ‰€æœ‰æ™ºèƒ½ä½“
    
    def route_data(self, data: Dict, agents: List[str]) -> Dict:
        """æ ¹æ®æ™ºèƒ½ä½“ç±»å‹åˆ†å‘ç›¸åº”æ•°æ®"""
        
        routed_data = {}
        
        for agent in agents:
            if agent == "fundamentals_analyst":
                routed_data[agent] = {
                    "financial_data": data["financial_data"],
                    "company_info": data["company_info"],
                    "industry_data": data["industry_data"]
                }
            elif agent == "technical_analyst":
                routed_data[agent] = {
                    "price_data": data["price_data"],
                    "volume_data": data["volume_data"],
                    "technical_indicators": data["technical_indicators"]
                }
            # ... å…¶ä»–æ™ºèƒ½ä½“çš„è·¯ç”±è§„åˆ™
        
        return routed_data
```

### 2. æ•°æ®æ ¼å¼åŒ–
```python
class DataFormatter:
    """æ•°æ®æ ¼å¼åŒ–å™¨"""
    
    def format_for_agent(self, data: Dict, agent_type: str) -> Dict:
        """ä¸ºç‰¹å®šæ™ºèƒ½ä½“æ ¼å¼åŒ–æ•°æ®"""
        
        if agent_type == "fundamentals_analyst":
            return self.format_fundamental_data(data)
        elif agent_type == "technical_analyst":
            return self.format_technical_data(data)
        elif agent_type == "news_analyst":
            return self.format_news_data(data)
        elif agent_type == "social_analyst":
            return self.format_social_data(data)
        
        return data
```

## æ€§èƒ½ä¼˜åŒ–

### 1. å¹¶è¡Œå¤„ç†
- å¤šçº¿ç¨‹æ•°æ®è·å–
- å¼‚æ­¥APIè°ƒç”¨
- å¹¶è¡Œæ•°æ®å¤„ç†

### 2. æ™ºèƒ½ç¼“å­˜
- é¢„æµ‹æ€§ç¼“å­˜
- çƒ­æ•°æ®é¢„åŠ è½½
- ç¼“å­˜å‘½ä¸­ç‡ä¼˜åŒ–

### 3. æ•°æ®å‹ç¼©
- æ•°æ®å‹ç¼©å­˜å‚¨
- å¢é‡æ•°æ®ä¼ è¾“
- æ•°æ®å»é‡

### 4. é”™è¯¯å¤„ç†
- æ•°æ®æºæ•…éšœè½¬ç§»
- é‡è¯•æœºåˆ¶
- é™çº§ç­–ç•¥

è¿™ç§æ•°æ®æµæ¶æ„ç¡®ä¿äº†ç³»ç»Ÿèƒ½å¤Ÿé«˜æ•ˆã€å¯é åœ°å¤„ç†å¤§é‡é‡‘èæ•°æ®ï¼Œä¸ºæ™ºèƒ½ä½“æä¾›é«˜è´¨é‡çš„æ•°æ®æ”¯æŒã€‚


<!-- docs/architecture/database-architecture.md -->

# TradingAgents-CN æ•°æ®åº“æ¶æ„è®¾è®¡

## 1. æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº† TradingAgents-CN é¡¹ç›®çš„æ•°æ®åº“æ¶æ„è®¾è®¡ï¼ŒåŒ…æ‹¬ MongoDB å’Œ Redis çš„é›†æˆæ–¹æ¡ˆã€‚è¯¥æ¶æ„æ—¨åœ¨æä¾›é«˜æ€§èƒ½ã€å¯æ‰©å±•ã€é«˜å¯ç”¨çš„æ•°æ®ç®¡ç†è§£å†³æ–¹æ¡ˆï¼Œä»¥æ”¯æŒå¤šæ™ºèƒ½ä½“äº¤æ˜“ç³»ç»Ÿçš„æ•°æ®éœ€æ±‚ã€‚

## 2. æ¶æ„æ¦‚è§ˆ

TradingAgents-CN é‡‡ç”¨å¤šå±‚æ•°æ®æ¶æ„ï¼š

```mermaid
graph TD
    A[åº”ç”¨å±‚] --> B[æ•°æ®è®¿é—®æŠ½è±¡å±‚]
    B --> C[Redis ç¼“å­˜å±‚]
    B --> D[MongoDB æŒä¹…å±‚]
    B --> E[æ–‡ä»¶å­˜å‚¨å±‚]
    C -.-> D
    D -.-> E
```

### 2.1 æ ¸å¿ƒç»„ä»¶

| ç»„ä»¶ | è§’è‰² | ä¸»è¦èŒè´£ |
|-----|-----|---------|
| **Redis** | ç¼“å­˜å±‚ | æä¾›é«˜é€Ÿæ•°æ®è®¿é—®ï¼Œå‡è½»æ•°æ®åº“è´Ÿæ‹… |
| **MongoDB** | æŒä¹…å±‚ | å­˜å‚¨ç»“æ„åŒ–å’ŒåŠç»“æ„åŒ–æ•°æ® |
| **æ–‡ä»¶å­˜å‚¨** | å¤‡ä»½å±‚ | æä¾›æ•°æ®å¤‡ä»½å’Œå†å²å½’æ¡£ |
| **æ•°æ®è®¿é—®æŠ½è±¡å±‚** | ä¸­é—´å±‚ | ç»Ÿä¸€æ•°æ®è®¿é—®æ¥å£ï¼Œç®¡ç†ç¼“å­˜ç­–ç•¥ |

## 3. MongoDB æ•°æ®æ¨¡å‹

### 3.1 æ•°æ®åº“ç»“æ„

```
mongodb://localhost:27017/tradingagents
â”œâ”€â”€ market_data                # é›†åˆï¼šå¸‚åœºæ•°æ®
â”‚   â”œâ”€â”€ { symbol: "AAPL", date: "2023-05-15", open: 150.25, ... }
â”‚   â””â”€â”€ { symbol: "GOOGL", date: "2023-05-15", open: 2500.10, ... }
â”œâ”€â”€ fundamental_data          # é›†åˆï¼šåŸºæœ¬é¢æ•°æ®
â”‚   â”œâ”€â”€ { symbol: "AAPL", period: "2023Q1", revenue: 94.8, ... }
â”‚   â””â”€â”€ { symbol: "GOOGL", period: "2023Q1", revenue: 69.8, ... }
â”œâ”€â”€ news_data                 # é›†åˆï¼šæ–°é—»æ•°æ®
â”‚   â”œâ”€â”€ { symbol: "AAPL", timestamp: "2023-05-15T08:30:00", title: "...", ... }
â”‚   â””â”€â”€ { symbol: "MARKET", timestamp: "2023-05-15T09:15:00", title: "...", ... }
â”œâ”€â”€ social_data               # é›†åˆï¼šç¤¾äº¤åª’ä½“æ•°æ®
â”‚   â””â”€â”€ { symbol: "AAPL", source: "reddit", timestamp: "...", sentiment: 0.75, ... }
â”œâ”€â”€ analysis_results          # é›†åˆï¼šåˆ†æç»“æœ
â”‚   â””â”€â”€ { symbol: "AAPL", date: "2023-05-15", analyst: "market", decision: "BUY", ... }
â””â”€â”€ metadata                  # é›†åˆï¼šå…ƒæ•°æ®
    â”œâ”€â”€ { type: "sync_status", last_update: "2023-05-15T10:00:00", ... }
    â””â”€â”€ { type: "data_catalog", schema_version: "1.0", ... }
```

### 3.2 ç´¢å¼•ç­–ç•¥

| é›†åˆ | ç´¢å¼• | ç±»å‹ | ç›®çš„ |
|-----|-----|------|-----|
| **market_data** | `{ symbol: 1, date: 1 }` | å¤åˆç´¢å¼• | å¿«é€ŸæŸ¥è¯¢ç‰¹å®šè‚¡ç¥¨çš„å†å²æ•°æ® |
| **market_data** | `{ date: 1 }` | å•å­—æ®µç´¢å¼• | æŒ‰æ—¥æœŸæŸ¥è¯¢å¸‚åœºæ•°æ® |
| **fundamental_data** | `{ symbol: 1, period: 1 }` | å¤åˆç´¢å¼• | å¿«é€ŸæŸ¥è¯¢ç‰¹å®šè‚¡ç¥¨çš„è´¢åŠ¡æ•°æ® |
| **news_data** | `{ symbol: 1, timestamp: -1 }` | å¤åˆç´¢å¼• | æŒ‰æ—¶é—´å€’åºæŸ¥è¯¢æ–°é—» |
| **news_data** | `{ timestamp: -1 }` | å•å­—æ®µç´¢å¼• | è·å–æœ€æ–°æ–°é—» |
| **social_data** | `{ symbol: 1, timestamp: -1 }` | å¤åˆç´¢å¼• | æŒ‰æ—¶é—´å€’åºæŸ¥è¯¢ç¤¾äº¤æ•°æ® |
| **analysis_results** | `{ symbol: 1, date: -1 }` | å¤åˆç´¢å¼• | æŸ¥è¯¢æœ€æ–°åˆ†æç»“æœ |

### 3.3 æ–‡æ¡£æ¨¡å‹ç¤ºä¾‹

```json
// market_data é›†åˆæ–‡æ¡£ç¤ºä¾‹
{
  "_id": ObjectId("..."),
  "symbol": "AAPL",
  "market": "us",
  "date": "2023-05-15",
  "open": 150.25,
  "high": 152.30,
  "low": 149.80,
  "close": 151.75,
  "volume": 75482365,
  "adjusted_close": 151.75,
  "source": "finnhub",
  "created_at": ISODate("2023-05-15T20:00:00Z"),
  "updated_at": ISODate("2023-05-15T20:00:00Z")
}

// fundamental_data é›†åˆæ–‡æ¡£ç¤ºä¾‹
{
  "_id": ObjectId("..."),
  "symbol": "AAPL",
  "period": "2023Q1",
  "report_type": "income_statement",
  "currency": "USD",
  "revenue": 94800000000,
  "gross_profit": 41500000000,
  "net_income": 24160000000,
  "eps": 1.52,
  "source": "simfin",
  "filing_date": "2023-04-28",
  "created_at": ISODate("2023-04-28T18:30:00Z"),
  "updated_at": ISODate("2023-04-28T18:30:00Z")
}
```

## 4. Redis ç¼“å­˜è®¾è®¡

### 4.1 é”®ç©ºé—´è®¾è®¡

```
Redis å®ä¾‹ (localhost:6379)
â”œâ”€â”€ ta:price:{symbol}:{timeframe}     # ä»·æ ¼æ•°æ®ç¼“å­˜
â”œâ”€â”€ ta:quote:{symbol}                 # å®æ—¶æŠ¥ä»·ç¼“å­˜
â”œâ”€â”€ ta:news:{symbol}                  # æ–°é—»æ•°æ®ç¼“å­˜
â”œâ”€â”€ ta:social:{symbol}                # ç¤¾äº¤åª’ä½“æ•°æ®ç¼“å­˜
â”œâ”€â”€ ta:analysis:{symbol}:{analyst}    # åˆ†æç»“æœç¼“å­˜
â”œâ”€â”€ ta:stats:{symbol}                 # ç»Ÿè®¡æ•°æ®ç¼“å­˜
â”œâ”€â”€ ta:locks:{resource}               # åˆ†å¸ƒå¼é”
â””â”€â”€ ta:jobs:{job_id}                  # åå°ä»»åŠ¡çŠ¶æ€
```

### 4.2 æ•°æ®ç»“æ„ä¸TTLç­–ç•¥

| ç¼“å­˜é”®æ¨¡å¼ | æ•°æ®ç±»å‹ | TTL | ç”¨é€” |
|-----------|---------|-----|-----|
| `ta:price:{symbol}:daily` | Hash | 1å¤© | æ—¥çº¿ä»·æ ¼æ•°æ® |
| `ta:price:{symbol}:intraday` | Hash | 5åˆ†é’Ÿ | åˆ†é’Ÿçº§ä»·æ ¼æ•°æ® |
| `ta:quote:{symbol}` | Hash | 1åˆ†é’Ÿ | å®æ—¶æŠ¥ä»· |
| `ta:news:{symbol}` | List | 15åˆ†é’Ÿ | æœ€æ–°æ–°é—» |
| `ta:news:market` | List | 10åˆ†é’Ÿ | å¸‚åœºæ–°é—» |
| `ta:social:{symbol}` | Sorted Set | 5åˆ†é’Ÿ | ç¤¾äº¤åª’ä½“æƒ…ç»ª |
| `ta:analysis:{symbol}:{date}` | Hash | 1å°æ—¶ | åˆ†æç»“æœ |
| `ta:stats:{symbol}` | Hash | 1å¤© | ç»Ÿè®¡æ•°æ® |

### 4.3 æ•°æ®ç»“æ„ç¤ºä¾‹

```
# ä»·æ ¼æ•°æ® (Hash)
HSET ta:price:AAPL:daily 2023-05-15 "{'open':150.25,'high':152.30,'low':149.80,'close':151.75,'volume':75482365}"
EXPIRE ta:price:AAPL:daily 86400

# å®æ—¶æŠ¥ä»· (Hash)
HSET ta:quote:AAPL price 151.75 change 1.25 percent 0.83 volume 75482365 updated_at 1684180800
EXPIRE ta:quote:AAPL 60

# æ–°é—»æ•°æ® (List)
LPUSH ta:news:AAPL "{'id':'n12345','title':'Apple Announces New iPhone','timestamp':'2023-05-15T14:30:00Z','source':'reuters'}"
EXPIRE ta:news:AAPL 900

# ç¤¾äº¤åª’ä½“æƒ…ç»ª (Sorted Setï¼ŒæŒ‰æ—¶é—´æˆ³æ’åº)
ZADD ta:social:AAPL 1684180800 "{'source':'reddit','sentiment':0.75,'mentions':120,'timestamp':1684180800}"
EXPIRE ta:social:AAPL 300
```

## 5. æ•°æ®æµè®¾è®¡

### 5.1 è¯»å–æµç¨‹

```mermaid
graph TD
    A[è¯·æ±‚æ•°æ®] --> B{Redisç¼“å­˜?}
    B -->|æ˜¯| C[è¿”å›ç¼“å­˜æ•°æ®]
    B -->|å¦| D{MongoDB?}
    D -->|æ˜¯| E[æŸ¥è¯¢MongoDB]
    D -->|å¦| F{æ–‡ä»¶å­˜å‚¨?}
    F -->|æ˜¯| G[è¯»å–æ–‡ä»¶]
    F -->|å¦| H[APIè·å–]
    
    E --> I[æ›´æ–°Redisç¼“å­˜]
    G --> I
    H --> J[å†™å…¥MongoDB]
    J --> I
    
    I --> C
```

### 5.2 å†™å…¥æµç¨‹

```mermaid
graph TD
    A[æ–°æ•°æ®] --> B[æ•°æ®éªŒè¯]
    B --> C[å†™å…¥MongoDB]
    C --> D[æ›´æ–°Redisç¼“å­˜]
    C --> E{éœ€è¦å¤‡ä»½?}
    E -->|æ˜¯| F[å†™å…¥æ–‡ä»¶å­˜å‚¨]
    E -->|å¦| G[å®Œæˆ]
    D --> G
    F --> G
```

### 5.3 ç¼“å­˜åŒæ­¥ç­–ç•¥

| åŒæ­¥ç±»å‹ | è§¦å‘æ¡ä»¶ | åŒæ­¥æ–¹å‘ | å®ç°æ–¹å¼ |
|---------|---------|---------|---------|
| **å†™å…¥åŒæ­¥** | æ•°æ®æ›´æ–° | API â†’ MongoDB â†’ Redis | å†™å…¥ç®¡é“ |
| **ç¼“å­˜å¤±æ•ˆ** | TTLè¿‡æœŸ | MongoDB â†’ Redis | æŒ‰éœ€åŠ è½½ |
| **å®šæœŸåŒæ­¥** | å®šæ—¶ä»»åŠ¡ | MongoDB â†’ Redis | åå°ä»»åŠ¡ |
| **å…¨é‡åŒæ­¥** | ç³»ç»Ÿå¯åŠ¨ | MongoDB â†’ Redis | å¯åŠ¨è„šæœ¬ |

## 6. æ•°æ®è®¿é—®å±‚è®¾è®¡

### 6.1 æŠ½è±¡æ¥å£

```python
class DataAccess:
    """æ•°æ®è®¿é—®æŠ½è±¡å±‚ï¼Œç»Ÿä¸€ç®¡ç†MongoDBå’ŒRedisè®¿é—®"""
    
    def __init__(self, config=None):
        self.config = config or DATABASE_CONFIG
        self.mongo_client = pymongo.MongoClient(self.config["mongodb"]["uri"])
        self.db = self.mongo_client[self.config["mongodb"]["db_name"]]
        self.redis_client = redis.Redis(
            host=self.config["redis"]["host"],
            port=self.config["redis"]["port"],
            db=self.config["redis"]["db"],
            password=self.config["redis"]["password"]
        )
        
    def get_price_data(self, symbol, start_date, end_date=None, timeframe="daily"):
        """è·å–ä»·æ ¼æ•°æ®ï¼Œä¼˜å…ˆä»ç¼“å­˜è·å–"""
        # å®ç°ä»£ç ...
        
    def get_fundamental_data(self, symbol, period=None, report_type=None):
        """è·å–åŸºæœ¬é¢æ•°æ®"""
        # å®ç°ä»£ç ...
        
    def get_news_data(self, symbol=None, start_time=None, limit=20):
        """è·å–æ–°é—»æ•°æ®"""
        # å®ç°ä»£ç ...
        
    def get_social_data(self, symbol, start_time=None, limit=20):
        """è·å–ç¤¾äº¤åª’ä½“æ•°æ®"""
        # å®ç°ä»£ç ...
        
    def get_analysis_results(self, symbol, date=None, analyst=None):
        """è·å–åˆ†æç»“æœ"""
        # å®ç°ä»£ç ...
        
    def save_price_data(self, symbol, data, timeframe="daily"):
        """ä¿å­˜ä»·æ ¼æ•°æ®"""
        # å®ç°ä»£ç ...
        
    # å…¶ä»–æ•°æ®è®¿é—®æ–¹æ³•...
```

### 6.2 åˆ†å¸ƒå¼é”å®ç°

```python
def acquire_lock(resource_name, timeout=10):
    """è·å–åˆ†å¸ƒå¼é”"""
    lock_key = f"ta:locks:{resource_name}"
    lock_value = str(uuid.uuid4())
    
    # å°è¯•è·å–é”ï¼Œè®¾ç½®è¿‡æœŸæ—¶é—´é˜²æ­¢æ­»é”
    acquired = redis_client.set(lock_key, lock_value, nx=True, ex=timeout)
    
    if acquired:
        return lock_value
    return None

def release_lock(resource_name, lock_value):
    """é‡Šæ”¾åˆ†å¸ƒå¼é”"""
    lock_key = f"ta:locks:{resource_name}"
    
    # ä½¿ç”¨Luaè„šæœ¬ç¡®ä¿åŸå­æ€§æ“ä½œ
    script = """
    if redis.call('get', KEYS[1]) == ARGV[1] then
        return redis.call('del', KEYS[1])
    else
        return 0
    end
    """
    redis_client.eval(script, 1, lock_key, lock_value)
```

## 7. é…ç½®è®¾è®¡

### 7.1 MongoDB é…ç½®

```yaml
# MongoDB é…ç½®æ–‡ä»¶
storage:
  dbPath: /var/lib/mongodb
  journal:
    enabled: true
  directoryPerDB: true
  wiredTiger:
    engineConfig:
      cacheSizeGB: 2
      journalCompressor: snappy

systemLog:
  destination: file
  path: /var/log/mongodb/mongod.log
  logAppend: true

net:
  port: 27017
  bindIp: 127.0.0.1

security:
  authorization: enabled

processManagement:
  timeZoneInfo: /usr/share/zoneinfo
```

### 7.2 Redis é…ç½®

```
# Redis é…ç½®æ–‡ä»¶
port 6379
bind 127.0.0.1
protected-mode yes

# å†…å­˜é…ç½®
maxmemory 1gb
maxmemory-policy allkeys-lru

# æŒä¹…åŒ–é…ç½®
appendonly yes
appendfsync everysec

# è¶…æ—¶é…ç½®
timeout 0

# æ—¥å¿—é…ç½®
loglevel notice
logfile /var/log/redis/redis-server.log

# æ•°æ®åº“æ•°é‡
databases 16

# æ€§èƒ½ä¼˜åŒ–
tcp-keepalive 300
```

### 7.3 åº”ç”¨é…ç½®

```python
DATABASE_CONFIG = {
    "mongodb": {
        "uri": "mongodb://localhost:27017/",
        "db_name": "tradingagents",
        "options": {
            "connectTimeoutMS": 5000,
            "socketTimeoutMS": 30000,
            "maxPoolSize": 50,
            "minPoolSize": 5
        },
        "collections": {
            "market_data": "market_data",
            "fundamental_data": "fundamental_data",
            "news_data": "news_data",
            "social_data": "social_data",
            "analysis_results": "analysis_results",
            "metadata": "metadata"
        }
    },
    "redis": {
        "host": "localhost",
        "port": 6379,
        "db": 0,
        "password": None,
        "key_prefix": "ta:",
        "ttl": {
            "price_data": 86400,      # 1å¤©
            "quote_data": 60,         # 1åˆ†é’Ÿ
            "news_data": 900,         # 15åˆ†é’Ÿ
            "social_data": 300,       # 5åˆ†é’Ÿ
            "analysis_results": 3600  # 1å°æ—¶
        }
    },
    "file_storage": {
        "enabled": True,              # æ˜¯å¦ä¿ç•™æ–‡ä»¶å­˜å‚¨
        "base_dir": "./data",
        "backup_frequency": "daily"   # æ–‡ä»¶å¤‡ä»½é¢‘ç‡
    }
}
```

## 8. æ€§èƒ½ä¼˜åŒ–

### 8.1 MongoDB æ€§èƒ½ä¼˜åŒ–

1. **ç´¢å¼•ä¼˜åŒ–**
   - ä¸ºå¸¸ç”¨æŸ¥è¯¢åˆ›å»ºé€‚å½“ç´¢å¼•
   - å®šæœŸåˆ†ææ…¢æŸ¥è¯¢å¹¶ä¼˜åŒ–
   - é¿å…è¿‡å¤šç´¢å¼•å¯¼è‡´å†™å…¥æ€§èƒ½ä¸‹é™

2. **æ–‡æ¡£è®¾è®¡ä¼˜åŒ–**
   - é¿å…è¿‡å¤§æ–‡æ¡£ï¼ˆä¿æŒ<16MBï¼‰
   - åˆç†è®¾è®¡åµŒå¥—ç»“æ„
   - é€‚å½“åè§„èŒƒåŒ–ä»¥å‡å°‘æŸ¥è¯¢æ¬¡æ•°

3. **æŸ¥è¯¢ä¼˜åŒ–**
   - ä½¿ç”¨æŠ•å½±é™åˆ¶è¿”å›å­—æ®µ
   - åˆ©ç”¨èšåˆç®¡é“å‡å°‘æ•°æ®ä¼ è¾“
   - æ‰¹é‡æ“ä½œå‡å°‘ç½‘ç»œå¾€è¿”

4. **è¿æ¥æ± ç®¡ç†**
   - é…ç½®é€‚å½“çš„è¿æ¥æ± å¤§å°
   - ç›‘æ§è¿æ¥ä½¿ç”¨æƒ…å†µ
   - åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„è¿æ¥

### 8.2 Redis æ€§èƒ½ä¼˜åŒ–

1. **å†…å­˜ç®¡ç†**
   - è®¾ç½®åˆç†çš„maxmemory
   - é€‰æ‹©é€‚å½“çš„æ·˜æ±°ç­–ç•¥
   - ç›‘æ§å†…å­˜ä½¿ç”¨ç‡

2. **æ•°æ®ç»“æ„é€‰æ‹©**
   - ä¸ºä¸åŒæ•°æ®é€‰æ‹©æœ€åˆé€‚çš„æ•°æ®ç»“æ„
   - ä½¿ç”¨Hashå­˜å‚¨å¯¹è±¡è€Œéå¤šä¸ªString
   - åˆ©ç”¨Sorted Setå®ç°æ—¶é—´åºåˆ—æ•°æ®

3. **æ‰¹é‡æ“ä½œ**
   - ä½¿ç”¨pipelineå‡å°‘ç½‘ç»œå¾€è¿”
   - ä½¿ç”¨mget/msetä»£æ›¿å¤šæ¬¡get/set
   - åˆç†ä½¿ç”¨Luaè„šæœ¬å®ç°åŸå­æ“ä½œ

4. **é”®è®¾è®¡**
   - é¿å…è¿‡é•¿çš„é”®å
   - ä½¿ç”¨ä¸€è‡´çš„å‘½åè§„èŒƒ
   - åˆç†è®¾ç½®TTLé¿å…å†…å­˜æ³„æ¼

## 9. é«˜å¯ç”¨è®¾è®¡

### 9.1 MongoDB é›†ç¾¤è®¾è®¡

```
MongoDB é›†ç¾¤
â”œâ”€â”€ é…ç½®æœåŠ¡å™¨ (3èŠ‚ç‚¹)
â”‚   â”œâ”€â”€ configsvr1: 27019
â”‚   â”œâ”€â”€ configsvr2: 27019
â”‚   â””â”€â”€ configsvr3: 27019
â”œâ”€â”€ åˆ†ç‰‡æœåŠ¡å™¨ (2åˆ†ç‰‡)
â”‚   â”œâ”€â”€ shard1 (3èŠ‚ç‚¹å‰¯æœ¬é›†)
â”‚   â”‚   â”œâ”€â”€ shard1svr1: 27018 (Primary)
â”‚   â”‚   â”œâ”€â”€ shard1svr2: 27018 (Secondary)
â”‚   â”‚   â””â”€â”€ shard1svr3: 27018 (Secondary)
â”‚   â””â”€â”€ shard2 (3èŠ‚ç‚¹å‰¯æœ¬é›†)
â”‚       â”œâ”€â”€ shard2svr1: 27018 (Primary)
â”‚       â”œâ”€â”€ shard2svr2: 27018 (Secondary)
â”‚       â””â”€â”€ shard2svr3: 27018 (Secondary)
â””â”€â”€ è·¯ç”±æœåŠ¡å™¨ (2èŠ‚ç‚¹)
    â”œâ”€â”€ mongos1: 27017
    â””â”€â”€ mongos2: 27017
```

### 9.2 Redis é›†ç¾¤è®¾è®¡

```
Redis é›†ç¾¤
â”œâ”€â”€ ä¸»ä»å¤åˆ¶ (3ç»„)
â”‚   â”œâ”€â”€ ç»„1
â”‚   â”‚   â”œâ”€â”€ master1: 6379
â”‚   â”‚   â””â”€â”€ slave1: 6380
â”‚   â”œâ”€â”€ ç»„2
â”‚   â”‚   â”œâ”€â”€ master2: 6381
â”‚   â”‚   â””â”€â”€ slave2: 6382
â”‚   â””â”€â”€ ç»„3
â”‚       â”œâ”€â”€ master3: 6383
â”‚       â””â”€â”€ slave3: 6384
â””â”€â”€ Sentinel (3èŠ‚ç‚¹)
    â”œâ”€â”€ sentinel1: 26379
    â”œâ”€â”€ sentinel2: 26380
    â””â”€â”€ sentinel3: 26381
```

### 9.3 æ•…éšœè½¬ç§»ç­–ç•¥

1. **MongoDB æ•…éšœè½¬ç§»**
   - å‰¯æœ¬é›†è‡ªåŠ¨é€‰ä¸¾æ–°ä¸»èŠ‚ç‚¹
   - åº”ç”¨å±‚è‡ªåŠ¨é‡è¿åˆ°æ–°ä¸»èŠ‚ç‚¹
   - ç›‘æ§ç³»ç»Ÿå‘é€æ•…éšœé€šçŸ¥

2. **Redis æ•…éšœè½¬ç§»**
   - Sentinelè‡ªåŠ¨ç›‘æµ‹ä¸»èŠ‚ç‚¹æ•…éšœ
   - è‡ªåŠ¨é€‰ä¸¾æ–°ä¸»èŠ‚ç‚¹
   - å®¢æˆ·ç«¯é€šè¿‡Sentinelå‘ç°æ–°ä¸»èŠ‚ç‚¹

3. **åº”ç”¨å±‚æ•…éšœå¤„ç†**
   - è¿æ¥æ± è‡ªåŠ¨é‡è¿
   - æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥
   - é™çº§æœåŠ¡æœºåˆ¶

## 10. ç›‘æ§ä¸è¿ç»´

### 10.1 ç›‘æ§æŒ‡æ ‡

| ç›‘æ§ç±»åˆ« | ç›‘æ§æŒ‡æ ‡ | å‘Šè­¦é˜ˆå€¼ | å¤„ç†ç­–ç•¥ |
|---------|---------|---------|---------|
| **MongoDB** | æŸ¥è¯¢å»¶è¿Ÿ | >100ms | ä¼˜åŒ–ç´¢å¼•æˆ–æŸ¥è¯¢ |
| **MongoDB** | è¿æ¥æ•° | >80% | å¢åŠ è¿æ¥æ±  |
| **MongoDB** | å†…å­˜ä½¿ç”¨ | >80% | å¢åŠ å†…å­˜æˆ–ä¼˜åŒ–æŸ¥è¯¢ |
| **Redis** | å†…å­˜ä½¿ç”¨ | >80% | è°ƒæ•´æ·˜æ±°ç­–ç•¥æˆ–å¢åŠ å†…å­˜ |
| **Redis** | å‘½ä¸­ç‡ | <80% | è°ƒæ•´ç¼“å­˜ç­–ç•¥ |
| **Redis** | å»¶è¿Ÿ | >10ms | æ£€æŸ¥ç½‘ç»œæˆ–å‘½ä»¤å¤æ‚åº¦ |

### 10.2 å¤‡ä»½ç­–ç•¥

1. **MongoDB å¤‡ä»½**
   - æ¯æ—¥å…¨é‡å¤‡ä»½
   - æ¯å°æ—¶å¢é‡å¤‡ä»½
   - è·¨åŒºåŸŸå¤‡ä»½å­˜å‚¨

2. **Redis å¤‡ä»½**
   - RDBå®šæ—¶å¿«ç…§
   - AOFæŒä¹…åŒ–
   - ä¸»ä»å¤åˆ¶ä½œä¸ºå®æ—¶å¤‡ä»½

3. **æ–‡ä»¶å¤‡ä»½**
   - å…³é”®æ•°æ®å®šæœŸå½’æ¡£
   - å¢é‡å¤‡ä»½ç­–ç•¥
   - å¤šå‰¯æœ¬å­˜å‚¨

### 10.3 è¿ç»´å·¥å…·

1. **ç›‘æ§å·¥å…·**
   - Prometheus + Grafana
   - MongoDB Atlasç›‘æ§
   - Redis Insight

2. **è¿ç»´è„šæœ¬**
   - è‡ªåŠ¨å¤‡ä»½è„šæœ¬
   - æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
   - æ€§èƒ½è¯Šæ–­å·¥å…·

## 11. å®æ–½è·¯çº¿å›¾

### 11.1 ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ•´åˆï¼ˆ1-2å‘¨ï¼‰

1. å®‰è£…é…ç½®MongoDBå’ŒRedis
2. å¼€å‘æ•°æ®è®¿é—®æŠ½è±¡å±‚
3. è¿ç§»æ ¸å¿ƒæ•°æ®åˆ°MongoDB
4. å®ç°åŸºæœ¬ç¼“å­˜ç­–ç•¥

### 11.2 ç¬¬äºŒé˜¶æ®µï¼šåŠŸèƒ½å®Œå–„ï¼ˆ2-3å‘¨ï¼‰

1. å®Œå–„æ‰€æœ‰æ•°æ®ç±»å‹çš„å­˜å‚¨å’Œç¼“å­˜
2. å®ç°åˆ†å¸ƒå¼é”å’Œä»»åŠ¡é˜Ÿåˆ—
3. å¼€å‘æ•°æ®åŒæ­¥å’Œä¸€è‡´æ€§ç®¡ç†
4. æ·»åŠ åŸºæœ¬ç›‘æ§å’Œå‘Šè­¦

### 11.3 ç¬¬ä¸‰é˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆ2å‘¨ï¼‰

1. ä¼˜åŒ–ç´¢å¼•å’ŒæŸ¥è¯¢æ€§èƒ½
2. å®ç°é«˜çº§ç¼“å­˜ç­–ç•¥
3. æ·»åŠ æ•°æ®å‹ç¼©å’Œåˆ†åŒº
4. å®Œå–„ç›‘æ§å’Œæ€§èƒ½åˆ†æ

### 11.4 ç¬¬å››é˜¶æ®µï¼šé«˜å¯ç”¨éƒ¨ç½²ï¼ˆ2-3å‘¨ï¼‰

1. éƒ¨ç½²MongoDBå‰¯æœ¬é›†æˆ–åˆ†ç‰‡é›†ç¾¤
2. é…ç½®Redisä¸»ä»å¤åˆ¶å’Œå“¨å…µ
3. å®ç°è‡ªåŠ¨æ•…éšœè½¬ç§»
4. å¼€å‘å®Œæ•´çš„è¿ç»´å·¥å…·

## 12. æ€»ç»“

TradingAgents-CN çš„æ•°æ®åº“æ¶æ„è®¾è®¡åŸºäº MongoDB å’Œ Redisï¼Œæä¾›äº†é«˜æ€§èƒ½ã€å¯æ‰©å±•ã€é«˜å¯ç”¨çš„æ•°æ®ç®¡ç†è§£å†³æ–¹æ¡ˆã€‚è¯¥æ¶æ„å…·æœ‰ä»¥ä¸‹æ ¸å¿ƒä¼˜åŠ¿ï¼š

1. **é«˜æ€§èƒ½æ•°æ®è®¿é—®**ï¼šRedisæä¾›æ¯«ç§’çº§çš„æ•°æ®è¯»å–ï¼ŒMongoDBæä¾›çµæ´»çš„æŸ¥è¯¢èƒ½åŠ›
2. **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒæ•°æ®é‡å¢é•¿å’Œç”¨æˆ·å¹¶å‘è®¿é—®
3. **æ•°æ®ä¸€è‡´æ€§**ï¼šè‡ªåŠ¨åŒ–çš„æ•°æ®åŒæ­¥å’Œç¼“å­˜ç®¡ç†
4. **é«˜å¯ç”¨æ€§**ï¼šæ”¯æŒæ•…éšœè½¬ç§»å’Œè´Ÿè½½å‡è¡¡
5. **è¿ç»´ç®€åŒ–**ï¼šæ ‡å‡†åŒ–çš„æ•°æ®ç®¡ç†å’Œç›‘æ§

è¿™ç§æ¶æ„ä¸ä»…æ»¡è¶³å½“å‰éœ€æ±‚ï¼Œè¿˜ä¸ºæœªæ¥çš„åŠŸèƒ½æ‰©å±•å’Œæ€§èƒ½ä¼˜åŒ–æä¾›äº†åšå®åŸºç¡€ï¼Œä½¿TradingAgents-CNèƒ½å¤Ÿå¤„ç†æ›´å¤§è§„æ¨¡çš„æ•°æ®å’Œæ›´å¤æ‚çš„åˆ†æä»»åŠ¡ã€‚

<!-- docs/architecture/graph-structure.md -->

# LangGraph å›¾ç»“æ„è®¾è®¡

## æ¦‚è¿°

TradingAgents åŸºäº LangGraph æ¡†æ¶æ„å»ºï¼Œé‡‡ç”¨æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰ç»“æ„æ¥ç»„ç»‡æ™ºèƒ½ä½“çš„å·¥ä½œæµç¨‹ã€‚è¿™ç§è®¾è®¡ç¡®ä¿äº†æ™ºèƒ½ä½“ä¹‹é—´çš„æœ‰åºåä½œå’Œä¿¡æ¯çš„æ­£ç¡®æµè½¬ã€‚

## å›¾ç»“æ„æ¶æ„

### æ•´ä½“å·¥ä½œæµå›¾

```mermaid
graph TD
    START([å¼€å§‹]) --> INIT[åˆå§‹åŒ–çŠ¶æ€]
    INIT --> PARALLEL_ANALYSIS{å¹¶è¡Œåˆ†æé˜¶æ®µ}
    
    PARALLEL_ANALYSIS --> FA[åŸºæœ¬é¢åˆ†æå¸ˆ]
    PARALLEL_ANALYSIS --> TA[æŠ€æœ¯åˆ†æå¸ˆ]
    PARALLEL_ANALYSIS --> NA[æ–°é—»åˆ†æå¸ˆ]
    PARALLEL_ANALYSIS --> SA[ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ]
    
    FA --> COLLECT_ANALYSIS[æ”¶é›†åˆ†æç»“æœ]
    TA --> COLLECT_ANALYSIS
    NA --> COLLECT_ANALYSIS
    SA --> COLLECT_ANALYSIS
    
    COLLECT_ANALYSIS --> RESEARCH_MANAGER[ç ”ç©¶ç»ç†]
    RESEARCH_MANAGER --> DEBATE_INIT[åˆå§‹åŒ–è¾©è®º]
    
    DEBATE_INIT --> BULL_RESEARCHER[çœ‹æ¶¨ç ”ç©¶å‘˜]
    DEBATE_INIT --> BEAR_RESEARCHER[çœ‹è·Œç ”ç©¶å‘˜]
    
    BULL_RESEARCHER --> DEBATE_ROUND{è¾©è®ºè½®æ¬¡}
    BEAR_RESEARCHER --> DEBATE_ROUND
    
    DEBATE_ROUND -->|ç»§ç»­è¾©è®º| BULL_RESEARCHER
    DEBATE_ROUND -->|è¾©è®ºç»“æŸ| RESEARCH_CONSENSUS[ç ”ç©¶å…±è¯†]
    
    RESEARCH_CONSENSUS --> TRADER[äº¤æ˜“å‘˜]
    TRADER --> TRADING_DECISION[äº¤æ˜“å†³ç­–]
    
    TRADING_DECISION --> RISK_PARALLEL{å¹¶è¡Œé£é™©è¯„ä¼°}
    
    RISK_PARALLEL --> AGGRESSIVE_RISK[æ¿€è¿›é£é™©è¯„ä¼°]
    RISK_PARALLEL --> CONSERVATIVE_RISK[ä¿å®ˆé£é™©è¯„ä¼°]
    RISK_PARALLEL --> NEUTRAL_RISK[ä¸­æ€§é£é™©è¯„ä¼°]
    
    AGGRESSIVE_RISK --> RISK_DEBATE[é£é™©è¾©è®º]
    CONSERVATIVE_RISK --> RISK_DEBATE
    NEUTRAL_RISK --> RISK_DEBATE
    
    RISK_DEBATE --> RISK_MANAGER[é£é™©ç»ç†]
    RISK_MANAGER --> PORTFOLIO_DECISION[æŠ•èµ„ç»„åˆå†³ç­–]
    
    PORTFOLIO_DECISION --> END([ç»“æŸ])
```

## æ ¸å¿ƒç»„ä»¶è®¾è®¡

### 1. å›¾æ„å»ºå™¨ (GraphSetup)

```python
class GraphSetup:
    """LangGraph å›¾ç»“æ„è®¾ç½®"""
    
    def build_graph(self) -> StateGraph:
        """æ„å»ºå®Œæ•´çš„äº¤æ˜“å†³ç­–å›¾"""
        
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        self._add_analysis_nodes(workflow)
        self._add_research_nodes(workflow)
        self._add_trading_nodes(workflow)
        self._add_risk_nodes(workflow)
        
        # æ·»åŠ è¾¹å’Œæ¡ä»¶é€»è¾‘
        self._add_edges(workflow)
        self._add_conditional_edges(workflow)
        
        # è®¾ç½®å…¥å£å’Œå‡ºå£
        workflow.set_entry_point("initialize")
        workflow.set_finish_point("portfolio_decision")
        
        return workflow.compile()
    
    def _add_analysis_nodes(self, workflow: StateGraph):
        """æ·»åŠ åˆ†æå¸ˆèŠ‚ç‚¹"""
        workflow.add_node("fundamentals_analyst", self.fundamentals_analyst)
        workflow.add_node("technical_analyst", self.technical_analyst)
        workflow.add_node("news_analyst", self.news_analyst)
        workflow.add_node("social_analyst", self.social_analyst)
    
    def _add_research_nodes(self, workflow: StateGraph):
        """æ·»åŠ ç ”ç©¶å‘˜èŠ‚ç‚¹"""
        workflow.add_node("research_manager", self.research_manager)
        workflow.add_node("bull_researcher", self.bull_researcher)
        workflow.add_node("bear_researcher", self.bear_researcher)
    
    def _add_trading_nodes(self, workflow: StateGraph):
        """æ·»åŠ äº¤æ˜“èŠ‚ç‚¹"""
        workflow.add_node("trader", self.trader)
    
    def _add_risk_nodes(self, workflow: StateGraph):
        """æ·»åŠ é£é™©ç®¡ç†èŠ‚ç‚¹"""
        workflow.add_node("aggressive_risk", self.aggressive_risk)
        workflow.add_node("conservative_risk", self.conservative_risk)
        workflow.add_node("neutral_risk", self.neutral_risk)
        workflow.add_node("risk_manager", self.risk_manager)
```

### 2. æ¡ä»¶é€»è¾‘ (ConditionalLogic)

```python
class ConditionalLogic:
    """å›¾çš„æ¡ä»¶é€»è¾‘æ§åˆ¶"""
    
    def should_continue_debate(self, state: AgentState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­ç ”ç©¶å‘˜è¾©è®º"""
        
        current_round = state.get("debate_round", 0)
        max_rounds = self.config.get("max_debate_rounds", 3)
        
        # æ£€æŸ¥è¾©è®ºè½®æ¬¡
        if current_round >= max_rounds:
            return "end_debate"
        
        # æ£€æŸ¥æ˜¯å¦è¾¾æˆå…±è¯†
        if self._has_consensus(state):
            return "end_debate"
        
        # æ£€æŸ¥åˆ†æ­§æ˜¯å¦è¶³å¤Ÿå¤§
        if self._has_significant_disagreement(state):
            return "continue_debate"
        
        return "end_debate"
    
    def route_to_risk_assessment(self, state: AgentState) -> List[str]:
        """è·¯ç”±åˆ°é£é™©è¯„ä¼°èŠ‚ç‚¹"""
        
        trading_decision = state.get("trader_decision", {})
        risk_level = trading_decision.get("risk_level", "medium")
        
        # æ ¹æ®é£é™©çº§åˆ«å†³å®šè¯„ä¼°è·¯å¾„
        if risk_level == "high":
            return ["aggressive_risk", "conservative_risk", "neutral_risk"]
        elif risk_level == "low":
            return ["conservative_risk", "neutral_risk"]
        else:
            return ["neutral_risk"]
    
    def should_approve_trade(self, state: AgentState) -> str:
        """åˆ¤æ–­æ˜¯å¦æ‰¹å‡†äº¤æ˜“"""
        
        risk_assessment = state.get("risk_assessment", {})
        risk_score = risk_assessment.get("overall_risk_score", 0.5)
        
        # é£é™©é˜ˆå€¼æ£€æŸ¥
        if risk_score > self.config.get("risk_threshold", 0.8):
            return "reject_trade"
        
        # ä¸€è‡´æ€§æ£€æŸ¥
        if self._risk_assessments_consistent(state):
            return "approve_trade"
        
        return "request_review"
```

### 3. çŠ¶æ€ä¼ æ’­ (Propagator)

```python
class Propagator:
    """çŠ¶æ€ä¼ æ’­ç®¡ç†å™¨"""
    
    def propagate(self, symbol: str, date: str) -> Tuple[AgentState, Dict]:
        """æ‰§è¡Œå®Œæ•´çš„ä¼ æ’­æµç¨‹"""
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = self._initialize_state(symbol, date)
        
        # æ‰§è¡Œå›¾ä¼ æ’­
        final_state = self.graph.invoke(initial_state)
        
        # æå–å†³ç­–ç»“æœ
        decision = self._extract_decision(final_state)
        
        return final_state, decision
    
    def _initialize_state(self, symbol: str, date: str) -> AgentState:
        """åˆå§‹åŒ–æ™ºèƒ½ä½“çŠ¶æ€"""
        return AgentState(
            ticker=symbol,
            date=date,
            analyst_reports={},
            research_reports={},
            trader_decision={},
            risk_assessment={},
            portfolio_decision={},
            messages=[],
            metadata={}
        )
    
    def _extract_decision(self, state: AgentState) -> Dict:
        """ä»æœ€ç»ˆçŠ¶æ€æå–å†³ç­–ä¿¡æ¯"""
        return {
            "action": state.portfolio_decision.get("action", "hold"),
            "quantity": state.portfolio_decision.get("quantity", 0),
            "confidence": state.portfolio_decision.get("confidence", 0.5),
            "reasoning": state.portfolio_decision.get("reasoning", ""),
            "risk_score": state.risk_assessment.get("overall_risk_score", 0.5)
        }
```

## èŠ‚ç‚¹ç±»å‹è¯¦è§£

### 1. åˆ†æèŠ‚ç‚¹ (Analysis Nodes)
```python
def fundamentals_analyst_node(state: AgentState) -> AgentState:
    """åŸºæœ¬é¢åˆ†æå¸ˆèŠ‚ç‚¹"""
    
    # è·å–æ•°æ®
    data = get_fundamental_data(state.ticker, state.date)
    
    # æ‰§è¡Œåˆ†æ
    analysis = fundamentals_analyst.analyze(data)
    
    # æ›´æ–°çŠ¶æ€
    state.analyst_reports["fundamentals"] = analysis
    
    return state
```

### 2. å†³ç­–èŠ‚ç‚¹ (Decision Nodes)
```python
def trader_node(state: AgentState) -> AgentState:
    """äº¤æ˜“å‘˜å†³ç­–èŠ‚ç‚¹"""
    
    # æ”¶é›†æ‰€æœ‰åˆ†ææŠ¥å‘Š
    all_reports = {
        **state.analyst_reports,
        **state.research_reports
    }
    
    # åˆ¶å®šäº¤æ˜“å†³ç­–
    decision = trader.make_decision(all_reports)
    
    # æ›´æ–°çŠ¶æ€
    state.trader_decision = decision
    
    return state
```

### 3. å¹¶è¡ŒèŠ‚ç‚¹ (Parallel Nodes)
```python
def parallel_analysis_node(state: AgentState) -> AgentState:
    """å¹¶è¡Œåˆ†æèŠ‚ç‚¹"""
    
    # å¹¶è¡Œæ‰§è¡Œå¤šä¸ªåˆ†æå¸ˆ
    with ThreadPoolExecutor() as executor:
        futures = {
            executor.submit(fundamentals_analyst.analyze, state): "fundamentals",
            executor.submit(technical_analyst.analyze, state): "technical",
            executor.submit(news_analyst.analyze, state): "news",
            executor.submit(social_analyst.analyze, state): "social"
        }
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(futures):
            analyst_type = futures[future]
            result = future.result()
            state.analyst_reports[analyst_type] = result
    
    return state
```

## è¾¹å’Œè·¯ç”±è®¾è®¡

### 1. é¡ºåºè¾¹ (Sequential Edges)
```python
# ç®€å•çš„é¡ºåºè¿æ¥
workflow.add_edge("initialize", "parallel_analysis")
workflow.add_edge("parallel_analysis", "research_manager")
workflow.add_edge("research_manager", "trader")
```

### 2. æ¡ä»¶è¾¹ (Conditional Edges)
```python
# åŸºäºæ¡ä»¶çš„è·¯ç”±
workflow.add_conditional_edges(
    "debate_round",
    conditional_logic.should_continue_debate,
    {
        "continue_debate": "bull_researcher",
        "end_debate": "research_consensus"
    }
)
```

### 3. å¹¶è¡Œè¾¹ (Parallel Edges)
```python
# å¹¶è¡Œæ‰§è¡Œå¤šä¸ªèŠ‚ç‚¹
workflow.add_conditional_edges(
    "trading_decision",
    conditional_logic.route_to_risk_assessment,
    {
        "aggressive_risk": "aggressive_risk_node",
        "conservative_risk": "conservative_risk_node",
        "neutral_risk": "neutral_risk_node"
    }
)
```

## çŠ¶æ€ç®¡ç†

### 1. çŠ¶æ€ç»“æ„
```python
@dataclass
class AgentState:
    """æ™ºèƒ½ä½“çŠ¶æ€æ•°æ®ç»“æ„"""
    
    # åŸºæœ¬ä¿¡æ¯
    ticker: str
    date: str
    
    # åˆ†æç»“æœ
    analyst_reports: Dict[str, Any]
    research_reports: Dict[str, Any]
    
    # å†³ç­–ä¿¡æ¯
    trader_decision: Dict[str, Any]
    risk_assessment: Dict[str, Any]
    portfolio_decision: Dict[str, Any]
    
    # é€šä¿¡è®°å½•
    messages: List[BaseMessage]
    
    # å…ƒæ•°æ®
    metadata: Dict[str, Any]
    
    # æ§åˆ¶ä¿¡æ¯
    debate_round: int = 0
    risk_round: int = 0
```

### 2. çŠ¶æ€æ›´æ–°
```python
class StateManager:
    """çŠ¶æ€ç®¡ç†å™¨"""
    
    def update_state(self, state: AgentState, updates: Dict) -> AgentState:
        """å®‰å…¨åœ°æ›´æ–°çŠ¶æ€"""
        
        # æ·±æ‹·è´çŠ¶æ€
        new_state = copy.deepcopy(state)
        
        # åº”ç”¨æ›´æ–°
        for key, value in updates.items():
            if hasattr(new_state, key):
                setattr(new_state, key, value)
        
        # éªŒè¯çŠ¶æ€ä¸€è‡´æ€§
        self._validate_state(new_state)
        
        return new_state
    
    def _validate_state(self, state: AgentState):
        """éªŒè¯çŠ¶æ€ä¸€è‡´æ€§"""
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ["ticker", "date"]
        for field in required_fields:
            if not getattr(state, field):
                raise ValueError(f"Required field {field} is missing")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if not isinstance(state.analyst_reports, dict):
            raise TypeError("analyst_reports must be a dictionary")
```

## é”™è¯¯å¤„ç†å’Œæ¢å¤

### 1. èŠ‚ç‚¹çº§é”™è¯¯å¤„ç†
```python
def safe_node_execution(node_func):
    """èŠ‚ç‚¹æ‰§è¡Œçš„å®‰å…¨åŒ…è£…å™¨"""
    
    def wrapper(state: AgentState) -> AgentState:
        try:
            return node_func(state)
        except Exception as e:
            # è®°å½•é”™è¯¯
            logger.error(f"Node {node_func.__name__} failed: {e}")
            
            # æ·»åŠ é”™è¯¯ä¿¡æ¯åˆ°çŠ¶æ€
            state.metadata["errors"] = state.metadata.get("errors", [])
            state.metadata["errors"].append({
                "node": node_func.__name__,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            })
            
            return state
    
    return wrapper
```

### 2. å›¾çº§é”™è¯¯æ¢å¤
```python
class GraphRecovery:
    """å›¾æ‰§è¡Œæ¢å¤æœºåˆ¶"""
    
    def execute_with_recovery(self, graph, initial_state):
        """å¸¦æ¢å¤æœºåˆ¶çš„å›¾æ‰§è¡Œ"""
        
        try:
            return graph.invoke(initial_state)
        except Exception as e:
            # å°è¯•ä»æ£€æŸ¥ç‚¹æ¢å¤
            if checkpoint := self._find_last_checkpoint(initial_state):
                logger.info("Recovering from checkpoint")
                return self._recover_from_checkpoint(graph, checkpoint)
            
            # é™çº§æ‰§è¡Œ
            logger.warning("Falling back to degraded execution")
            return self._degraded_execution(initial_state)
```

è¿™ç§å›¾ç»“æ„è®¾è®¡ç¡®ä¿äº†æ™ºèƒ½ä½“å·¥ä½œæµçš„æ¸…æ™°æ€§ã€å¯ç»´æŠ¤æ€§å’Œå®¹é”™æ€§ï¼ŒåŒæ—¶æä¾›äº†çµæ´»çš„æ‰©å±•æœºåˆ¶ã€‚


<!-- docs/architecture/system-architecture.md -->

# ç³»ç»Ÿæ¶æ„

## æ¦‚è¿°

TradingAgents æ˜¯ä¸€ä¸ªåŸºäºå¤šæ™ºèƒ½ä½“çš„é‡‘èäº¤æ˜“æ¡†æ¶ï¼Œé‡‡ç”¨åˆ†å±‚æ¶æ„è®¾è®¡ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œäº¤æ˜“å…¬å¸çš„è¿ä½œæ¨¡å¼ã€‚ç³»ç»Ÿé€šè¿‡å¤šä¸ªä¸“ä¸šåŒ–çš„AIæ™ºèƒ½ä½“åä½œï¼Œå®ç°ä»å¸‚åœºåˆ†æåˆ°äº¤æ˜“æ‰§è¡Œçš„å®Œæ•´æµç¨‹ã€‚

## æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "ç”¨æˆ·æ¥å£å±‚"
        CLI[å‘½ä»¤è¡Œç•Œé¢]
        API[Python API]
        WEB[Webç•Œé¢]
    end
    
    subgraph "æ ¸å¿ƒæ¡†æ¶å±‚"
        TG[TradingAgentsGraph]
        CL[ConditionalLogic]
        PROP[Propagator]
        REF[Reflector]
        SP[SignalProcessor]
    end
    
    subgraph "æ™ºèƒ½ä½“å±‚"
        subgraph "åˆ†æå¸ˆå›¢é˜Ÿ"
            FA[åŸºæœ¬é¢åˆ†æå¸ˆ]
            MA[å¸‚åœºåˆ†æå¸ˆ]
            NA[æ–°é—»åˆ†æå¸ˆ]
            SA[ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ]
        end
        
        subgraph "ç ”ç©¶å‘˜å›¢é˜Ÿ"
            BR[çœ‹æ¶¨ç ”ç©¶å‘˜]
            BEAR[çœ‹è·Œç ”ç©¶å‘˜]
        end
        
        subgraph "äº¤æ˜“æ‰§è¡Œ"
            TRADER[äº¤æ˜“å‘˜]
        end
        
        subgraph "é£é™©ç®¡ç†"
            AGG[æ¿€è¿›é£é™©è¯„ä¼°]
            CON[ä¿å®ˆé£é™©è¯„ä¼°]
            NEU[ä¸­æ€§é£é™©è¯„ä¼°]
        end
        
        subgraph "ç®¡ç†å±‚"
            RM[ç ”ç©¶ç»ç†]
            RISKM[é£é™©ç»ç†]
        end
    end
    
    subgraph "æ•°æ®å±‚"
        subgraph "å¤–éƒ¨æ•°æ®æº"
            FINN[FinnHub API]
            YF[Yahoo Finance]
            REDDIT[Reddit API]
            NEWS[Google News]
        end
        
        subgraph "æ•°æ®å¤„ç†"
            CACHE[æ•°æ®ç¼“å­˜]
            PROC[æ•°æ®å¤„ç†å™¨]
        end
    end
    
    subgraph "LLMå±‚"
        OPENAI[OpenAI]
        ANTHROPIC[Anthropic]
        GOOGLE[Google AI]
    end
    
    CLI --> TG
    API --> TG
    WEB --> TG
    
    TG --> CL
    TG --> PROP
    TG --> REF
    TG --> SP
    
    CL --> FA
    CL --> MA
    CL --> NA
    CL --> SA
    CL --> BR
    CL --> BEAR
    CL --> TRADER
    CL --> AGG
    CL --> CON
    CL --> NEU
    CL --> RM
    CL --> RISKM
    
    FA --> PROC
    MA --> PROC
    NA --> PROC
    SA --> PROC
    
    PROC --> FINN
    PROC --> YF
    PROC --> REDDIT
    PROC --> NEWS
    
    PROC --> CACHE
    
    FA --> OPENAI
    MA --> ANTHROPIC
    NA --> GOOGLE
    SA --> OPENAI
    BR --> OPENAI
    BEAR --> OPENAI
    TRADER --> OPENAI
    AGG --> OPENAI
    CON --> OPENAI
    NEU --> OPENAI
    RM --> OPENAI
    RISKM --> OPENAI
```

## æ¶æ„å±‚æ¬¡

### 1. ç”¨æˆ·æ¥å£å±‚
- **å‘½ä»¤è¡Œç•Œé¢ (CLI)**: æä¾›äº¤äº’å¼å‘½ä»¤è¡Œå·¥å…·
- **Python API**: ç¨‹åºåŒ–æ¥å£ï¼Œæ”¯æŒé›†æˆåˆ°å…¶ä»–ç³»ç»Ÿ
- **Webç•Œé¢**: åŸºäºChainlitçš„Webç”¨æˆ·ç•Œé¢

### 2. æ ¸å¿ƒæ¡†æ¶å±‚
- **TradingAgentsGraph**: ä¸»è¦çš„ç¼–æ’ç±»ï¼Œç®¡ç†æ•´ä¸ªäº¤æ˜“æµç¨‹
- **ConditionalLogic**: æ¡ä»¶é€»è¾‘å¤„ç†ï¼Œæ§åˆ¶æ™ºèƒ½ä½“é—´çš„äº¤äº’æµç¨‹
- **Propagator**: ä¿¡æ¯ä¼ æ’­æœºåˆ¶ï¼Œç®¡ç†æ™ºèƒ½ä½“é—´çš„ä¿¡æ¯æµ
- **Reflector**: åæ€æœºåˆ¶ï¼Œæ”¯æŒä»å†å²å†³ç­–ä¸­å­¦ä¹ 
- **SignalProcessor**: ä¿¡å·å¤„ç†ï¼Œæ•´åˆå„æ™ºèƒ½ä½“çš„è¾“å‡º

### 3. æ™ºèƒ½ä½“å±‚
é‡‡ç”¨ä¸“ä¸šåŒ–åˆ†å·¥çš„å¤šæ™ºèƒ½ä½“æ¶æ„ï¼š

#### åˆ†æå¸ˆå›¢é˜Ÿ
- **åŸºæœ¬é¢åˆ†æå¸ˆ**: åˆ†æå…¬å¸è´¢åŠ¡æ•°æ®å’ŒåŸºæœ¬é¢æŒ‡æ ‡
- **å¸‚åœºåˆ†æå¸ˆ**: åˆ†ææŠ€æœ¯æŒ‡æ ‡å’Œå¸‚åœºè¶‹åŠ¿
- **æ–°é—»åˆ†æå¸ˆ**: å¤„ç†æ–°é—»äº‹ä»¶å’Œå®è§‚ç»æµæ•°æ®
- **ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ**: åˆ†æç¤¾äº¤åª’ä½“æƒ…ç»ªå’Œèˆ†è®º

#### ç ”ç©¶å‘˜å›¢é˜Ÿ
- **çœ‹æ¶¨ç ”ç©¶å‘˜**: ä»ä¹è§‚è§’åº¦è¯„ä¼°æŠ•èµ„æœºä¼š
- **çœ‹è·Œç ”ç©¶å‘˜**: ä»æ‚²è§‚è§’åº¦è¯„ä¼°æŠ•èµ„é£é™©

#### äº¤æ˜“æ‰§è¡Œ
- **äº¤æ˜“å‘˜**: ç»¼åˆå„æ–¹ä¿¡æ¯åšå‡ºæœ€ç»ˆäº¤æ˜“å†³ç­–

#### é£é™©ç®¡ç†
- **æ¿€è¿›é£é™©è¯„ä¼°**: è¯„ä¼°é«˜é£é™©é«˜æ”¶ç›Šç­–ç•¥
- **ä¿å®ˆé£é™©è¯„ä¼°**: è¯„ä¼°ä½é£é™©ç¨³å¥ç­–ç•¥
- **ä¸­æ€§é£é™©è¯„ä¼°**: å¹³è¡¡é£é™©æ”¶ç›Šçš„ä¸­æ€§è¯„ä¼°

#### ç®¡ç†å±‚
- **ç ”ç©¶ç»ç†**: åè°ƒç ”ç©¶å‘˜å›¢é˜Ÿçš„å·¥ä½œ
- **é£é™©ç»ç†**: ç®¡ç†æ•´ä½“é£é™©æ§åˆ¶æµç¨‹

### 4. æ•°æ®å±‚
#### å¤–éƒ¨æ•°æ®æº
- **FinnHub API**: å®æ—¶é‡‘èæ•°æ®
- **Yahoo Finance**: å†å²ä»·æ ¼å’Œè´¢åŠ¡æ•°æ®
- **Reddit API**: ç¤¾äº¤åª’ä½“æƒ…ç»ªæ•°æ®
- **Google News**: æ–°é—»å’Œäº‹ä»¶æ•°æ®

#### æ•°æ®å¤„ç†
- **æ•°æ®ç¼“å­˜**: æœ¬åœ°ç¼“å­˜æœºåˆ¶ï¼Œæé«˜æ€§èƒ½
- **æ•°æ®å¤„ç†å™¨**: ç»Ÿä¸€çš„æ•°æ®å¤„ç†æ¥å£

### 5. LLMå±‚
æ”¯æŒå¤šç§å¤§è¯­è¨€æ¨¡å‹æä¾›å•†ï¼š
- **OpenAI**: GPTç³»åˆ—æ¨¡å‹
- **Anthropic**: Claudeç³»åˆ—æ¨¡å‹
- **Google AI**: Geminiç³»åˆ—æ¨¡å‹

## æ ¸å¿ƒè®¾è®¡åŸåˆ™

### 1. æ¨¡å—åŒ–è®¾è®¡
- æ¯ä¸ªæ™ºèƒ½ä½“éƒ½æ˜¯ç‹¬ç«‹çš„æ¨¡å—
- æ”¯æŒæ’ä»¶å¼æ‰©å±•
- æ¾è€¦åˆçš„ç»„ä»¶è®¾è®¡

### 2. å¯æ‰©å±•æ€§
- æ”¯æŒæ·»åŠ æ–°çš„æ™ºèƒ½ä½“ç±»å‹
- æ”¯æŒæ–°çš„æ•°æ®æºé›†æˆ
- æ”¯æŒæ–°çš„LLMæä¾›å•†

### 3. å®¹é”™æ€§
- æ™ºèƒ½ä½“æ•…éšœéš”ç¦»
- æ•°æ®æºæ•…éšœè½¬ç§»
- ä¼˜é›…çš„é”™è¯¯å¤„ç†

### 4. æ€§èƒ½ä¼˜åŒ–
- æ•°æ®ç¼“å­˜æœºåˆ¶
- å¹¶è¡Œå¤„ç†èƒ½åŠ›
- æ™ºèƒ½çš„APIè°ƒç”¨ç®¡ç†

## æ•°æ®æµå‘

1. **æ•°æ®è·å–**: ä»å¤šä¸ªå¤–éƒ¨æ•°æ®æºè·å–å®æ—¶å’Œå†å²æ•°æ®
2. **æ•°æ®å¤„ç†**: æ¸…æ´—ã€æ ‡å‡†åŒ–å’Œç¼“å­˜æ•°æ®
3. **æ™ºèƒ½ä½“åˆ†æ**: å„ä¸“ä¸šæ™ºèƒ½ä½“å¹¶è¡Œåˆ†ææ•°æ®
4. **ä¿¡æ¯æ•´åˆ**: æ•´åˆå„æ™ºèƒ½ä½“çš„åˆ†æç»“æœ
5. **å†³ç­–åˆ¶å®š**: é€šè¿‡è¾©è®ºå’Œåå•†æœºåˆ¶å½¢æˆæœ€ç»ˆå†³ç­–
6. **é£é™©è¯„ä¼°**: é£é™©ç®¡ç†å›¢é˜Ÿè¯„ä¼°å†³ç­–é£é™©
7. **äº¤æ˜“æ‰§è¡Œ**: æ‰§è¡Œæœ€ç»ˆçš„äº¤æ˜“å†³ç­–

## æŠ€æœ¯æ ˆ

- **æ¡†æ¶**: LangGraph (åŸºäºLangChain)
- **ç¼–ç¨‹è¯­è¨€**: Python 3.10+
- **æ•°æ®å¤„ç†**: Pandas, NumPy
- **APIé›†æˆ**: requests, finnhub-python, yfinance
- **ç¼“å­˜**: Redis (å¯é€‰)
- **UI**: Chainlit, Rich (CLI)
- **é…ç½®ç®¡ç†**: YAML/JSONé…ç½®æ–‡ä»¶

è¿™ç§æ¶æ„è®¾è®¡ç¡®ä¿äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ã€å¯ç»´æŠ¤æ€§å’Œé«˜æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†å„ç»„ä»¶é—´çš„æ¸…æ™°èŒè´£åˆ†å·¥ã€‚


<!-- docs/configuration/config-guide.md -->

# é…ç½®æŒ‡å— (v0.1.4)

## æ¦‚è¿°

TradingAgents ä¸­æ–‡å¢å¼ºç‰ˆæä¾›äº†ç»Ÿä¸€çš„é…ç½®ç³»ç»Ÿï¼Œæ‰€æœ‰é…ç½®é€šè¿‡ `.env` æ–‡ä»¶ç®¡ç†ã€‚æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»äº†æ‰€æœ‰å¯ç”¨çš„é…ç½®é€‰é¡¹å’Œæœ€ä½³å®è·µã€‚

## ğŸ¯ v0.1.4 é…ç½®ä¼˜åŒ–

### ç»Ÿä¸€é…ç½®ç®¡ç†
- âœ… **å•ä¸€é…ç½®æº**: åªä½¿ç”¨ `.env` æ–‡ä»¶
- âœ… **å¯ç”¨å¼€å…³ç”Ÿæ•ˆ**: æ•°æ®åº“å¯ç”¨å¼€å…³å®Œå…¨ç”Ÿæ•ˆ
- âœ… **æ™ºèƒ½é™çº§**: è‡ªåŠ¨æ£€æµ‹å¹¶é™çº§åˆ°å¯ç”¨çš„æ•°æ®æº
- âœ… **Webç•Œé¢ç®¡ç†**: é€šè¿‡Webç•Œé¢ç®¡ç†é…ç½®

## é…ç½®æ–‡ä»¶ç»“æ„

### .env é…ç½®æ–‡ä»¶ (æ¨è)
```bash
# ===========================================
# TradingAgents ä¸­æ–‡å¢å¼ºç‰ˆé…ç½®æ–‡ä»¶ (v0.1.4)
# ===========================================

# ğŸ§  LLM é…ç½® (æ¨èé˜¿é‡Œç™¾ç‚¼)
DASHSCOPE_API_KEY=your_dashscope_api_key_here
GOOGLE_API_KEY=your_google_api_key_here

# ğŸ“Š æ•°æ®æºé…ç½®
FINNHUB_API_KEY=your_finnhub_api_key_here

# ğŸ—„ï¸ æ•°æ®åº“é…ç½® (é»˜è®¤ç¦ç”¨)
MONGODB_ENABLED=false
REDIS_ENABLED=false
MONGODB_HOST=localhost
MONGODB_PORT=27018
REDIS_HOST=localhost
REDIS_PORT=6380

# ğŸ“ è·¯å¾„é…ç½®
TRADINGAGENTS_RESULTS_DIR=./results
TRADINGAGENTS_DATA_DIR=./data
```

## é…ç½®é€‰é¡¹è¯¦è§£

### 1. è·¯å¾„é…ç½®

#### project_dir
- **ç±»å‹**: `str`
- **é»˜è®¤å€¼**: é¡¹ç›®æ ¹ç›®å½•
- **è¯´æ˜**: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼Œç”¨äºå®šä½å…¶ä»–ç›¸å¯¹è·¯å¾„

#### results_dir
- **ç±»å‹**: `str`
- **é»˜è®¤å€¼**: `"./results"`
- **ç¯å¢ƒå˜é‡**: `TRADINGAGENTS_RESULTS_DIR`
- **è¯´æ˜**: åˆ†æç»“æœå­˜å‚¨ç›®å½•

```python
config = {
    "results_dir": "/path/to/custom/results",  # è‡ªå®šä¹‰ç»“æœç›®å½•
}
```

#### data_cache_dir
- **ç±»å‹**: `str`
- **é»˜è®¤å€¼**: `"tradingagents/dataflows/data_cache"`
- **è¯´æ˜**: æ•°æ®ç¼“å­˜ç›®å½•

### 2. LLM é…ç½®

#### llm_provider
- **ç±»å‹**: `str`
- **å¯é€‰å€¼**: `"openai"`, `"anthropic"`, `"google"`
- **é»˜è®¤å€¼**: `"openai"`
- **è¯´æ˜**: å¤§è¯­è¨€æ¨¡å‹æä¾›å•†

```python
# OpenAI é…ç½®
config = {
    "llm_provider": "openai",
    "backend_url": "https://api.openai.com/v1",
    "deep_think_llm": "gpt-4o",
    "quick_think_llm": "gpt-4o-mini",
}

# Anthropic é…ç½®
config = {
    "llm_provider": "anthropic",
    "backend_url": "https://api.anthropic.com",
    "deep_think_llm": "claude-3-opus-20240229",
    "quick_think_llm": "claude-3-haiku-20240307",
}

# Google é…ç½®
config = {
    "llm_provider": "google",
    "backend_url": "https://generativelanguage.googleapis.com/v1",
    "deep_think_llm": "gemini-pro",
    "quick_think_llm": "gemini-pro",
}
```

#### deep_think_llm
- **ç±»å‹**: `str`
- **é»˜è®¤å€¼**: `"o4-mini"`
- **è¯´æ˜**: ç”¨äºæ·±åº¦æ€è€ƒä»»åŠ¡çš„æ¨¡å‹ï¼ˆå¦‚å¤æ‚åˆ†æã€è¾©è®ºï¼‰

**æ¨èæ¨¡å‹**:
- **é«˜æ€§èƒ½**: `"gpt-4o"`, `"claude-3-opus-20240229"`
- **å¹³è¡¡**: `"gpt-4o-mini"`, `"claude-3-sonnet-20240229"`
- **ç»æµ**: `"gpt-3.5-turbo"`, `"claude-3-haiku-20240307"`

#### quick_think_llm
- **ç±»å‹**: `str`
- **é»˜è®¤å€¼**: `"gpt-4o-mini"`
- **è¯´æ˜**: ç”¨äºå¿«é€Ÿä»»åŠ¡çš„æ¨¡å‹ï¼ˆå¦‚æ•°æ®å¤„ç†ã€æ ¼å¼åŒ–ï¼‰

### 3. è¾©è®ºå’Œè®¨è®ºé…ç½®

#### max_debate_rounds
- **ç±»å‹**: `int`
- **é»˜è®¤å€¼**: `1`
- **èŒƒå›´**: `1-10`
- **è¯´æ˜**: ç ”ç©¶å‘˜è¾©è®ºçš„æœ€å¤§è½®æ¬¡

```python
# ä¸åŒåœºæ™¯çš„æ¨èé…ç½®
config_scenarios = {
    "quick_analysis": {"max_debate_rounds": 1},      # å¿«é€Ÿåˆ†æ
    "standard": {"max_debate_rounds": 2},            # æ ‡å‡†åˆ†æ
    "thorough": {"max_debate_rounds": 3},            # æ·±åº¦åˆ†æ
    "comprehensive": {"max_debate_rounds": 5},       # å…¨é¢åˆ†æ
}
```

#### max_risk_discuss_rounds
- **ç±»å‹**: `int`
- **é»˜è®¤å€¼**: `1`
- **èŒƒå›´**: `1-5`
- **è¯´æ˜**: é£é™©ç®¡ç†è®¨è®ºçš„æœ€å¤§è½®æ¬¡

#### max_recur_limit
- **ç±»å‹**: `int`
- **é»˜è®¤å€¼**: `100`
- **è¯´æ˜**: é€’å½’è°ƒç”¨çš„æœ€å¤§é™åˆ¶ï¼Œé˜²æ­¢æ— é™å¾ªç¯

### 4. å·¥å…·é…ç½®

#### online_tools
- **ç±»å‹**: `bool`
- **é»˜è®¤å€¼**: `True`
- **è¯´æ˜**: æ˜¯å¦ä½¿ç”¨åœ¨çº¿æ•°æ®å·¥å…·

```python
# åœ¨çº¿æ¨¡å¼ - è·å–å®æ—¶æ•°æ®
config = {"online_tools": True}

# ç¦»çº¿æ¨¡å¼ - ä½¿ç”¨ç¼“å­˜æ•°æ®
config = {"online_tools": False}
```

## é«˜çº§é…ç½®é€‰é¡¹

### 1. æ™ºèƒ½ä½“æƒé‡é…ç½®
```python
config = {
    "analyst_weights": {
        "fundamentals": 0.3,    # åŸºæœ¬é¢åˆ†ææƒé‡
        "technical": 0.3,       # æŠ€æœ¯åˆ†ææƒé‡
        "news": 0.2,           # æ–°é—»åˆ†ææƒé‡
        "social": 0.2,         # ç¤¾äº¤åª’ä½“åˆ†ææƒé‡
    }
}
```

### 2. é£é™©ç®¡ç†é…ç½®
```python
config = {
    "risk_management": {
        "risk_threshold": 0.8,           # é£é™©é˜ˆå€¼
        "max_position_size": 0.1,        # æœ€å¤§ä»“ä½æ¯”ä¾‹
        "stop_loss_threshold": 0.05,     # æ­¢æŸé˜ˆå€¼
        "take_profit_threshold": 0.15,   # æ­¢ç›ˆé˜ˆå€¼
    }
}
```

### 3. æ•°æ®æºé…ç½®
```python
config = {
    "data_sources": {
        "primary": "finnhub",            # ä¸»è¦æ•°æ®æº
        "fallback": ["yahoo", "alpha_vantage"],  # å¤‡ç”¨æ•°æ®æº
        "cache_ttl": {
            "price_data": 300,           # ä»·æ ¼æ•°æ®ç¼“å­˜5åˆ†é’Ÿ
            "fundamental_data": 86400,   # åŸºæœ¬é¢æ•°æ®ç¼“å­˜24å°æ—¶
            "news_data": 3600,          # æ–°é—»æ•°æ®ç¼“å­˜1å°æ—¶
        }
    }
}
```

### 4. æ€§èƒ½ä¼˜åŒ–é…ç½®
```python
config = {
    "performance": {
        "parallel_analysis": True,       # å¹¶è¡Œåˆ†æ
        "max_workers": 4,               # æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
        "timeout": 300,                 # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        "retry_attempts": 3,            # é‡è¯•æ¬¡æ•°
        "batch_size": 10,               # æ‰¹å¤„ç†å¤§å°
    }
}
```

## ç¯å¢ƒå˜é‡é…ç½®

### å¿…éœ€çš„ç¯å¢ƒå˜é‡
```bash
# OpenAI API
export OPENAI_API_KEY="your_openai_api_key"

# FinnHub API
export FINNHUB_API_KEY="your_finnhub_api_key"

# å¯é€‰çš„ç¯å¢ƒå˜é‡
export ANTHROPIC_API_KEY="your_anthropic_api_key"
export GOOGLE_API_KEY="your_google_api_key"
export TRADINGAGENTS_RESULTS_DIR="/custom/results/path"
```

### .env æ–‡ä»¶é…ç½®
```bash
# .env æ–‡ä»¶
OPENAI_API_KEY=your_openai_api_key
FINNHUB_API_KEY=your_finnhub_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
GOOGLE_API_KEY=your_google_api_key
TRADINGAGENTS_RESULTS_DIR=./custom_results
TRADINGAGENTS_LOG_LEVEL=INFO
```

## é…ç½®æœ€ä½³å®è·µ

### 1. æˆæœ¬ä¼˜åŒ–é…ç½®
```python
# ä½æˆæœ¬é…ç½®
cost_optimized_config = {
    "llm_provider": "openai",
    "deep_think_llm": "gpt-4o-mini",
    "quick_think_llm": "gpt-4o-mini",
    "max_debate_rounds": 1,
    "max_risk_discuss_rounds": 1,
    "online_tools": False,  # ä½¿ç”¨ç¼“å­˜æ•°æ®
}
```

### 2. é«˜æ€§èƒ½é…ç½®
```python
# é«˜æ€§èƒ½é…ç½®
high_performance_config = {
    "llm_provider": "openai",
    "deep_think_llm": "gpt-4o",
    "quick_think_llm": "gpt-4o",
    "max_debate_rounds": 3,
    "max_risk_discuss_rounds": 2,
    "online_tools": True,
    "performance": {
        "parallel_analysis": True,
        "max_workers": 8,
    }
}
```

### 3. å¼€å‘ç¯å¢ƒé…ç½®
```python
# å¼€å‘ç¯å¢ƒé…ç½®
dev_config = {
    "llm_provider": "openai",
    "deep_think_llm": "gpt-4o-mini",
    "quick_think_llm": "gpt-4o-mini",
    "max_debate_rounds": 1,
    "online_tools": True,
    "debug": True,
    "log_level": "DEBUG",
}
```

### 4. ç”Ÿäº§ç¯å¢ƒé…ç½®
```python
# ç”Ÿäº§ç¯å¢ƒé…ç½®
prod_config = {
    "llm_provider": "openai",
    "deep_think_llm": "gpt-4o",
    "quick_think_llm": "gpt-4o-mini",
    "max_debate_rounds": 2,
    "max_risk_discuss_rounds": 1,
    "online_tools": True,
    "performance": {
        "parallel_analysis": True,
        "max_workers": 4,
        "timeout": 600,
        "retry_attempts": 3,
    },
    "logging": {
        "level": "INFO",
        "file": "/var/log/tradingagents.log",
    }
}
```

## é…ç½®éªŒè¯

### é…ç½®éªŒè¯å™¨
```python
class ConfigValidator:
    """é…ç½®éªŒè¯å™¨"""
    
    def validate(self, config: Dict) -> Tuple[bool, List[str]]:
        """éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§"""
        errors = []
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ["llm_provider", "deep_think_llm", "quick_think_llm"]
        for field in required_fields:
            if field not in config:
                errors.append(f"Missing required field: {field}")
        
        # æ£€æŸ¥LLMæä¾›å•†
        valid_providers = ["openai", "anthropic", "google"]
        if config.get("llm_provider") not in valid_providers:
            errors.append(f"Invalid llm_provider. Must be one of: {valid_providers}")
        
        # æ£€æŸ¥æ•°å€¼èŒƒå›´
        if config.get("max_debate_rounds", 1) < 1:
            errors.append("max_debate_rounds must be >= 1")
        
        return len(errors) == 0, errors

# ä½¿ç”¨ç¤ºä¾‹
validator = ConfigValidator()
is_valid, errors = validator.validate(config)
if not is_valid:
    print("Configuration errors:", errors)
```

## åŠ¨æ€é…ç½®æ›´æ–°

### è¿è¡Œæ—¶é…ç½®æ›´æ–°
```python
class TradingAgentsGraph:
    def update_config(self, new_config: Dict):
        """è¿è¡Œæ—¶æ›´æ–°é…ç½®"""
        
        # éªŒè¯æ–°é…ç½®
        validator = ConfigValidator()
        is_valid, errors = validator.validate(new_config)
        
        if not is_valid:
            raise ValueError(f"Invalid configuration: {errors}")
        
        # æ›´æ–°é…ç½®
        self.config.update(new_config)
        
        # é‡æ–°åˆå§‹åŒ–å—å½±å“çš„ç»„ä»¶
        self._reinitialize_components()
    
    def _reinitialize_components(self):
        """é‡æ–°åˆå§‹åŒ–ç»„ä»¶"""
        # é‡æ–°åˆå§‹åŒ–LLM
        self._setup_llms()
        
        # é‡æ–°åˆå§‹åŒ–æ™ºèƒ½ä½“
        self._setup_agents()
```

é€šè¿‡åˆç†çš„é…ç½®ï¼Œæ‚¨å¯ä»¥æ ¹æ®ä¸åŒçš„ä½¿ç”¨åœºæ™¯ä¼˜åŒ– TradingAgents çš„æ€§èƒ½å’Œæˆæœ¬ã€‚


<!-- docs/configuration/dashscope-config.md -->

# é˜¿é‡Œç™¾ç‚¼å¤§æ¨¡å‹é…ç½®æŒ‡å—

## æ¦‚è¿°

é˜¿é‡Œç™¾ç‚¼ï¼ˆDashScopeï¼‰æ˜¯é˜¿é‡Œäº‘æ¨å‡ºçš„å¤§æ¨¡å‹æœåŠ¡å¹³å°ï¼Œæä¾›é€šä¹‰åƒé—®ç³»åˆ—æ¨¡å‹ã€‚æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»å¦‚ä½•åœ¨ TradingAgents ä¸­é…ç½®å’Œä½¿ç”¨é˜¿é‡Œç™¾ç‚¼å¤§æ¨¡å‹ã€‚

## ä¸ºä»€ä¹ˆé€‰æ‹©é˜¿é‡Œç™¾ç‚¼ï¼Ÿ

### ğŸ‡¨ğŸ‡³ **å›½äº§åŒ–ä¼˜åŠ¿**
- **æ— éœ€ç¿»å¢™**: å›½å†…ç›´æ¥è®¿é—®ï¼Œç½‘ç»œç¨³å®š
- **ä¸­æ–‡ä¼˜åŒ–**: ä¸“é—¨é’ˆå¯¹ä¸­æ–‡åœºæ™¯ä¼˜åŒ–
- **åˆè§„å®‰å…¨**: ç¬¦åˆå›½å†…æ•°æ®å®‰å…¨è¦æ±‚
- **æœ¬åœŸåŒ–æœåŠ¡**: ä¸­æ–‡å®¢æœå’ŒæŠ€æœ¯æ”¯æŒ

### ğŸ’° **æˆæœ¬ä¼˜åŠ¿**
- **ä»·æ ¼é€æ˜**: æŒ‰é‡è®¡è´¹ï¼Œä»·æ ¼å…¬å¼€é€æ˜
- **å…è´¹é¢åº¦**: æ–°ç”¨æˆ·æœ‰å…è´¹è¯•ç”¨é¢åº¦
- **æ€§ä»·æ¯”é«˜**: ç›¸æ¯”å›½å¤–æ¨¡å‹æˆæœ¬æ›´ä½

### ğŸ§  **æŠ€æœ¯ä¼˜åŠ¿**
- **ä¸­æ–‡ç†è§£**: åœ¨ä¸­æ–‡ç†è§£å’Œç”Ÿæˆæ–¹é¢è¡¨ç°ä¼˜ç§€
- **é‡‘èçŸ¥è¯†**: å¯¹ä¸­å›½é‡‘èå¸‚åœºæœ‰æ›´å¥½çš„ç†è§£
- **æ¨ç†èƒ½åŠ›**: é€šä¹‰åƒé—®ç³»åˆ—åœ¨æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²

## å¿«é€Ÿå¼€å§‹

### 1. è·å–APIå¯†é’¥

#### æ­¥éª¤1: æ³¨å†Œé˜¿é‡Œäº‘è´¦å·
1. è®¿é—® [é˜¿é‡Œäº‘å®˜ç½‘](https://www.aliyun.com/)
2. ç‚¹å‡»"å…è´¹æ³¨å†Œ"
3. å®Œæˆè´¦å·æ³¨å†Œå’Œå®åè®¤è¯

#### æ­¥éª¤2: å¼€é€šç™¾ç‚¼æœåŠ¡
1. è®¿é—® [ç™¾ç‚¼æ§åˆ¶å°](https://dashscope.console.aliyun.com/)
2. ç‚¹å‡»"ç«‹å³å¼€é€š"
3. é€‰æ‹©åˆé€‚çš„å¥—é¤ï¼ˆå»ºè®®å…ˆé€‰æ‹©æŒ‰é‡ä»˜è´¹ï¼‰

#### æ­¥éª¤3: è·å–APIå¯†é’¥
1. åœ¨ç™¾ç‚¼æ§åˆ¶å°ä¸­ï¼Œç‚¹å‡»"API-KEYç®¡ç†"
2. ç‚¹å‡»"åˆ›å»ºæ–°çš„API-KEY"
3. å¤åˆ¶ç”Ÿæˆçš„APIå¯†é’¥

### 2. é…ç½®ç¯å¢ƒå˜é‡

#### æ–¹æ³•1: ä½¿ç”¨ç¯å¢ƒå˜é‡
```bash
# Windows
set DASHSCOPE_API_KEY=your_dashscope_api_key_here
set FINNHUB_API_KEY=your_finnhub_api_key_here

# Linux/macOS
export DASHSCOPE_API_KEY=your_dashscope_api_key_here
export FINNHUB_API_KEY=your_finnhub_api_key_here
```

#### æ–¹æ³•2: ä½¿ç”¨ .env æ–‡ä»¶
```bash
# å¤åˆ¶ç¤ºä¾‹æ–‡ä»¶
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥çœŸå®çš„APIå¯†é’¥
DASHSCOPE_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
FINNHUB_API_KEY=your_finnhub_api_key_here
```

### 3. è¿è¡Œæ¼”ç¤º

```bash
# ä½¿ç”¨ä¸“é—¨çš„é˜¿é‡Œç™¾ç‚¼æ¼”ç¤ºè„šæœ¬
python demo_dashscope.py
```

## æ”¯æŒçš„æ¨¡å‹

### é€šä¹‰åƒé—®ç³»åˆ—æ¨¡å‹

| æ¨¡å‹åç§° | æ¨¡å‹ID | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|---------|--------|------|----------|
| **é€šä¹‰åƒé—® Turbo** | `qwen-turbo` | å¿«é€Ÿå“åº”ï¼Œæˆæœ¬ä½ | å¿«é€Ÿä»»åŠ¡ã€æ—¥å¸¸å¯¹è¯ |
| **é€šä¹‰åƒé—® Plus** | `qwen-plus-latest` | å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬ | å¤æ‚åˆ†æã€ä¸“ä¸šä»»åŠ¡ |
| **é€šä¹‰åƒé—® Max** | `qwen-max` | æœ€å¼ºæ€§èƒ½ | æœ€å¤æ‚ä»»åŠ¡ã€é«˜è´¨é‡è¾“å‡º |
| **é€šä¹‰åƒé—® Max é•¿æ–‡æœ¬** | `qwen-max-longcontext` | è¶…é•¿ä¸Šä¸‹æ–‡ | é•¿æ–‡æ¡£åˆ†æã€å¤§é‡æ•°æ®å¤„ç† |

### æ¨èé…ç½®

#### ç»æµå‹é…ç½®ï¼ˆæˆæœ¬ä¼˜å…ˆï¼‰
```python
config = {
    "llm_provider": "dashscope",
    "deep_think_llm": "qwen-plus-latest",      # æ·±åº¦æ€è€ƒä½¿ç”¨Plus
    "quick_think_llm": "qwen-turbo",    # å¿«é€Ÿä»»åŠ¡ä½¿ç”¨Turbo
    "max_debate_rounds": 1,             # å‡å°‘è¾©è®ºè½®æ¬¡
}
```

#### æ€§èƒ½å‹é…ç½®ï¼ˆè´¨é‡ä¼˜å…ˆï¼‰
```python
config = {
    "llm_provider": "dashscope", 
    "deep_think_llm": "qwen-max",       # æ·±åº¦æ€è€ƒä½¿ç”¨Max
    "quick_think_llm": "qwen-plus",     # å¿«é€Ÿä»»åŠ¡ä½¿ç”¨Plus
    "max_debate_rounds": 2,             # å¢åŠ è¾©è®ºè½®æ¬¡
}
```

#### é•¿æ–‡æœ¬é…ç½®ï¼ˆå¤„ç†å¤§é‡æ•°æ®ï¼‰
```python
config = {
    "llm_provider": "dashscope",
    "deep_think_llm": "qwen-max-longcontext",  # ä½¿ç”¨é•¿æ–‡æœ¬ç‰ˆæœ¬
    "quick_think_llm": "qwen-plus",
    "max_debate_rounds": 1,
}
```

## é…ç½®ç¤ºä¾‹

### åŸºç¡€é…ç½®
```python
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

# åˆ›å»ºé˜¿é‡Œç™¾ç‚¼é…ç½®
config = DEFAULT_CONFIG.copy()
config["llm_provider"] = "dashscope"
config["deep_think_llm"] = "qwen-plus-latest"
config["quick_think_llm"] = "qwen-turbo"

# åˆå§‹åŒ–
ta = TradingAgentsGraph(debug=True, config=config)

# è¿è¡Œåˆ†æ
state, decision = ta.propagate("AAPL", "2024-05-10")
print(decision)
```

### é«˜çº§é…ç½®
```python
# è‡ªå®šä¹‰æ¨¡å‹å‚æ•°
config = DEFAULT_CONFIG.copy()
config.update({
    "llm_provider": "dashscope",
    "deep_think_llm": "qwen-max",
    "quick_think_llm": "qwen-plus-latest",
    "max_debate_rounds": 2,
    "max_risk_discuss_rounds": 2,
    "online_tools": True,
})

# ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°åˆ›å»ºLLM
from tradingagents.llm_adapters import ChatDashScope

custom_llm = ChatDashScope(
    model="qwen-max",
    temperature=0.1,
    max_tokens=3000,
    top_p=0.9
)
```

## æˆæœ¬æ§åˆ¶

### å…¸å‹ä½¿ç”¨æˆæœ¬
- **ç»æµæ¨¡å¼**: Â¥0.01-0.05/æ¬¡åˆ†æ (ä½¿ç”¨ qwen-turbo)
- **æ ‡å‡†æ¨¡å¼**: Â¥0.05-0.15/æ¬¡åˆ†æ (ä½¿ç”¨ qwen-plus)
- **é«˜ç²¾åº¦æ¨¡å¼**: Â¥0.10-0.30/æ¬¡åˆ†æ (ä½¿ç”¨ qwen-max)

### æˆæœ¬ä¼˜åŒ–å»ºè®®
1. **åˆç†é€‰æ‹©æ¨¡å‹**: æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹
2. **æ§åˆ¶è¾©è®ºè½®æ¬¡**: å‡å°‘ `max_debate_rounds` å‚æ•°
3. **ä½¿ç”¨ç¼“å­˜**: å¯ç”¨æ•°æ®ç¼“å­˜å‡å°‘é‡å¤è°ƒç”¨
4. **ç›‘æ§ä½¿ç”¨é‡**: å®šæœŸæ£€æŸ¥APIè°ƒç”¨é‡å’Œè´¹ç”¨

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. APIå¯†é’¥é”™è¯¯
```
Error: Invalid API key
```
**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œç¡®è®¤å·²å¼€é€šç™¾ç‚¼æœåŠ¡

#### 2. é¢åº¦ä¸è¶³
```
Error: Insufficient quota
```
**è§£å†³æ–¹æ¡ˆ**: åœ¨ç™¾ç‚¼æ§åˆ¶å°å……å€¼æˆ–å‡çº§å¥—é¤

#### 3. ç½‘ç»œè¿æ¥é—®é¢˜
```
Error: Connection timeout
```
**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œç¡®è®¤å¯ä»¥è®¿é—®é˜¿é‡Œäº‘æœåŠ¡

#### 4. æ¨¡å‹ä¸å­˜åœ¨
```
Error: Model not found
```
**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®ï¼Œç¡®è®¤æ¨¡å‹å·²å¼€é€š

### è°ƒè¯•æŠ€å·§

1. **å¯ç”¨è°ƒè¯•æ¨¡å¼**:
   ```python
   ta = TradingAgentsGraph(debug=True, config=config)
   ```

2. **æ£€æŸ¥APIè¿æ¥**:
   ```python
   import dashscope
   dashscope.api_key = "your_api_key"
   
   from dashscope import Generation
   response = Generation.call(
       model="qwen-turbo",
       messages=[{"role": "user", "content": "Hello"}]
   )
   print(response)
   ```

## æœ€ä½³å®è·µ

1. **æ¨¡å‹é€‰æ‹©**: æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹
2. **å‚æ•°è°ƒä¼˜**: æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´æ¸©åº¦ã€æœ€å¤§tokenæ•°ç­‰å‚æ•°
3. **é”™è¯¯å¤„ç†**: å®ç°é€‚å½“çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
4. **ç›‘æ§ä½¿ç”¨**: å®šæœŸç›‘æ§APIä½¿ç”¨é‡å’Œæˆæœ¬
5. **ç¼“å­˜ç­–ç•¥**: åˆç†ä½¿ç”¨ç¼“å­˜å‡å°‘APIè°ƒç”¨

## ç›¸å…³é“¾æ¥

- [é˜¿é‡Œç™¾ç‚¼å®˜ç½‘](https://dashscope.aliyun.com/)
- [ç™¾ç‚¼æ§åˆ¶å°](https://dashscope.console.aliyun.com/)
- [APIæ–‡æ¡£](https://help.aliyun.com/zh/dashscope/)
- [ä»·æ ¼è¯´æ˜](https://help.aliyun.com/zh/dashscope/product-overview/billing-overview)


<!-- docs/configuration/data-directory-configuration.md -->

# æ•°æ®ç›®å½•é…ç½®æŒ‡å— | Data Directory Configuration Guide

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜å¦‚ä½•åœ¨TradingAgentsä¸­é…ç½®æ•°æ®ç›®å½•è·¯å¾„ï¼Œè§£å†³è·¯å¾„ç›¸å…³é—®é¢˜ï¼Œå¹¶æä¾›å¤šç§é…ç½®æ–¹å¼ã€‚

This guide explains how to configure data directory paths in TradingAgents, resolve path-related issues, and provides multiple configuration methods.

## æ¦‚è¿° | Overview

TradingAgentsæ”¯æŒçµæ´»çš„æ•°æ®ç›®å½•é…ç½®ï¼Œå…è®¸ç”¨æˆ·ï¼š
- è‡ªå®šä¹‰æ•°æ®å­˜å‚¨ä½ç½®
- é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®
- ä½¿ç”¨CLIå‘½ä»¤ç®¡ç†
- è‡ªåŠ¨åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„

TradingAgents supports flexible data directory configuration, allowing users to:
- Customize data storage locations
- Configure via environment variables
- Manage through CLI commands
- Automatically create necessary directory structures

## é…ç½®æ–¹æ³• | Configuration Methods

### 1. CLIå‘½ä»¤é…ç½® | CLI Command Configuration

#### æŸ¥çœ‹å½“å‰é…ç½® | View Current Configuration
```bash
# æ˜¾ç¤ºå½“å‰æ•°æ®ç›®å½•é…ç½®
python -m cli.main data-config
python -m cli.main data-config --show
```

#### è®¾ç½®è‡ªå®šä¹‰æ•°æ®ç›®å½• | Set Custom Data Directory
```bash
# Windows
python -m cli.main data-config --set "C:\MyTradingData"

# Linux/macOS
python -m cli.main data-config --set "/home/user/trading-data"
```

#### é‡ç½®ä¸ºé»˜è®¤é…ç½® | Reset to Default Configuration
```bash
python -m cli.main data-config --reset
```

### 2. ç¯å¢ƒå˜é‡é…ç½® | Environment Variable Configuration

#### Windows
```cmd
# è®¾ç½®æ•°æ®ç›®å½•
set TRADINGAGENTS_DATA_DIR=C:\MyTradingData

# è®¾ç½®ç¼“å­˜ç›®å½•
set TRADINGAGENTS_CACHE_DIR=C:\MyTradingData\cache

# è®¾ç½®ç»“æœç›®å½•
set TRADINGAGENTS_RESULTS_DIR=C:\MyTradingData\results
```

#### Linux/macOS
```bash
# è®¾ç½®æ•°æ®ç›®å½•
export TRADINGAGENTS_DATA_DIR="/home/user/trading-data"

# è®¾ç½®ç¼“å­˜ç›®å½•
export TRADINGAGENTS_CACHE_DIR="/home/user/trading-data/cache"

# è®¾ç½®ç»“æœç›®å½•
export TRADINGAGENTS_RESULTS_DIR="/home/user/trading-data/results"
```

#### .envæ–‡ä»¶é…ç½® | .env File Configuration
```env
# åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º.envæ–‡ä»¶
TRADINGAGENTS_DATA_DIR=/path/to/your/data
TRADINGAGENTS_CACHE_DIR=/path/to/your/cache
TRADINGAGENTS_RESULTS_DIR=/path/to/your/results
```

### 3. ç¨‹åºåŒ–é…ç½® | Programmatic Configuration

```python
from tradingagents.dataflows.config import set_data_dir, get_data_dir
from tradingagents.config.config_manager import config_manager

# è®¾ç½®æ•°æ®ç›®å½•
set_data_dir("/path/to/custom/data")

# è·å–å½“å‰æ•°æ®ç›®å½•
current_dir = get_data_dir()
print(f"å½“å‰æ•°æ®ç›®å½•: {current_dir}")

# ç¡®ä¿ç›®å½•å­˜åœ¨
config_manager.ensure_directories_exist()
```

## ç›®å½•ç»“æ„ | Directory Structure

é…ç½®æ•°æ®ç›®å½•åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åˆ›å»ºä»¥ä¸‹ç›®å½•ç»“æ„ï¼š

After configuring the data directory, the system automatically creates the following directory structure:

```
data/
â”œâ”€â”€ cache/                          # ç¼“å­˜ç›®å½• | Cache directory
â”œâ”€â”€ finnhub_data/                   # Finnhubæ•°æ®ç›®å½• | Finnhub data directory
â”‚   â”œâ”€â”€ news_data/                  # æ–°é—»æ•°æ® | News data
â”‚   â”œâ”€â”€ insider_sentiment/          # å†…éƒ¨äººæƒ…ç»ªæ•°æ® | Insider sentiment data
â”‚   â””â”€â”€ insider_transactions/       # å†…éƒ¨äººäº¤æ˜“æ•°æ® | Insider transaction data
â””â”€â”€ results/                        # åˆ†æç»“æœ | Analysis results
```

## é…ç½®ä¼˜å…ˆçº§ | Configuration Priority

é…ç½®çš„ä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼š

Configuration priority from high to low:

1. **ç¯å¢ƒå˜é‡** | Environment Variables
2. **CLIè®¾ç½®** | CLI Settings
3. **é»˜è®¤é…ç½®** | Default Configuration

## é»˜è®¤é…ç½® | Default Configuration

å¦‚æœæ²¡æœ‰è‡ªå®šä¹‰é…ç½®ï¼Œç³»ç»Ÿä½¿ç”¨ä»¥ä¸‹é»˜è®¤è·¯å¾„ï¼š

If no custom configuration is provided, the system uses the following default paths:

- **Windows**: `C:\Users\{username}\Documents\TradingAgents\data`
- **Linux/macOS**: `~/Documents/TradingAgents/data`

## å¸¸è§é—®é¢˜è§£å†³ | Troubleshooting

### é—®é¢˜1ï¼šè·¯å¾„ä¸å­˜åœ¨é”™è¯¯ | Issue 1: Path Not Found Error

**é”™è¯¯ä¿¡æ¯** | Error Message:
```
No such file or directory: '/data/finnhub_data/news_data'
```

**è§£å†³æ–¹æ¡ˆ** | Solution:
```bash
# ä½¿ç”¨CLIé‡æ–°é…ç½®æ•°æ®ç›®å½•
python -m cli.main data-config --set "C:\YourDataPath"

# æˆ–é‡ç½®ä¸ºé»˜è®¤é…ç½®
python -m cli.main data-config --reset
```

### é—®é¢˜2ï¼šæƒé™ä¸è¶³ | Issue 2: Permission Denied

**è§£å†³æ–¹æ¡ˆ** | Solution:
1. ç¡®ä¿å¯¹ç›®æ ‡ç›®å½•æœ‰å†™æƒé™
2. é€‰æ‹©ç”¨æˆ·ç›®å½•ä¸‹çš„è·¯å¾„
3. åœ¨Windowsä¸Šä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ

### é—®é¢˜3ï¼šè·¨å¹³å°è·¯å¾„é—®é¢˜ | Issue 3: Cross-Platform Path Issues

**è§£å†³æ–¹æ¡ˆ** | Solution:
- ä½¿ç”¨æ­£æ–œæ  `/` æˆ–åŒåæ–œæ  `\\` åœ¨Windowsä¸Š
- é¿å…ç¡¬ç¼–ç è·¯å¾„åˆ†éš”ç¬¦
- ä½¿ç”¨ç¯å¢ƒå˜é‡è¿›è¡Œè·¨å¹³å°é…ç½®

## éªŒè¯é…ç½® | Verify Configuration

### 1. ä½¿ç”¨CLIéªŒè¯ | Verify Using CLI
```bash
python -m cli.main data-config --show
```

### 2. ä½¿ç”¨æµ‹è¯•è„šæœ¬éªŒè¯ | Verify Using Test Script
```bash
python test_data_config_cli.py
```

### 3. ä½¿ç”¨æ¼”ç¤ºè„šæœ¬éªŒè¯ | Verify Using Demo Script
```bash
python examples/data_dir_config_demo.py
```

## æœ€ä½³å®è·µ | Best Practices

1. **ä½¿ç”¨ç»å¯¹è·¯å¾„** | Use Absolute Paths
   - é¿å…ç›¸å¯¹è·¯å¾„å¯èƒ½å¯¼è‡´çš„é—®é¢˜
   - Avoid issues that relative paths might cause

2. **å®šæœŸå¤‡ä»½æ•°æ®** | Regular Data Backup
   - é‡è¦çš„åˆ†æç»“æœåº”å®šæœŸå¤‡ä»½
   - Important analysis results should be backed up regularly

3. **ç¯å¢ƒéš”ç¦»** | Environment Isolation
   - ä¸åŒé¡¹ç›®ä½¿ç”¨ä¸åŒçš„æ•°æ®ç›®å½•
   - Use different data directories for different projects

4. **æƒé™ç®¡ç†** | Permission Management
   - ç¡®ä¿åº”ç”¨ç¨‹åºå¯¹æ•°æ®ç›®å½•æœ‰é€‚å½“æƒé™
   - Ensure the application has appropriate permissions to the data directory

## é«˜çº§é…ç½® | Advanced Configuration

### è‡ªå®šä¹‰å­ç›®å½•ç»“æ„ | Custom Subdirectory Structure

```python
from tradingagents.config.config_manager import config_manager

# è‡ªå®šä¹‰ç›®å½•ç»“æ„
custom_dirs = {
    'custom_data': 'my_custom_data',
    'reports': 'analysis_reports',
    'logs': 'application_logs'
}

# åˆ›å»ºè‡ªå®šä¹‰ç›®å½•
for dir_name, dir_path in custom_dirs.items():
    full_path = os.path.join(config_manager.get_data_dir(), dir_path)
    os.makedirs(full_path, exist_ok=True)
```

### åŠ¨æ€é…ç½®æ›´æ–° | Dynamic Configuration Updates

```python
# è¿è¡Œæ—¶æ›´æ–°é…ç½®
config_manager.set_data_dir('/new/data/path')
config_manager.ensure_directories_exist()

# éªŒè¯æ›´æ–°
print(f"æ–°æ•°æ®ç›®å½•: {config_manager.get_data_dir()}")
```

## ç›¸å…³æ–‡ä»¶ | Related Files

- `tradingagents/config/config_manager.py` - é…ç½®ç®¡ç†å™¨
- `tradingagents/dataflows/config.py` - æ•°æ®æµé…ç½®
- `cli/main.py` - CLIå‘½ä»¤å®ç°
- `examples/data_dir_config_demo.py` - é…ç½®æ¼”ç¤ºè„šæœ¬
- `test_data_config_cli.py` - é…ç½®æµ‹è¯•è„šæœ¬

## æŠ€æœ¯æ”¯æŒ | Technical Support

å¦‚æœé‡åˆ°é…ç½®é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹é”™è¯¯æ—¥å¿—
2. è¿è¡Œè¯Šæ–­è„šæœ¬
3. æ£€æŸ¥æƒé™è®¾ç½®
4. å‚è€ƒæ•…éšœæ’é™¤æŒ‡å—

If you encounter configuration issues, please:
1. Check error logs
2. Run diagnostic scripts
3. Check permission settings
4. Refer to the troubleshooting guide

<!-- docs/configuration/google-ai-setup.md -->

# Google AI é…ç½®æŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨é…ç½®Google AI (Gemini)æ¨¡å‹ï¼Œä»¥ä¾¿åœ¨TradingAgents-CNä¸­ä½¿ç”¨Googleçš„å¼ºå¤§AIèƒ½åŠ›è¿›è¡Œè‚¡ç¥¨åˆ†æã€‚

## ğŸ¯ æ¦‚è¿°

TradingAgents-CN v0.1.2æ–°å¢äº†å¯¹Google AIçš„å®Œæ•´æ”¯æŒï¼ŒåŒ…æ‹¬ï¼š

- **Gemini 2.0 Flash** - æœ€æ–°æ¨¡å‹ï¼Œæ¨èä½¿ç”¨
- **Gemini 1.5 Pro** - å¼ºå¤§æ€§èƒ½ï¼Œé€‚åˆæ·±åº¦åˆ†æ  
- **Gemini 1.5 Flash** - å¿«é€Ÿå“åº”ï¼Œé€‚åˆç®€å•åˆ†æ
- **æ™ºèƒ½æ··åˆåµŒå…¥** - Google AIæ¨ç† + é˜¿é‡Œç™¾ç‚¼åµŒå…¥

## ğŸ”‘ è·å–Google AI APIå¯†é’¥

### 1. è®¿é—®Google AI Studio

1. æ‰“å¼€ [Google AI Studio](https://aistudio.google.com/)
2. ä½¿ç”¨æ‚¨çš„Googleè´¦å·ç™»å½•
3. å¦‚æœæ˜¯é¦–æ¬¡ä½¿ç”¨ï¼Œéœ€è¦åŒæ„æœåŠ¡æ¡æ¬¾

### 2. åˆ›å»ºAPIå¯†é’¥

1. åœ¨å·¦ä¾§å¯¼èˆªæ ä¸­ç‚¹å‡» **"API keys"**
2. ç‚¹å‡» **"Create API key"** æŒ‰é’®
3. é€‰æ‹©ä¸€ä¸ªGoogle Cloudé¡¹ç›®ï¼ˆæˆ–åˆ›å»ºæ–°é¡¹ç›®ï¼‰
4. å¤åˆ¶ç”Ÿæˆçš„APIå¯†é’¥

### 3. é…ç½®APIå¯†é’¥

åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ `.env` æ–‡ä»¶ä¸­æ·»åŠ ï¼š

```env
# Google AI APIå¯†é’¥
GOOGLE_API_KEY=your_google_api_key_here
```

## ğŸ¤– æ”¯æŒçš„æ¨¡å‹

### Gemini 2.0 Flash (æ¨è)
- **æ¨¡å‹åç§°**: `gemini-2.0-flash`
- **ç‰¹ç‚¹**: æœ€æ–°ç‰ˆæœ¬ï¼Œæ€§èƒ½ä¼˜ç§€ï¼ŒLangChainé›†æˆç¨³å®š
- **é€‚ç”¨åœºæ™¯**: æ—¥å¸¸è‚¡ç¥¨åˆ†æï¼Œæ¨èé¦–é€‰
- **ä¼˜åŠ¿**: 
  - ğŸ§  ä¼˜ç§€çš„æ¨ç†èƒ½åŠ›
  - ğŸŒ å®Œç¾çš„ä¸­æ–‡æ”¯æŒ
  - ğŸ”§ ç¨³å®šçš„LangChainé›†æˆ
  - ğŸ’¾ å®Œæ•´çš„å†…å­˜å­¦ä¹ åŠŸèƒ½

### Gemini 1.5 Pro
- **æ¨¡å‹åç§°**: `gemini-1.5-pro`
- **ç‰¹ç‚¹**: å¼ºå¤§æ€§èƒ½ï¼Œé€‚åˆå¤æ‚åˆ†æ
- **é€‚ç”¨åœºæ™¯**: æ·±åº¦åˆ†æï¼Œé‡è¦æŠ•èµ„å†³ç­–
- **ä¼˜åŠ¿**: åŠŸèƒ½å¼ºå¤§ï¼Œåˆ†ææ·±åº¦é«˜

### Gemini 1.5 Flash  
- **æ¨¡å‹åç§°**: `gemini-1.5-flash`
- **ç‰¹ç‚¹**: å¿«é€Ÿå“åº”ï¼Œæˆæœ¬è¾ƒä½
- **é€‚ç”¨åœºæ™¯**: å¿«é€ŸæŸ¥è¯¢ï¼Œæ‰¹é‡åˆ†æ
- **ä¼˜åŠ¿**: å“åº”é€Ÿåº¦å¿«ï¼Œé€‚åˆé«˜é¢‘ä½¿ç”¨

## ğŸ”§ é…ç½®æ–¹æ³•

### 1. Webç•Œé¢é…ç½®

1. **å¯åŠ¨Webç•Œé¢**:
   ```bash
   python -m streamlit run web/app.py
   ```

2. **åœ¨å·¦ä¾§è¾¹æ ä¸­**:
   - é€‰æ‹© **"Google AI - Geminiæ¨¡å‹"** ä½œä¸ºLLMæä¾›å•†
   - é€‰æ‹©å…·ä½“çš„Geminiæ¨¡å‹
   - å¯ç”¨è®°å¿†åŠŸèƒ½è·å¾—æ›´å¥½æ•ˆæœ

3. **å¼€å§‹åˆ†æ**:
   - è¾“å…¥è‚¡ç¥¨ä»£ç 
   - é€‰æ‹©åˆ†æå¸ˆ
   - ç‚¹å‡»"å¼€å§‹åˆ†æ"

### 2. CLIé…ç½®

```bash
# ä½¿ç”¨Gemini 2.0 Flashæ¨¡å‹
python -m cli.main --llm-provider google --model gemini-2.0-flash --stock AAPL

# ä½¿ç”¨Gemini 1.5 Proè¿›è¡Œæ·±åº¦åˆ†æ
python -m cli.main --llm-provider google --model gemini-1.5-pro --stock TSLA --analysts market fundamentals news
```

### 3. Python APIé…ç½®

```python
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

# é…ç½®Google AI
config = DEFAULT_CONFIG.copy()
config["llm_provider"] = "google"
config["deep_think_llm"] = "gemini-2.0-flash"
config["quick_think_llm"] = "gemini-2.0-flash"
config["memory_enabled"] = True

# åˆ›å»ºåˆ†æå›¾
graph = TradingAgentsGraph(["market", "fundamentals"], config=config)

# æ‰§è¡Œåˆ†æ
state, decision = graph.propagate("AAPL", "2025-06-27")
```

## ğŸ”„ æ™ºèƒ½æ··åˆåµŒå…¥

TradingAgents-CNçš„ä¸€ä¸ªç‹¬ç‰¹åŠŸèƒ½æ˜¯æ™ºèƒ½æ··åˆåµŒå…¥æœåŠ¡ï¼š

### å·¥ä½œåŸç†
```
ğŸ§  Google Gemini (ä¸»è¦æ¨ç†)
    â†“
ğŸ” é˜¿é‡Œç™¾ç‚¼åµŒå…¥ (å‘é‡åŒ–å’Œè®°å¿†)
    â†“  
ğŸ’¾ ChromaDB (å‘é‡æ•°æ®åº“)
    â†“
ğŸ¯ ä¸­æ–‡è‚¡ç¥¨åˆ†æç»“æœ
```

### ä¼˜åŠ¿
- **æœ€ä½³æ€§èƒ½**: Google AIçš„å¼ºå¤§æ¨ç†èƒ½åŠ›
- **ä¸­æ–‡ä¼˜åŒ–**: é˜¿é‡Œç™¾ç‚¼çš„ä¸­æ–‡åµŒå…¥ä¼˜åŠ¿
- **æˆæœ¬æ§åˆ¶**: åˆç†çš„APIè°ƒç”¨æˆæœ¬
- **ç¨³å®šå¯é **: ç»è¿‡å……åˆ†æµ‹è¯•çš„é›†æˆæ–¹æ¡ˆ

## ğŸ§ª æµ‹è¯•é…ç½®

### 1. è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
# æµ‹è¯•Google AIè¿æ¥
python tests/test_gemini_correct.py

# æµ‹è¯•Webç•Œé¢Googleæ¨¡å‹åŠŸèƒ½
python tests/test_web_interface.py

# å®Œæ•´çš„GeminiåŠŸèƒ½æµ‹è¯•
python tests/final_gemini_test.py
```

### 2. éªŒè¯é…ç½®

```bash
# æ£€æŸ¥APIå¯†é’¥é…ç½®
python tests/test_all_apis.py

# æµ‹è¯•ä¸­æ–‡è¾“å‡ºåŠŸèƒ½
python tests/test_chinese_output.py
```

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### æ¨¡å‹é€‰æ‹©å»ºè®®

1. **æ—¥å¸¸ä½¿ç”¨**: æ¨è `gemini-2.0-flash`
   - æ€§èƒ½ä¼˜ç§€ï¼Œæˆæœ¬åˆç†
   - LangChainé›†æˆç¨³å®š
   - ä¸­æ–‡æ”¯æŒå®Œç¾

2. **æ·±åº¦åˆ†æ**: ä½¿ç”¨ `gemini-1.5-pro`
   - é€‚åˆé‡è¦æŠ•èµ„å†³ç­–
   - åˆ†ææ·±åº¦æ›´é«˜
   - æ¨ç†èƒ½åŠ›æ›´å¼º

3. **å¿«é€ŸæŸ¥è¯¢**: ä½¿ç”¨ `gemini-1.5-flash`
   - å“åº”é€Ÿåº¦å¿«
   - é€‚åˆæ‰¹é‡åˆ†æ
   - æˆæœ¬è¾ƒä½

### æœ€ä½³å®è·µ

1. **å¯ç”¨å†…å­˜åŠŸèƒ½**: è®©AIå­¦ä¹ æ‚¨çš„åˆ†æåå¥½
2. **åˆç†é€‰æ‹©åˆ†æå¸ˆ**: æ ¹æ®éœ€è¦é€‰æ‹©ç›¸å…³çš„åˆ†æå¸ˆ
3. **è®¾ç½®é€‚å½“çš„ç ”ç©¶æ·±åº¦**: å¹³è¡¡åˆ†æè´¨é‡å’Œæ—¶é—´æˆæœ¬
4. **å®šæœŸæ£€æŸ¥APIé¢åº¦**: ç¡®ä¿æœ‰è¶³å¤Ÿçš„APIè°ƒç”¨é¢åº¦

## âš ï¸ æ³¨æ„äº‹é¡¹

### APIé™åˆ¶
- Google AIæœ‰APIè°ƒç”¨é¢‘ç‡é™åˆ¶
- å»ºè®®åˆç†æ§åˆ¶åˆ†æé¢‘ç‡
- ç›‘æ§APIä½¿ç”¨é‡å’Œæˆæœ¬

### ç½‘ç»œè¦æ±‚
- éœ€è¦ç¨³å®šçš„ç½‘ç»œè¿æ¥
- æŸäº›åœ°åŒºå¯èƒ½éœ€è¦ç‰¹æ®Šç½‘ç»œé…ç½®
- å»ºè®®ä½¿ç”¨ç¨³å®šçš„ç½‘ç»œç¯å¢ƒ

### æ•°æ®å®‰å…¨
- APIå¯†é’¥ä»…åœ¨æœ¬åœ°ä½¿ç”¨
- ä¸ä¼šä¸Šä¼ åˆ°ä»»ä½•æœåŠ¡å™¨
- å»ºè®®å®šæœŸæ›´æ¢APIå¯†é’¥

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. APIå¯†é’¥æ— æ•ˆ
```bash
# æ£€æŸ¥APIå¯†é’¥æ ¼å¼
echo $GOOGLE_API_KEY

# éªŒè¯APIå¯†é’¥æœ‰æ•ˆæ€§
python tests/test_correct_apis.py
```

#### 2. æ¨¡å‹è°ƒç”¨å¤±è´¥
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- éªŒè¯APIé¢åº¦æ˜¯å¦å……è¶³
- ç¡®è®¤æ¨¡å‹åç§°æ­£ç¡®

#### 3. ä¸­æ–‡è¾“å‡ºå¼‚å¸¸
- æ£€æŸ¥å­—ç¬¦ç¼–ç è®¾ç½®
- éªŒè¯æ¨¡å‹é…ç½®
- è¿è¡Œä¸­æ–‡è¾“å‡ºæµ‹è¯•

### è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. ğŸ“– æŸ¥çœ‹ [å®Œæ•´æ–‡æ¡£](../README.md)
2. ğŸ§ª è¿è¡Œ [æµ‹è¯•ç¨‹åº](../../tests/)
3. ğŸ’¬ æäº¤ [GitHub Issue](https://github.com/hsliuping/TradingAgents-CN/issues)

## ğŸ‰ å¼€å§‹ä½¿ç”¨

ç°åœ¨æ‚¨å·²ç»å®Œæˆäº†Google AIçš„é…ç½®ï¼Œå¯ä»¥å¼€å§‹äº«å—Geminiæ¨¡å‹çš„å¼ºå¤§åˆ†æèƒ½åŠ›äº†ï¼

```bash
# å¯åŠ¨Webç•Œé¢
python -m streamlit run web/app.py

# æˆ–ä½¿ç”¨CLI
python -m cli.main --llm-provider google --model gemini-2.0-flash --stock AAPL
```

ç¥æ‚¨æŠ•èµ„åˆ†ææ„‰å¿«ï¼ğŸš€


<!-- docs/configuration/llm-config.md -->

# å¤§è¯­è¨€æ¨¡å‹é…ç½®

## æ¦‚è¿°

TradingAgents æ¡†æ¶æ”¯æŒå¤šç§å¤§è¯­è¨€æ¨¡å‹æä¾›å•†ï¼ŒåŒ…æ‹¬ OpenAIã€Anthropic å’Œ Google AIã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†å¦‚ä½•é…ç½®å’Œä¼˜åŒ–ä¸åŒçš„ LLM ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚

## æ”¯æŒçš„ LLM æä¾›å•†

### 1. OpenAI

#### æ”¯æŒçš„æ¨¡å‹
```python
openai_models = {
    "gpt-4o": {
        "description": "æœ€æ–°çš„ GPT-4 ä¼˜åŒ–ç‰ˆæœ¬",
        "context_length": 128000,
        "cost_per_1k_tokens": {"input": 0.005, "output": 0.015},
        "recommended_for": ["æ·±åº¦åˆ†æ", "å¤æ‚æ¨ç†", "é«˜è´¨é‡è¾“å‡º"]
    },
    "gpt-4o-mini": {
        "description": "è½»é‡çº§ GPT-4 ç‰ˆæœ¬",
        "context_length": 128000,
        "cost_per_1k_tokens": {"input": 0.00015, "output": 0.0006},
        "recommended_for": ["å¿«é€Ÿä»»åŠ¡", "æˆæœ¬æ•æ„Ÿåœºæ™¯", "å¤§é‡APIè°ƒç”¨"]
    },
    "gpt-4-turbo": {
        "description": "GPT-4 Turbo ç‰ˆæœ¬",
        "context_length": 128000,
        "cost_per_1k_tokens": {"input": 0.01, "output": 0.03},
        "recommended_for": ["å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬", "æ ‡å‡†åˆ†æä»»åŠ¡"]
    },
    "gpt-3.5-turbo": {
        "description": "ç»æµå®ç”¨çš„é€‰æ‹©",
        "context_length": 16385,
        "cost_per_1k_tokens": {"input": 0.0005, "output": 0.0015},
        "recommended_for": ["ç®€å•ä»»åŠ¡", "é¢„ç®—æœ‰é™", "å¿«é€Ÿå“åº”"]
    }
}
```

#### é…ç½®ç¤ºä¾‹
```python
# OpenAI é…ç½®
openai_config = {
    "llm_provider": "openai",
    "backend_url": "https://api.openai.com/v1",
    "deep_think_llm": "gpt-4o",           # ç”¨äºå¤æ‚åˆ†æ
    "quick_think_llm": "gpt-4o-mini",     # ç”¨äºç®€å•ä»»åŠ¡
    "api_key": os.getenv("OPENAI_API_KEY"),
    
    # æ¨¡å‹å‚æ•°
    "model_params": {
        "temperature": 0.1,               # ä½æ¸©åº¦ä¿è¯ä¸€è‡´æ€§
        "max_tokens": 2000,               # æœ€å¤§è¾“å‡ºé•¿åº¦
        "top_p": 0.9,                     # æ ¸é‡‡æ ·å‚æ•°
        "frequency_penalty": 0.0,         # é¢‘ç‡æƒ©ç½š
        "presence_penalty": 0.0,          # å­˜åœ¨æƒ©ç½š
    },
    
    # é€Ÿç‡é™åˆ¶
    "rate_limits": {
        "requests_per_minute": 3500,      # æ¯åˆ†é’Ÿè¯·æ±‚æ•°
        "tokens_per_minute": 90000,       # æ¯åˆ†é’Ÿtokenæ•°
    },
    
    # é‡è¯•é…ç½®
    "retry_config": {
        "max_retries": 3,
        "backoff_factor": 2,
        "timeout": 60
    }
}
```

### 2. Anthropic Claude

#### æ”¯æŒçš„æ¨¡å‹
```python
anthropic_models = {
    "claude-3-opus-20240229": {
        "description": "æœ€å¼ºå¤§çš„ Claude æ¨¡å‹",
        "context_length": 200000,
        "cost_per_1k_tokens": {"input": 0.015, "output": 0.075},
        "recommended_for": ["æœ€å¤æ‚çš„åˆ†æ", "é«˜è´¨é‡æ¨ç†", "åˆ›æ„ä»»åŠ¡"]
    },
    "claude-3-sonnet-20240229": {
        "description": "å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬",
        "context_length": 200000,
        "cost_per_1k_tokens": {"input": 0.003, "output": 0.015},
        "recommended_for": ["æ ‡å‡†åˆ†æä»»åŠ¡", "å¹³è¡¡ä½¿ç”¨åœºæ™¯"]
    },
    "claude-3-haiku-20240307": {
        "description": "å¿«é€Ÿä¸”ç»æµçš„é€‰æ‹©",
        "context_length": 200000,
        "cost_per_1k_tokens": {"input": 0.00025, "output": 0.00125},
        "recommended_for": ["å¿«é€Ÿä»»åŠ¡", "å¤§é‡è°ƒç”¨", "æˆæœ¬ä¼˜åŒ–"]
    }
}
```

#### é…ç½®ç¤ºä¾‹
```python
# Anthropic é…ç½®
anthropic_config = {
    "llm_provider": "anthropic",
    "backend_url": "https://api.anthropic.com",
    "deep_think_llm": "claude-3-opus-20240229",
    "quick_think_llm": "claude-3-haiku-20240307",
    "api_key": os.getenv("ANTHROPIC_API_KEY"),
    
    # æ¨¡å‹å‚æ•°
    "model_params": {
        "temperature": 0.1,
        "max_tokens": 2000,
        "top_p": 0.9,
        "top_k": 40,
    },
    
    # é€Ÿç‡é™åˆ¶
    "rate_limits": {
        "requests_per_minute": 1000,
        "tokens_per_minute": 40000,
    }
}
```

### 3. Google AI (Gemini)

#### æ”¯æŒçš„æ¨¡å‹
```python
google_models = {
    "gemini-pro": {
        "description": "Google çš„ä¸»åŠ›æ¨¡å‹",
        "context_length": 32768,
        "cost_per_1k_tokens": {"input": 0.0005, "output": 0.0015},
        "recommended_for": ["å¤šæ¨¡æ€ä»»åŠ¡", "ä»£ç åˆ†æ", "æ¨ç†ä»»åŠ¡"]
    },
    "gemini-pro-vision": {
        "description": "æ”¯æŒå›¾åƒçš„ Gemini ç‰ˆæœ¬",
        "context_length": 16384,
        "cost_per_1k_tokens": {"input": 0.0005, "output": 0.0015},
        "recommended_for": ["å›¾è¡¨åˆ†æ", "å¤šæ¨¡æ€è¾“å…¥"]
    },
    "gemini-2.0-flash": {
        "description": "æœ€æ–°çš„å¿«é€Ÿç‰ˆæœ¬",
        "context_length": 32768,
        "cost_per_1k_tokens": {"input": 0.0002, "output": 0.0008},
        "recommended_for": ["å¿«é€Ÿå“åº”", "å®æ—¶åˆ†æ"]
    }
}
```

#### é…ç½®ç¤ºä¾‹
```python
# Google AI é…ç½®
google_config = {
    "llm_provider": "google",
    "backend_url": "https://generativelanguage.googleapis.com/v1",
    "deep_think_llm": "gemini-pro",
    "quick_think_llm": "gemini-2.0-flash",
    "api_key": os.getenv("GOOGLE_API_KEY"),
    
    # æ¨¡å‹å‚æ•°
    "model_params": {
        "temperature": 0.1,
        "max_output_tokens": 2000,
        "top_p": 0.9,
        "top_k": 40,
    }
}
```

## LLM é€‰æ‹©ç­–ç•¥

### åŸºäºä»»åŠ¡ç±»å‹çš„é€‰æ‹©
```python
class LLMSelector:
    """LLM é€‰æ‹©å™¨ - æ ¹æ®ä»»åŠ¡é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.task_model_mapping = self._initialize_task_mapping()
        
    def select_model(self, task_type: str, complexity: str = "medium") -> str:
        """æ ¹æ®ä»»åŠ¡ç±»å‹å’Œå¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""
        
        task_config = self.task_model_mapping.get(task_type, {})
        
        if complexity == "high":
            return task_config.get("high_complexity", self.config["deep_think_llm"])
        elif complexity == "low":
            return task_config.get("low_complexity", self.config["quick_think_llm"])
        else:
            return task_config.get("medium_complexity", self.config["deep_think_llm"])
    
    def _initialize_task_mapping(self) -> Dict:
        """åˆå§‹åŒ–ä»»åŠ¡-æ¨¡å‹æ˜ å°„"""
        return {
            "fundamental_analysis": {
                "high_complexity": "gpt-4o",
                "medium_complexity": "gpt-4o-mini",
                "low_complexity": "gpt-3.5-turbo"
            },
            "technical_analysis": {
                "high_complexity": "claude-3-opus-20240229",
                "medium_complexity": "claude-3-sonnet-20240229",
                "low_complexity": "claude-3-haiku-20240307"
            },
            "news_analysis": {
                "high_complexity": "gpt-4o",
                "medium_complexity": "gpt-4o-mini",
                "low_complexity": "gemini-pro"
            },
            "social_sentiment": {
                "high_complexity": "claude-3-sonnet-20240229",
                "medium_complexity": "gpt-4o-mini",
                "low_complexity": "gemini-2.0-flash"
            },
            "risk_assessment": {
                "high_complexity": "gpt-4o",
                "medium_complexity": "claude-3-sonnet-20240229",
                "low_complexity": "gpt-4o-mini"
            },
            "trading_decision": {
                "high_complexity": "gpt-4o",
                "medium_complexity": "gpt-4o",
                "low_complexity": "claude-3-sonnet-20240229"
            }
        }
```

### æˆæœ¬ä¼˜åŒ–ç­–ç•¥
```python
class CostOptimizer:
    """æˆæœ¬ä¼˜åŒ–å™¨ - åœ¨æ€§èƒ½å’Œæˆæœ¬é—´æ‰¾åˆ°å¹³è¡¡"""
    
    def __init__(self, budget_config: Dict):
        self.daily_budget = budget_config.get("daily_budget", 100)  # ç¾å…ƒ
        self.cost_tracking = {}
        self.model_costs = self._load_model_costs()
        
    def get_cost_optimized_config(self, current_usage: Dict) -> Dict:
        """è·å–æˆæœ¬ä¼˜åŒ–çš„é…ç½®"""
        
        remaining_budget = self._calculate_remaining_budget(current_usage)
        
        if remaining_budget > 50:  # é¢„ç®—å……è¶³
            return {
                "deep_think_llm": "gpt-4o",
                "quick_think_llm": "gpt-4o-mini",
                "max_debate_rounds": 3
            }
        elif remaining_budget > 20:  # é¢„ç®—ä¸­ç­‰
            return {
                "deep_think_llm": "gpt-4o-mini",
                "quick_think_llm": "gpt-4o-mini",
                "max_debate_rounds": 2
            }
        else:  # é¢„ç®—ç´§å¼ 
            return {
                "deep_think_llm": "gpt-3.5-turbo",
                "quick_think_llm": "gpt-3.5-turbo",
                "max_debate_rounds": 1
            }
    
    def estimate_request_cost(self, model: str, input_tokens: int, output_tokens: int) -> float:
        """ä¼°ç®—è¯·æ±‚æˆæœ¬"""
        
        model_cost = self.model_costs.get(model, {"input": 0.001, "output": 0.002})
        
        input_cost = (input_tokens / 1000) * model_cost["input"]
        output_cost = (output_tokens / 1000) * model_cost["output"]
        
        return input_cost + output_cost
```

## æ€§èƒ½ä¼˜åŒ–

### æç¤ºè¯ä¼˜åŒ–
```python
class PromptOptimizer:
    """æç¤ºè¯ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.prompt_templates = self._load_prompt_templates()
        
    def optimize_prompt(self, task_type: str, model: str, context: Dict) -> str:
        """ä¼˜åŒ–æç¤ºè¯"""
        
        base_prompt = self.prompt_templates[task_type]["base"]
        
        # æ ¹æ®æ¨¡å‹ç‰¹ç‚¹è°ƒæ•´æç¤ºè¯
        if "gpt" in model.lower():
            optimized_prompt = self._optimize_for_gpt(base_prompt, context)
        elif "claude" in model.lower():
            optimized_prompt = self._optimize_for_claude(base_prompt, context)
        elif "gemini" in model.lower():
            optimized_prompt = self._optimize_for_gemini(base_prompt, context)
        else:
            optimized_prompt = base_prompt
        
        return optimized_prompt
    
    def _optimize_for_gpt(self, prompt: str, context: Dict) -> str:
        """ä¸º GPT æ¨¡å‹ä¼˜åŒ–æç¤ºè¯"""
        
        # GPT å–œæ¬¢ç»“æ„åŒ–çš„æŒ‡ä»¤
        structured_prompt = f"""
ä»»åŠ¡: {context.get('task_description', '')}

æŒ‡ä»¤:
1. ä»”ç»†åˆ†ææä¾›çš„æ•°æ®
2. åº”ç”¨ç›¸å…³çš„é‡‘èåˆ†ææ–¹æ³•
3. æä¾›æ¸…æ™°çš„ç»“è®ºå’Œå»ºè®®
4. åŒ…å«ç½®ä¿¡åº¦è¯„ä¼°

æ•°æ®:
{context.get('data', '')}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”:
- åˆ†æç»“æœ: [ä½ çš„åˆ†æ]
- ç»“è®º: [ä¸»è¦ç»“è®º]
- å»ºè®®: [å…·ä½“å»ºè®®]
- ç½®ä¿¡åº¦: [0-1ä¹‹é—´çš„æ•°å€¼]
"""
        return structured_prompt
    
    def _optimize_for_claude(self, prompt: str, context: Dict) -> str:
        """ä¸º Claude æ¨¡å‹ä¼˜åŒ–æç¤ºè¯"""
        
        # Claude å–œæ¬¢å¯¹è¯å¼çš„æç¤º
        conversational_prompt = f"""
æˆ‘éœ€è¦ä½ ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆæ¥å¸®åŠ©æˆ‘åˆ†æä»¥ä¸‹æ•°æ®ã€‚

{context.get('data', '')}

è¯·ä½ :
1. æ·±å…¥åˆ†æè¿™äº›æ•°æ®çš„å«ä¹‰
2. è¯†åˆ«å…³é”®çš„è¶‹åŠ¿å’Œæ¨¡å¼
3. è¯„ä¼°æ½œåœ¨çš„é£é™©å’Œæœºä¼š
4. ç»™å‡ºä½ çš„ä¸“ä¸šå»ºè®®

è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€å›ç­”ï¼Œå¹¶è§£é‡Šä½ çš„æ¨ç†è¿‡ç¨‹ã€‚
"""
        return conversational_prompt
```

### å¹¶å‘æ§åˆ¶
```python
class LLMConcurrencyManager:
    """LLM å¹¶å‘ç®¡ç†å™¨"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.semaphores = self._initialize_semaphores()
        self.rate_limiters = self._initialize_rate_limiters()
        
    def _initialize_semaphores(self) -> Dict:
        """åˆå§‹åŒ–ä¿¡å·é‡æ§åˆ¶å¹¶å‘"""
        return {
            "openai": asyncio.Semaphore(10),      # OpenAI æœ€å¤š10ä¸ªå¹¶å‘
            "anthropic": asyncio.Semaphore(5),    # Anthropic æœ€å¤š5ä¸ªå¹¶å‘
            "google": asyncio.Semaphore(8)        # Google æœ€å¤š8ä¸ªå¹¶å‘
        }
    
    async def execute_with_concurrency_control(self, provider: str, llm_call: callable) -> Any:
        """åœ¨å¹¶å‘æ§åˆ¶ä¸‹æ‰§è¡ŒLLMè°ƒç”¨"""
        
        semaphore = self.semaphores.get(provider)
        rate_limiter = self.rate_limiters.get(provider)
        
        async with semaphore:
            await rate_limiter.acquire()
            try:
                result = await llm_call()
                return result
            except Exception as e:
                # å¤„ç†é€Ÿç‡é™åˆ¶é”™è¯¯
                if "rate_limit" in str(e).lower():
                    await asyncio.sleep(60)  # ç­‰å¾…1åˆ†é’Ÿ
                    return await llm_call()
                else:
                    raise e
```

## ç›‘æ§å’Œè°ƒè¯•

### LLM æ€§èƒ½ç›‘æ§
```python
class LLMMonitor:
    """LLM æ€§èƒ½ç›‘æ§"""
    
    def __init__(self):
        self.metrics = {
            "request_count": defaultdict(int),
            "response_times": defaultdict(list),
            "token_usage": defaultdict(dict),
            "error_rates": defaultdict(float),
            "costs": defaultdict(float)
        }
    
    def record_request(self, model: str, response_time: float, 
                      input_tokens: int, output_tokens: int, cost: float):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        
        self.metrics["request_count"][model] += 1
        self.metrics["response_times"][model].append(response_time)
        
        if model not in self.metrics["token_usage"]:
            self.metrics["token_usage"][model] = {"input": 0, "output": 0}
        
        self.metrics["token_usage"][model]["input"] += input_tokens
        self.metrics["token_usage"][model]["output"] += output_tokens
        self.metrics["costs"][model] += cost
    
    def get_performance_report(self) -> Dict:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        
        report = {}
        
        for model in self.metrics["request_count"]:
            response_times = self.metrics["response_times"][model]
            
            report[model] = {
                "total_requests": self.metrics["request_count"][model],
                "avg_response_time": sum(response_times) / len(response_times) if response_times else 0,
                "total_input_tokens": self.metrics["token_usage"][model].get("input", 0),
                "total_output_tokens": self.metrics["token_usage"][model].get("output", 0),
                "total_cost": self.metrics["costs"][model],
                "avg_cost_per_request": self.metrics["costs"][model] / self.metrics["request_count"][model] if self.metrics["request_count"][model] > 0 else 0
            }
        
        return report
```

## æœ€ä½³å®è·µ

### 1. æ¨¡å‹é€‰æ‹©å»ºè®®
- **é«˜ç²¾åº¦ä»»åŠ¡**: ä½¿ç”¨ GPT-4o æˆ– Claude-3-Opus
- **å¹³è¡¡åœºæ™¯**: ä½¿ç”¨ GPT-4o-mini æˆ– Claude-3-Sonnet  
- **æˆæœ¬æ•æ„Ÿ**: ä½¿ç”¨ GPT-3.5-turbo æˆ– Claude-3-Haiku
- **å¿«é€Ÿå“åº”**: ä½¿ç”¨ Gemini-2.0-flash

### 2. æˆæœ¬æ§åˆ¶ç­–ç•¥
- è®¾ç½®æ¯æ—¥é¢„ç®—é™åˆ¶
- ä½¿ç”¨è¾ƒå°æ¨¡å‹å¤„ç†ç®€å•ä»»åŠ¡
- å®æ–½æ™ºèƒ½ç¼“å­˜å‡å°‘é‡å¤è°ƒç”¨
- ç›‘æ§tokenä½¿ç”¨é‡

### 3. æ€§èƒ½ä¼˜åŒ–æŠ€å·§
- ä¼˜åŒ–æç¤ºè¯é•¿åº¦å’Œç»“æ„
- ä½¿ç”¨é€‚å½“çš„æ¸©åº¦å‚æ•°
- å®æ–½å¹¶å‘æ§åˆ¶é¿å…é€Ÿç‡é™åˆ¶
- å®šæœŸç›‘æ§å’Œè°ƒæ•´é…ç½®

é€šè¿‡åˆç†çš„LLMé…ç½®å’Œä¼˜åŒ–ï¼Œå¯ä»¥åœ¨ä¿è¯åˆ†æè´¨é‡çš„åŒæ—¶æ§åˆ¶æˆæœ¬å¹¶æé«˜ç³»ç»Ÿæ€§èƒ½ã€‚


<!-- docs/configuration/token-tracking-guide.md -->

# Tokenä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬è·Ÿè¸ªæŒ‡å—

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•é…ç½®å’Œä½¿ç”¨TradingAgentsçš„Tokenä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬è·Ÿè¸ªåŠŸèƒ½ã€‚

## åŠŸèƒ½æ¦‚è¿°

TradingAgentsæä¾›äº†å®Œæ•´çš„Tokenä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬è·Ÿè¸ªåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š

- **å®æ—¶Tokenç»Ÿè®¡**: è‡ªåŠ¨è®°å½•æ¯æ¬¡LLMè°ƒç”¨çš„è¾“å…¥å’Œè¾“å‡ºtokenæ•°é‡
- **æˆæœ¬è®¡ç®—**: æ ¹æ®ä¸åŒä¾›åº”å•†çš„å®šä»·è‡ªåŠ¨è®¡ç®—ä½¿ç”¨æˆæœ¬
- **å¤šå­˜å‚¨æ”¯æŒ**: æ”¯æŒJSONæ–‡ä»¶å­˜å‚¨å’ŒMongoDBæ•°æ®åº“å­˜å‚¨
- **ç»Ÿè®¡åˆ†æ**: æä¾›è¯¦ç»†çš„ä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬åˆ†æ
- **æˆæœ¬è­¦å‘Š**: å½“ä½¿ç”¨æˆæœ¬è¶…è¿‡é˜ˆå€¼æ—¶è‡ªåŠ¨æé†’

## æ”¯æŒçš„LLMä¾›åº”å•†

ç›®å‰æ”¯æŒä»¥ä¸‹LLMä¾›åº”å•†çš„Tokenç»Ÿè®¡ï¼š

- âœ… **DashScope (é˜¿é‡Œç™¾ç‚¼)**: å®Œå…¨æ”¯æŒï¼Œè‡ªåŠ¨æå–APIå“åº”ä¸­çš„tokenä½¿ç”¨é‡
- ğŸ”„ **OpenAI**: è®¡åˆ’æ”¯æŒ
- ğŸ”„ **Google AI**: è®¡åˆ’æ”¯æŒ
- ğŸ”„ **Anthropic**: è®¡åˆ’æ”¯æŒ

## é…ç½®æ–¹æ³•

### 1. åŸºç¡€é…ç½®

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»ºæˆ–ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```bash
# å¯ç”¨æˆæœ¬è·Ÿè¸ªï¼ˆé»˜è®¤å¯ç”¨ï¼‰
ENABLE_COST_TRACKING=true

# æˆæœ¬è­¦å‘Šé˜ˆå€¼ï¼ˆäººæ°‘å¸ï¼‰
COST_ALERT_THRESHOLD=100.0

# DashScope APIå¯†é’¥
DASHSCOPE_API_KEY=your_dashscope_api_key_here
```

### 2. å­˜å‚¨é…ç½®

#### é€‰é¡¹1: JSONæ–‡ä»¶å­˜å‚¨ï¼ˆé»˜è®¤ï¼‰

é»˜è®¤æƒ…å†µä¸‹ï¼ŒTokenä½¿ç”¨è®°å½•ä¿å­˜åœ¨ `config/usage.json` æ–‡ä»¶ä¸­ã€‚

```bash
# æœ€å¤§è®°å½•æ•°é‡ï¼ˆé»˜è®¤10000ï¼‰
MAX_USAGE_RECORDS=10000

# è‡ªåŠ¨ä¿å­˜ä½¿ç”¨è®°å½•ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
AUTO_SAVE_USAGE=true
```

#### é€‰é¡¹2: MongoDBå­˜å‚¨ï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰

å¯¹äºå¤§é‡æ•°æ®å’Œé«˜æ€§èƒ½éœ€æ±‚ï¼Œæ¨èä½¿ç”¨MongoDBå­˜å‚¨ï¼š

```bash
# å¯ç”¨MongoDBå­˜å‚¨
USE_MONGODB_STORAGE=true

# MongoDBè¿æ¥å­—ç¬¦ä¸²
# æœ¬åœ°MongoDB
MONGODB_CONNECTION_STRING=mongodb://localhost:27017/

# æˆ–äº‘MongoDBï¼ˆå¦‚MongoDB Atlasï¼‰
# MONGODB_CONNECTION_STRING=mongodb+srv://username:password@cluster.mongodb.net/

# æ•°æ®åº“åç§°
MONGODB_DATABASE_NAME=tradingagents
```

### 3. å®‰è£…MongoDBä¾èµ–ï¼ˆå¦‚æœä½¿ç”¨MongoDBå­˜å‚¨ï¼‰

```bash
pip install pymongo
```

## ä½¿ç”¨æ–¹æ³•

### 1. è‡ªåŠ¨Tokenç»Ÿè®¡

å½“ä½¿ç”¨DashScopeé€‚é…å™¨æ—¶ï¼ŒTokenç»Ÿè®¡ä¼šè‡ªåŠ¨è¿›è¡Œï¼š

```python
from tradingagents.llm_adapters.dashscope_adapter import ChatDashScope
from langchain_core.messages import HumanMessage

# åˆå§‹åŒ–LLM
llm = ChatDashScope(
    model="qwen-turbo",
    temperature=0.7
)

# å‘é€æ¶ˆæ¯ï¼ˆè‡ªåŠ¨è®°å½•tokenä½¿ç”¨ï¼‰
response = llm.invoke([
    HumanMessage(content="åˆ†æä¸€ä¸‹è‹¹æœå…¬å¸çš„è‚¡ç¥¨")
], session_id="my_session", analysis_type="stock_analysis")
```

### 2. æŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡

```python
from tradingagents.config.config_manager import config_manager

# è·å–æœ€è¿‘30å¤©çš„ç»Ÿè®¡
stats = config_manager.get_usage_statistics(30)

print(f"æ€»æˆæœ¬: Â¥{stats['total_cost']:.4f}")
print(f"æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
print(f"è¾“å…¥tokens: {stats['total_input_tokens']}")
print(f"è¾“å‡ºtokens: {stats['total_output_tokens']}")

# æŒ‰ä¾›åº”å•†æŸ¥çœ‹ç»Ÿè®¡
for provider, provider_stats in stats['provider_stats'].items():
    print(f"{provider}: Â¥{provider_stats['cost']:.4f}")
```

### 3. æŸ¥çœ‹ä¼šè¯æˆæœ¬

```python
from tradingagents.config.config_manager import token_tracker

# æŸ¥çœ‹ç‰¹å®šä¼šè¯çš„æˆæœ¬
session_cost = token_tracker.get_session_cost("my_session")
print(f"ä¼šè¯æˆæœ¬: Â¥{session_cost:.4f}")
```

### 4. ä¼°ç®—æˆæœ¬

```python
# ä¼°ç®—æˆæœ¬ï¼ˆç”¨äºé¢„ç®—è§„åˆ’ï¼‰
estimated_cost = token_tracker.estimate_cost(
    provider="dashscope",
    model_name="qwen-turbo",
    estimated_input_tokens=1000,
    estimated_output_tokens=500
)
print(f"ä¼°ç®—æˆæœ¬: Â¥{estimated_cost:.4f}")
```

## å®šä»·é…ç½®

ç³»ç»Ÿå†…ç½®äº†ä¸»è¦LLMä¾›åº”å•†çš„å®šä»·ä¿¡æ¯ï¼Œä¹Ÿå¯ä»¥è‡ªå®šä¹‰å®šä»·ï¼š

```python
from tradingagents.config.config_manager import config_manager, PricingConfig

# æ·»åŠ è‡ªå®šä¹‰å®šä»·
custom_pricing = PricingConfig(
    provider="dashscope",
    model_name="qwen-max",
    input_price_per_1k=0.02,   # æ¯1000ä¸ªè¾“å…¥tokençš„ä»·æ ¼ï¼ˆäººæ°‘å¸ï¼‰
    output_price_per_1k=0.06,  # æ¯1000ä¸ªè¾“å‡ºtokençš„ä»·æ ¼ï¼ˆäººæ°‘å¸ï¼‰
    currency="CNY"
)

pricing_list = config_manager.load_pricing()
pricing_list.append(custom_pricing)
config_manager.save_pricing(pricing_list)
```

## å†…ç½®å®šä»·è¡¨

### DashScope (é˜¿é‡Œç™¾ç‚¼)

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ (Â¥/1K tokens) | è¾“å‡ºä»·æ ¼ (Â¥/1K tokens) |
|------|----------------------|----------------------|
| qwen-turbo | 0.002 | 0.006 |
| qwen-plus-latest | 0.004 | 0.012 |
| qwen-max | 0.02 | 0.06 |

### OpenAI

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ ($/1K tokens) | è¾“å‡ºä»·æ ¼ ($/1K tokens) |
|------|----------------------|----------------------|
| gpt-3.5-turbo | 0.0015 | 0.002 |
| gpt-4 | 0.03 | 0.06 |
| gpt-4-turbo | 0.01 | 0.03 |

## æµ‹è¯•Tokenç»Ÿè®¡åŠŸèƒ½

è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯åŠŸèƒ½ï¼š

```bash
# æµ‹è¯•DashScope tokenç»Ÿè®¡
python tests/test_dashscope_token_tracking.py
```

## MongoDBå­˜å‚¨ä¼˜åŠ¿

ä½¿ç”¨MongoDBå­˜å‚¨ç›¸æ¯”JSONæ–‡ä»¶å­˜å‚¨æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

1. **é«˜æ€§èƒ½**: æ”¯æŒå¤§é‡æ•°æ®çš„é«˜æ•ˆæŸ¥è¯¢å’Œèšåˆ
2. **å¯æ‰©å±•æ€§**: æ”¯æŒåˆ†å¸ƒå¼éƒ¨ç½²å’Œæ°´å¹³æ‰©å±•
3. **æ•°æ®å®‰å…¨**: æ”¯æŒå¤‡ä»½ã€å¤åˆ¶å’Œæ•…éšœæ¢å¤
4. **é«˜çº§æŸ¥è¯¢**: æ”¯æŒå¤æ‚çš„èšåˆæŸ¥è¯¢å’Œç»Ÿè®¡åˆ†æ
5. **å¹¶å‘æ”¯æŒ**: æ”¯æŒå¤šç”¨æˆ·å¹¶å‘è®¿é—®

### MongoDBç´¢å¼•ä¼˜åŒ–

ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ›å»ºä»¥ä¸‹ç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½ï¼š

- å¤åˆç´¢å¼•ï¼š`(timestamp, provider, model_name)`
- å•å­—æ®µç´¢å¼•ï¼š`session_id`, `analysis_type`

## æˆæœ¬æ§åˆ¶å»ºè®®

1. **è®¾ç½®åˆç†çš„æˆæœ¬è­¦å‘Šé˜ˆå€¼**
2. **å®šæœŸæŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡ï¼Œä¼˜åŒ–ä½¿ç”¨æ¨¡å¼**
3. **æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼ˆå¹³è¡¡æˆæœ¬å’Œæ€§èƒ½ï¼‰**
4. **ä½¿ç”¨ä¼šè¯IDè·Ÿè¸ªç‰¹å®šåˆ†æçš„æˆæœ¬**
5. **å®šæœŸæ¸…ç†æ—§çš„ä½¿ç”¨è®°å½•ï¼ˆMongoDBæ”¯æŒè‡ªåŠ¨æ¸…ç†ï¼‰**

## æ•…éšœæ’é™¤

### 1. Tokenç»Ÿè®¡ä¸å·¥ä½œ

- æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®
- ç¡®è®¤ `ENABLE_COST_TRACKING=true`
- æŸ¥çœ‹æ§åˆ¶å°æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯

### 2. MongoDBè¿æ¥å¤±è´¥

- æ£€æŸ¥MongoDBæœåŠ¡æ˜¯å¦è¿è¡Œ
- éªŒè¯è¿æ¥å­—ç¬¦ä¸²æ ¼å¼
- ç¡®è®¤ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®
- æ£€æŸ¥ç”¨æˆ·æƒé™

### 3. æˆæœ¬è®¡ç®—ä¸å‡†ç¡®

- æ£€æŸ¥å®šä»·é…ç½®æ˜¯å¦æ­£ç¡®
- ç¡®è®¤æ¨¡å‹åç§°åŒ¹é…
- éªŒè¯tokenæå–é€»è¾‘

## æœ€ä½³å®è·µ

1. **ç”Ÿäº§ç¯å¢ƒä½¿ç”¨MongoDBå­˜å‚¨**
2. **å®šæœŸå¤‡ä»½ä½¿ç”¨æ•°æ®**
3. **ç›‘æ§æˆæœ¬è¶‹åŠ¿ï¼ŒåŠæ—¶è°ƒæ•´ç­–ç•¥**
4. **ä½¿ç”¨æœ‰æ„ä¹‰çš„ä¼šè¯IDå’Œåˆ†æç±»å‹**
5. **å®šæœŸæ›´æ–°å®šä»·ä¿¡æ¯**

## æœªæ¥è®¡åˆ’

- [ ] æ”¯æŒæ›´å¤šLLMä¾›åº”å•†çš„Tokenç»Ÿè®¡
- [ ] æ·»åŠ å¯è§†åŒ–ä»ªè¡¨æ¿
- [ ] æ”¯æŒæˆæœ¬é¢„ç®—å’Œé™åˆ¶
- [ ] æ·»åŠ ä½¿ç”¨æŠ¥å‘Šå¯¼å‡ºåŠŸèƒ½
- [ ] æ”¯æŒå›¢é˜Ÿå’Œç”¨æˆ·çº§åˆ«çš„æˆæœ¬è·Ÿè¸ª

<!-- docs/data/caching.md -->

# æ•°æ®ç¼“å­˜ç­–ç•¥

## æ¦‚è¿°

TradingAgents æ¡†æ¶é‡‡ç”¨å¤šå±‚æ¬¡çš„ç¼“å­˜ç­–ç•¥æ¥ä¼˜åŒ–æ•°æ®è®¿é—®æ€§èƒ½ï¼Œå‡å°‘APIè°ƒç”¨æˆæœ¬ï¼Œå¹¶æé«˜ç³»ç»Ÿå“åº”é€Ÿåº¦ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†ç¼“å­˜æ¶æ„ã€ç­–ç•¥ã€å®ç°å’Œæœ€ä½³å®è·µã€‚

## ç¼“å­˜æ¶æ„

### å¤šå±‚ç¼“å­˜è®¾è®¡

```mermaid
graph TB
    subgraph "åº”ç”¨å±‚"
        AGENT1[åˆ†æå¸ˆæ™ºèƒ½ä½“]
        AGENT2[ç ”ç©¶å‘˜æ™ºèƒ½ä½“]
        AGENT3[äº¤æ˜“å‘˜æ™ºèƒ½ä½“]
    end
    
    subgraph "ç¼“å­˜å±‚æ¬¡"
        L1[L1: å†…å­˜ç¼“å­˜<br/>æœ€å¿«è®¿é—®]
        L2[L2: æœ¬åœ°æ–‡ä»¶ç¼“å­˜<br/>æŒä¹…åŒ–å­˜å‚¨]
        L3[L3: Redisç¼“å­˜<br/>åˆ†å¸ƒå¼å…±äº«]
        L4[L4: æ•°æ®åº“ç¼“å­˜<br/>é•¿æœŸå­˜å‚¨]
    end
    
    subgraph "æ•°æ®æº"
        API1[FinnHub API]
        API2[Yahoo Finance]
        API3[Reddit API]
        API4[Google News]
    end
    
    AGENT1 --> L1
    AGENT2 --> L1
    AGENT3 --> L1
    
    L1 --> L2
    L2 --> L3
    L3 --> L4
    
    L4 --> API1
    L4 --> API2
    L4 --> API3
    L4 --> API4
```

## 1. ç¼“å­˜ç®¡ç†å™¨

### æ ¸å¿ƒç¼“å­˜ç±»
```python
class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†å¤šå±‚ç¼“å­˜"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.memory_cache = MemoryCache(config.get("memory_cache", {}))
        self.file_cache = FileCache(config.get("file_cache", {}))
        self.redis_cache = RedisCache(config.get("redis_cache", {})) if config.get("redis_enabled") else None
        self.db_cache = DatabaseCache(config.get("db_cache", {})) if config.get("db_enabled") else None
        
        # ç¼“å­˜ç­–ç•¥é…ç½®
        self.cache_strategies = self._load_cache_strategies()
        self.ttl_config = self._load_ttl_config()
        
    def get(self, key: str, data_type: str = "default") -> Optional[Any]:
        """è·å–ç¼“å­˜æ•°æ® - æŒ‰å±‚æ¬¡æŸ¥æ‰¾"""
        
        # L1: å†…å­˜ç¼“å­˜
        data = self.memory_cache.get(key)
        if data is not None:
            self._record_cache_hit("memory", key, data_type)
            return data
        
        # L2: æ–‡ä»¶ç¼“å­˜
        data = self.file_cache.get(key)
        if data is not None:
            # å›å¡«åˆ°å†…å­˜ç¼“å­˜
            self.memory_cache.set(key, data, self._get_ttl(data_type))
            self._record_cache_hit("file", key, data_type)
            return data
        
        # L3: Redisç¼“å­˜
        if self.redis_cache:
            data = self.redis_cache.get(key)
            if data is not None:
                # å›å¡«åˆ°ä¸Šå±‚ç¼“å­˜
                self.file_cache.set(key, data, self._get_ttl(data_type))
                self.memory_cache.set(key, data, self._get_ttl(data_type))
                self._record_cache_hit("redis", key, data_type)
                return data
        
        # L4: æ•°æ®åº“ç¼“å­˜
        if self.db_cache:
            data = self.db_cache.get(key)
            if data is not None:
                # å›å¡«åˆ°æ‰€æœ‰ä¸Šå±‚ç¼“å­˜
                if self.redis_cache:
                    self.redis_cache.set(key, data, self._get_ttl(data_type))
                self.file_cache.set(key, data, self._get_ttl(data_type))
                self.memory_cache.set(key, data, self._get_ttl(data_type))
                self._record_cache_hit("database", key, data_type)
                return data
        
        # ç¼“å­˜æœªå‘½ä¸­
        self._record_cache_miss(key, data_type)
        return None
    
    def set(self, key: str, data: Any, data_type: str = "default", ttl: Optional[int] = None) -> None:
        """è®¾ç½®ç¼“å­˜æ•°æ® - å†™å…¥æ‰€æœ‰å±‚æ¬¡"""
        
        if ttl is None:
            ttl = self._get_ttl(data_type)
        
        # æ ¹æ®æ•°æ®ç±»å‹å’Œå¤§å°å†³å®šç¼“å­˜ç­–ç•¥
        cache_strategy = self._determine_cache_strategy(data, data_type)
        
        # L1: å†…å­˜ç¼“å­˜ (æ€»æ˜¯ç¼“å­˜å°æ•°æ®)
        if cache_strategy["memory"]:
            self.memory_cache.set(key, data, ttl)
        
        # L2: æ–‡ä»¶ç¼“å­˜ (ç¼“å­˜ä¸­ç­‰å¤§å°æ•°æ®)
        if cache_strategy["file"]:
            self.file_cache.set(key, data, ttl)
        
        # L3: Redisç¼“å­˜ (ç¼“å­˜å…±äº«æ•°æ®)
        if cache_strategy["redis"] and self.redis_cache:
            self.redis_cache.set(key, data, ttl)
        
        # L4: æ•°æ®åº“ç¼“å­˜ (ç¼“å­˜é‡è¦æ•°æ®)
        if cache_strategy["database"] and self.db_cache:
            self.db_cache.set(key, data, ttl)
    
    def _determine_cache_strategy(self, data: Any, data_type: str) -> Dict[str, bool]:
        """ç¡®å®šç¼“å­˜ç­–ç•¥"""
        
        data_size = self._estimate_data_size(data)
        data_importance = self._assess_data_importance(data_type)
        
        strategy = {
            "memory": data_size < 1024 * 1024,  # å°äº1MB
            "file": data_size < 10 * 1024 * 1024,  # å°äº10MB
            "redis": data_importance >= 0.7,  # é‡è¦æ•°æ®
            "database": data_importance >= 0.8 or data_type in ["fundamental_data", "company_profile"]
        }
        
        return strategy
    
    def _get_ttl(self, data_type: str) -> int:
        """è·å–æ•°æ®ç±»å‹çš„TTL"""
        return self.ttl_config.get(data_type, self.ttl_config["default"])
```

## 2. å†…å­˜ç¼“å­˜ (L1)

### é«˜é€Ÿå†…å­˜ç¼“å­˜
```python
class MemoryCache:
    """å†…å­˜ç¼“å­˜ - æœ€å¿«çš„ç¼“å­˜å±‚"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.cache = {}
        self.access_times = {}
        self.max_size = config.get("max_size", 1000)
        self.cleanup_threshold = config.get("cleanup_threshold", 0.8)
        
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜é¡¹"""
        if key in self.cache:
            item = self.cache[key]
            
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if self._is_expired(item):
                del self.cache[key]
                if key in self.access_times:
                    del self.access_times[key]
                return None
            
            # æ›´æ–°è®¿é—®æ—¶é—´
            self.access_times[key] = time.time()
            return item["data"]
        
        return None
    
    def set(self, key: str, data: Any, ttl: int) -> None:
        """è®¾ç½®ç¼“å­˜é¡¹"""
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†
        if len(self.cache) >= self.max_size * self.cleanup_threshold:
            self._cleanup_cache()
        
        # å­˜å‚¨æ•°æ®
        self.cache[key] = {
            "data": data,
            "timestamp": time.time(),
            "ttl": ttl
        }
        self.access_times[key] = time.time()
    
    def _cleanup_cache(self) -> None:
        """æ¸…ç†è¿‡æœŸå’Œæœ€å°‘ä½¿ç”¨çš„ç¼“å­˜é¡¹"""
        
        current_time = time.time()
        
        # é¦–å…ˆæ¸…ç†è¿‡æœŸé¡¹
        expired_keys = []
        for key, item in self.cache.items():
            if self._is_expired(item):
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.cache[key]
            if key in self.access_times:
                del self.access_times[key]
        
        # å¦‚æœè¿˜æ˜¯å¤ªå¤šï¼Œä½¿ç”¨LRUç­–ç•¥æ¸…ç†
        if len(self.cache) >= self.max_size * self.cleanup_threshold:
            # æŒ‰è®¿é—®æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€å°‘ä½¿ç”¨çš„
            sorted_keys = sorted(self.access_times.keys(), key=lambda k: self.access_times[k])
            keys_to_remove = sorted_keys[:len(sorted_keys) // 4]  # åˆ é™¤25%
            
            for key in keys_to_remove:
                if key in self.cache:
                    del self.cache[key]
                if key in self.access_times:
                    del self.access_times[key]
    
    def _is_expired(self, item: Dict) -> bool:
        """æ£€æŸ¥ç¼“å­˜é¡¹æ˜¯å¦è¿‡æœŸ"""
        return time.time() - item["timestamp"] > item["ttl"]
```

## 3. æ–‡ä»¶ç¼“å­˜ (L2)

### æŒä¹…åŒ–æ–‡ä»¶ç¼“å­˜
```python
class FileCache:
    """æ–‡ä»¶ç¼“å­˜ - æŒä¹…åŒ–å­˜å‚¨"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.cache_dir = Path(config.get("cache_dir", "./cache"))
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.compression_enabled = config.get("compression", True)
        self.max_file_size = config.get("max_file_size", 50 * 1024 * 1024)  # 50MB
        
    def get(self, key: str) -> Optional[Any]:
        """ä»æ–‡ä»¶è·å–ç¼“å­˜æ•°æ®"""
        
        cache_file = self._get_cache_file_path(key)
        
        if not cache_file.exists():
            return None
        
        try:
            # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
            if self._is_file_expired(cache_file, key):
                cache_file.unlink()  # åˆ é™¤è¿‡æœŸæ–‡ä»¶
                return None
            
            # è¯»å–æ•°æ®
            with open(cache_file, 'rb') as f:
                if self.compression_enabled:
                    compressed_data = f.read()
                    data = self._decompress_data(compressed_data)
                else:
                    data = pickle.load(f)
            
            return data
            
        except Exception as e:
            print(f"Error reading cache file {cache_file}: {e}")
            # åˆ é™¤æŸåçš„ç¼“å­˜æ–‡ä»¶
            if cache_file.exists():
                cache_file.unlink()
            return None
    
    def set(self, key: str, data: Any, ttl: int) -> None:
        """å°†æ•°æ®å†™å…¥æ–‡ä»¶ç¼“å­˜"""
        
        cache_file = self._get_cache_file_path(key)
        
        try:
            # æ£€æŸ¥æ•°æ®å¤§å°
            data_size = self._estimate_data_size(data)
            if data_size > self.max_file_size:
                print(f"Data too large for file cache: {data_size} bytes")
                return
            
            # åˆ›å»ºç¼“å­˜å…ƒæ•°æ®
            cache_data = {
                "data": data,
                "timestamp": time.time(),
                "ttl": ttl,
                "key": key
            }
            
            # å†™å…¥æ–‡ä»¶
            with open(cache_file, 'wb') as f:
                if self.compression_enabled:
                    compressed_data = self._compress_data(cache_data)
                    f.write(compressed_data)
                else:
                    pickle.dump(cache_data, f)
            
        except Exception as e:
            print(f"Error writing cache file {cache_file}: {e}")
    
    def _get_cache_file_path(self, key: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        # ä½¿ç”¨å“ˆå¸Œé¿å…æ–‡ä»¶åè¿‡é•¿æˆ–åŒ…å«ç‰¹æ®Šå­—ç¬¦
        key_hash = hashlib.md5(key.encode()).hexdigest()
        return self.cache_dir / f"{key_hash}.cache"
    
    def _is_file_expired(self, cache_file: Path, key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦è¿‡æœŸ"""
        try:
            with open(cache_file, 'rb') as f:
                if self.compression_enabled:
                    compressed_data = f.read()
                    cache_data = self._decompress_data(compressed_data)
                else:
                    cache_data = pickle.load(f)
            
            return time.time() - cache_data["timestamp"] > cache_data["ttl"]
            
        except Exception:
            return True  # å¦‚æœæ— æ³•è¯»å–ï¼Œè®¤ä¸ºå·²è¿‡æœŸ
    
    def _compress_data(self, data: Any) -> bytes:
        """å‹ç¼©æ•°æ®"""
        import gzip
        pickled_data = pickle.dumps(data)
        return gzip.compress(pickled_data)
    
    def _decompress_data(self, compressed_data: bytes) -> Any:
        """è§£å‹æ•°æ®"""
        import gzip
        pickled_data = gzip.decompress(compressed_data)
        return pickle.loads(pickled_data)
    
    def cleanup_expired_files(self) -> None:
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ–‡ä»¶"""
        for cache_file in self.cache_dir.glob("*.cache"):
            try:
                if self._is_file_expired(cache_file, ""):
                    cache_file.unlink()
            except Exception as e:
                print(f"Error checking cache file {cache_file}: {e}")
```

## 4. Redisç¼“å­˜ (L3)

### åˆ†å¸ƒå¼å…±äº«ç¼“å­˜
```python
class RedisCache:
    """Redisç¼“å­˜ - åˆ†å¸ƒå¼å…±äº«ç¼“å­˜"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.redis_client = self._initialize_redis_client()
        self.key_prefix = config.get("key_prefix", "tradingagents:")
        self.serialization_format = config.get("serialization", "pickle")  # pickle, json, msgpack
        
    def _initialize_redis_client(self):
        """åˆå§‹åŒ–Rediså®¢æˆ·ç«¯"""
        try:
            import redis
            
            redis_config = {
                "host": self.config.get("host", "localhost"),
                "port": self.config.get("port", 6379),
                "db": self.config.get("db", 0),
                "password": self.config.get("password"),
                "socket_timeout": self.config.get("timeout", 5),
                "socket_connect_timeout": self.config.get("connect_timeout", 5),
                "retry_on_timeout": True,
                "health_check_interval": 30
            }
            
            # ç§»é™¤Noneå€¼
            redis_config = {k: v for k, v in redis_config.items() if v is not None}
            
            client = redis.Redis(**redis_config)
            
            # æµ‹è¯•è¿æ¥
            client.ping()
            print("Redis connection established")
            
            return client
            
        except Exception as e:
            print(f"Failed to connect to Redis: {e}")
            return None
    
    def get(self, key: str) -> Optional[Any]:
        """ä»Redisè·å–æ•°æ®"""
        if not self.redis_client:
            return None
        
        try:
            full_key = self.key_prefix + key
            data = self.redis_client.get(full_key)
            
            if data is None:
                return None
            
            # ååºåˆ—åŒ–æ•°æ®
            return self._deserialize_data(data)
            
        except Exception as e:
            print(f"Error getting data from Redis: {e}")
            return None
    
    def set(self, key: str, data: Any, ttl: int) -> None:
        """å‘Redisè®¾ç½®æ•°æ®"""
        if not self.redis_client:
            return
        
        try:
            full_key = self.key_prefix + key
            
            # åºåˆ—åŒ–æ•°æ®
            serialized_data = self._serialize_data(data)
            
            # è®¾ç½®æ•°æ®å’ŒTTL
            self.redis_client.setex(full_key, ttl, serialized_data)
            
        except Exception as e:
            print(f"Error setting data to Redis: {e}")
    
    def _serialize_data(self, data: Any) -> bytes:
        """åºåˆ—åŒ–æ•°æ®"""
        if self.serialization_format == "pickle":
            return pickle.dumps(data)
        elif self.serialization_format == "json":
            import json
            return json.dumps(data, default=str).encode('utf-8')
        elif self.serialization_format == "msgpack":
            import msgpack
            return msgpack.packb(data, default=str)
        else:
            raise ValueError(f"Unsupported serialization format: {self.serialization_format}")
    
    def _deserialize_data(self, data: bytes) -> Any:
        """ååºåˆ—åŒ–æ•°æ®"""
        if self.serialization_format == "pickle":
            return pickle.loads(data)
        elif self.serialization_format == "json":
            import json
            return json.loads(data.decode('utf-8'))
        elif self.serialization_format == "msgpack":
            import msgpack
            return msgpack.unpackb(data, raw=False)
        else:
            raise ValueError(f"Unsupported serialization format: {self.serialization_format}")
    
    def delete(self, key: str) -> None:
        """åˆ é™¤Redisä¸­çš„æ•°æ®"""
        if not self.redis_client:
            return
        
        try:
            full_key = self.key_prefix + key
            self.redis_client.delete(full_key)
        except Exception as e:
            print(f"Error deleting data from Redis: {e}")
    
    def clear_expired(self) -> None:
        """æ¸…ç†è¿‡æœŸçš„é”®ï¼ˆRedisè‡ªåŠ¨å¤„ç†TTLï¼‰"""
        # Redisä¼šè‡ªåŠ¨æ¸…ç†è¿‡æœŸé”®ï¼Œè¿™é‡Œå¯ä»¥æ·»åŠ é¢å¤–çš„æ¸…ç†é€»è¾‘
        pass
```

## 5. ç¼“å­˜ç­–ç•¥é…ç½®

### TTLé…ç½®
```python
# ä¸åŒæ•°æ®ç±»å‹çš„TTLé…ç½®
TTL_CONFIG = {
    "price_data": 60,           # 1åˆ†é’Ÿ - ä»·æ ¼æ•°æ®å˜åŒ–å¿«
    "fundamental_data": 3600,   # 1å°æ—¶ - åŸºæœ¬é¢æ•°æ®ç›¸å¯¹ç¨³å®š
    "company_profile": 86400,   # 24å°æ—¶ - å…¬å¸ä¿¡æ¯å˜åŒ–å¾ˆå°‘
    "news_data": 1800,          # 30åˆ†é’Ÿ - æ–°é—»æ•°æ®ä¸­ç­‰é¢‘ç‡
    "social_data": 900,         # 15åˆ†é’Ÿ - ç¤¾äº¤åª’ä½“æ•°æ®å˜åŒ–è¾ƒå¿«
    "technical_indicators": 300, # 5åˆ†é’Ÿ - æŠ€æœ¯æŒ‡æ ‡éœ€è¦è¾ƒæ–°æ•°æ®
    "market_data": 600,         # 10åˆ†é’Ÿ - å¸‚åœºæ•°æ®ä¸­ç­‰é¢‘ç‡
    "historical_data": 7200,    # 2å°æ—¶ - å†å²æ•°æ®ç›¸å¯¹ç¨³å®š
    "default": 1800             # 30åˆ†é’Ÿ - é»˜è®¤TTL
}

# ç¼“å­˜é‡è¦æ€§è¯„åˆ†
DATA_IMPORTANCE = {
    "price_data": 0.9,          # é«˜é‡è¦æ€§
    "fundamental_data": 0.8,    # é«˜é‡è¦æ€§
    "company_profile": 0.7,     # ä¸­é«˜é‡è¦æ€§
    "news_data": 0.6,           # ä¸­ç­‰é‡è¦æ€§
    "social_data": 0.5,         # ä¸­ç­‰é‡è¦æ€§
    "technical_indicators": 0.7, # ä¸­é«˜é‡è¦æ€§
    "market_data": 0.6,         # ä¸­ç­‰é‡è¦æ€§
    "historical_data": 0.8,     # é«˜é‡è¦æ€§
}
```

## 6. ç¼“å­˜ç›‘æ§å’Œä¼˜åŒ–

### ç¼“å­˜æ€§èƒ½ç›‘æ§
```python
class CacheMonitor:
    """ç¼“å­˜æ€§èƒ½ç›‘æ§"""
    
    def __init__(self):
        self.metrics = {
            "hits": defaultdict(int),
            "misses": defaultdict(int),
            "hit_rates": defaultdict(float),
            "response_times": defaultdict(list),
            "cache_sizes": defaultdict(int)
        }
        
    def record_hit(self, cache_level: str, key: str, data_type: str, response_time: float = None):
        """è®°å½•ç¼“å­˜å‘½ä¸­"""
        self.metrics["hits"][cache_level] += 1
        if response_time:
            self.metrics["response_times"][cache_level].append(response_time)
        
        self._update_hit_rate(cache_level)
    
    def record_miss(self, key: str, data_type: str):
        """è®°å½•ç¼“å­˜æœªå‘½ä¸­"""
        self.metrics["misses"]["total"] += 1
        self._update_hit_rate("total")
    
    def _update_hit_rate(self, cache_level: str):
        """æ›´æ–°å‘½ä¸­ç‡"""
        hits = self.metrics["hits"][cache_level]
        misses = self.metrics["misses"].get(cache_level, 0)
        total = hits + misses
        
        if total > 0:
            self.metrics["hit_rates"][cache_level] = hits / total
    
    def get_performance_report(self) -> Dict:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        return {
            "hit_rates": dict(self.metrics["hit_rates"]),
            "total_hits": sum(self.metrics["hits"].values()),
            "total_misses": sum(self.metrics["misses"].values()),
            "avg_response_times": {
                level: sum(times) / len(times) if times else 0
                for level, times in self.metrics["response_times"].items()
            },
            "cache_efficiency": self._calculate_cache_efficiency()
        }
    
    def _calculate_cache_efficiency(self) -> float:
        """è®¡ç®—ç¼“å­˜æ•ˆç‡"""
        total_hits = sum(self.metrics["hits"].values())
        total_requests = total_hits + sum(self.metrics["misses"].values())
        
        return total_hits / total_requests if total_requests > 0 else 0.0
```

## 7. ç¼“å­˜æœ€ä½³å®è·µ

### ä½¿ç”¨å»ºè®®
```python
class CacheBestPractices:
    """ç¼“å­˜æœ€ä½³å®è·µæŒ‡å—"""
    
    @staticmethod
    def generate_cache_key(symbol: str, data_type: str, date: str = None, **kwargs) -> str:
        """ç”Ÿæˆæ ‡å‡†åŒ–çš„ç¼“å­˜é”®"""
        
        key_parts = [symbol.upper(), data_type]
        
        if date:
            key_parts.append(date)
        
        # æ·»åŠ å…¶ä»–å‚æ•°
        for k, v in sorted(kwargs.items()):
            key_parts.append(f"{k}:{v}")
        
        return ":".join(key_parts)
    
    @staticmethod
    def should_cache_data(data: Any, data_type: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç¼“å­˜æ•°æ®"""
        
        # ä¸ç¼“å­˜ç©ºæ•°æ®
        if not data:
            return False
        
        # ä¸ç¼“å­˜é”™è¯¯æ•°æ®
        if isinstance(data, dict) and "error" in data:
            return False
        
        # ä¸ç¼“å­˜è¿‡å¤§çš„æ•°æ®
        data_size = CacheBestPractices._estimate_size(data)
        if data_size > 100 * 1024 * 1024:  # 100MB
            return False
        
        return True
    
    @staticmethod
    def _estimate_size(obj: Any) -> int:
        """ä¼°ç®—å¯¹è±¡å¤§å°"""
        try:
            return len(pickle.dumps(obj))
        except:
            return 0
```

é€šè¿‡è¿™å¥—å®Œæ•´çš„ç¼“å­˜ç­–ç•¥ï¼ŒTradingAgents èƒ½å¤Ÿæ˜¾è‘—æé«˜æ•°æ®è®¿é—®æ€§èƒ½ï¼Œå‡å°‘APIè°ƒç”¨æˆæœ¬ï¼Œå¹¶æä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒã€‚


<!-- docs/data/data-processing.md -->

# æ•°æ®å¤„ç†æµç¨‹

## æ¦‚è¿°

TradingAgents æ¡†æ¶çš„æ•°æ®å¤„ç†ç³»ç»Ÿè´Ÿè´£å°†æ¥è‡ªå¤šä¸ªæ•°æ®æºçš„åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ™ºèƒ½ä½“å¯ä»¥ä½¿ç”¨çš„æ ‡å‡†åŒ–ã€é«˜è´¨é‡ä¿¡æ¯ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†æ•°æ®è·å–ã€æ¸…æ´—ã€è½¬æ¢ã€éªŒè¯å’Œåˆ†å‘çš„å®Œæ•´æµç¨‹ã€‚

## æ•°æ®å¤„ç†æ¶æ„

### æ•°æ®å¤„ç†ç®¡é“

```mermaid
graph TB
    subgraph "æ•°æ®è·å–å±‚"
        API1[FinnHub API]
        API2[Yahoo Finance]
        API3[Reddit API]
        API4[Google News]
    end
    
    subgraph "æ•°æ®é¢„å¤„ç†å±‚"
        COLLECT[æ•°æ®æ”¶é›†å™¨]
        VALIDATE[æ•°æ®éªŒè¯å™¨]
        CLEAN[æ•°æ®æ¸…æ´—å™¨]
        NORMALIZE[æ•°æ®æ ‡å‡†åŒ–å™¨]
    end
    
    subgraph "æ•°æ®è½¬æ¢å±‚"
        TRANSFORM[æ•°æ®è½¬æ¢å™¨]
        ENRICH[æ•°æ®å¢å¼ºå™¨]
        AGGREGATE[æ•°æ®èšåˆå™¨]
        FEATURE[ç‰¹å¾å·¥ç¨‹å™¨]
    end
    
    subgraph "æ•°æ®å­˜å‚¨å±‚"
        CACHE[ç¼“å­˜ç³»ç»Ÿ]
        DATABASE[æ•°æ®åº“]
        MEMORY[å†…å­˜å­˜å‚¨]
    end
    
    subgraph "æ•°æ®åˆ†å‘å±‚"
        ROUTER[æ•°æ®è·¯ç”±å™¨]
        FORMATTER[æ ¼å¼åŒ–å™¨]
        DISPATCHER[åˆ†å‘å™¨]
    end
    
    API1 --> COLLECT
    API2 --> COLLECT
    API3 --> COLLECT
    API4 --> COLLECT
    
    COLLECT --> VALIDATE
    VALIDATE --> CLEAN
    CLEAN --> NORMALIZE
    
    NORMALIZE --> TRANSFORM
    TRANSFORM --> ENRICH
    ENRICH --> AGGREGATE
    AGGREGATE --> FEATURE
    
    FEATURE --> CACHE
    FEATURE --> DATABASE
    FEATURE --> MEMORY
    
    CACHE --> ROUTER
    DATABASE --> ROUTER
    MEMORY --> ROUTER
    
    ROUTER --> FORMATTER
    FORMATTER --> DISPATCHER
```

## 1. æ•°æ®æ”¶é›†å™¨

### æ ¸å¿ƒåŠŸèƒ½
```python
class DataCollector:
    """æ•°æ®æ”¶é›†å™¨ - ç»Ÿä¸€æ”¶é›†å„æ•°æ®æºçš„æ•°æ®"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.data_sources = self._initialize_data_sources()
        self.collection_scheduler = CollectionScheduler()
        self.error_handler = DataErrorHandler()
        
    def collect_comprehensive_data(self, symbol: str, date: str = None) -> Dict:
        """æ”¶é›†ç»¼åˆæ•°æ®"""
        
        collection_tasks = {
            "price_data": self._collect_price_data,
            "fundamental_data": self._collect_fundamental_data,
            "technical_data": self._collect_technical_data,
            "news_data": self._collect_news_data,
            "social_data": self._collect_social_data,
            "market_data": self._collect_market_data
        }
        
        collected_data = {}
        collection_metadata = {}
        
        # å¹¶è¡Œæ”¶é›†æ•°æ®
        with ThreadPoolExecutor(max_workers=6) as executor:
            future_to_task = {
                executor.submit(task_func, symbol, date): task_name
                for task_name, task_func in collection_tasks.items()
            }
            
            for future in as_completed(future_to_task):
                task_name = future_to_task[future]
                try:
                    result = future.result(timeout=30)  # 30ç§’è¶…æ—¶
                    collected_data[task_name] = result["data"]
                    collection_metadata[task_name] = result["metadata"]
                except Exception as e:
                    self.error_handler.handle_collection_error(task_name, e)
                    collected_data[task_name] = {}
                    collection_metadata[task_name] = {"error": str(e)}
        
        return {
            "data": collected_data,
            "metadata": collection_metadata,
            "collection_timestamp": datetime.now().isoformat(),
            "symbol": symbol,
            "date": date
        }
    
    def _collect_price_data(self, symbol: str, date: str = None) -> Dict:
        """æ”¶é›†ä»·æ ¼æ•°æ®"""
        
        price_sources = ["finnhub", "yahoo_finance"]
        price_data = {}
        
        for source in price_sources:
            try:
                if source == "finnhub" and "finnhub" in self.data_sources:
                    data = self.data_sources["finnhub"].get_stock_price(symbol)
                    price_data["finnhub"] = data
                    break  # ä¼˜å…ˆä½¿ç”¨ FinnHub
                elif source == "yahoo_finance":
                    data = self.data_sources["yahoo"].get_current_price(symbol)
                    price_data["yahoo"] = data
            except Exception as e:
                print(f"Error collecting price data from {source}: {e}")
        
        # é€‰æ‹©æœ€ä½³æ•°æ®æº
        best_price_data = self._select_best_price_data(price_data)
        
        return {
            "data": best_price_data,
            "metadata": {
                "sources_attempted": price_sources,
                "sources_successful": list(price_data.keys()),
                "primary_source": self._identify_primary_source(price_data)
            }
        }
    
    def _collect_fundamental_data(self, symbol: str, date: str = None) -> Dict:
        """æ”¶é›†åŸºæœ¬é¢æ•°æ®"""
        
        fundamental_data = {}
        
        # è´¢åŠ¡æŠ¥è¡¨æ•°æ®
        try:
            if "finnhub" in self.data_sources:
                financials = self.data_sources["finnhub"].get_financial_statements(symbol)
                fundamental_data["financials"] = financials
        except Exception as e:
            print(f"Error collecting financial statements: {e}")
        
        # å…¬å¸æ¦‚å†µ
        try:
            if "finnhub" in self.data_sources:
                profile = self.data_sources["finnhub"].get_company_profile(symbol)
                fundamental_data["profile"] = profile
        except Exception as e:
            print(f"Error collecting company profile: {e}")
        
        # ä¼°å€¼æŒ‡æ ‡
        try:
            if "yahoo" in self.data_sources:
                valuation = self.data_sources["yahoo"].get_valuation_metrics(symbol)
                fundamental_data["valuation"] = valuation
        except Exception as e:
            print(f"Error collecting valuation metrics: {e}")
        
        return {
            "data": fundamental_data,
            "metadata": {
                "data_completeness": self._assess_fundamental_completeness(fundamental_data),
                "data_freshness": self._assess_data_freshness(fundamental_data)
            }
        }
```

## 2. æ•°æ®éªŒè¯å™¨

### æ•°æ®è´¨é‡æ£€æŸ¥
```python
class DataValidator:
    """æ•°æ®éªŒè¯å™¨ - ç¡®ä¿æ•°æ®è´¨é‡å’Œå®Œæ•´æ€§"""
    
    def __init__(self):
        self.validation_rules = self._load_validation_rules()
        self.quality_metrics = QualityMetrics()
        
    def validate_collected_data(self, collected_data: Dict) -> Dict:
        """éªŒè¯æ”¶é›†çš„æ•°æ®"""
        
        validation_results = {}
        
        for data_type, data in collected_data["data"].items():
            validation_result = self._validate_data_type(data_type, data)
            validation_results[data_type] = validation_result
        
        # è®¡ç®—æ•´ä½“æ•°æ®è´¨é‡è¯„åˆ†
        overall_quality = self._calculate_overall_quality(validation_results)
        
        return {
            "validation_results": validation_results,
            "overall_quality": overall_quality,
            "quality_grade": self._assign_quality_grade(overall_quality),
            "issues_found": self._extract_issues(validation_results),
            "recommendations": self._generate_quality_recommendations(validation_results)
        }
    
    def _validate_data_type(self, data_type: str, data: Dict) -> Dict:
        """éªŒè¯ç‰¹å®šç±»å‹çš„æ•°æ®"""
        
        validation_checks = {
            "completeness": self._check_completeness(data_type, data),
            "accuracy": self._check_accuracy(data_type, data),
            "consistency": self._check_consistency(data_type, data),
            "timeliness": self._check_timeliness(data_type, data),
            "format": self._check_format(data_type, data)
        }
        
        # è®¡ç®—éªŒè¯è¯„åˆ†
        validation_score = sum(check["score"] for check in validation_checks.values()) / len(validation_checks)
        
        return {
            "checks": validation_checks,
            "validation_score": validation_score,
            "status": "passed" if validation_score > 0.8 else "warning" if validation_score > 0.6 else "failed",
            "critical_issues": [check["issue"] for check in validation_checks.values() if check.get("critical")]
        }
    
    def _check_completeness(self, data_type: str, data: Dict) -> Dict:
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        
        required_fields = self.validation_rules[data_type]["required_fields"]
        missing_fields = [field for field in required_fields if field not in data]
        
        completeness_score = 1.0 - (len(missing_fields) / len(required_fields))
        
        return {
            "score": completeness_score,
            "missing_fields": missing_fields,
            "critical": len(missing_fields) > len(required_fields) * 0.5,
            "issue": f"Missing {len(missing_fields)} required fields" if missing_fields else None
        }
    
    def _check_accuracy(self, data_type: str, data: Dict) -> Dict:
        """æ£€æŸ¥æ•°æ®å‡†ç¡®æ€§"""
        
        accuracy_issues = []
        
        if data_type == "price_data":
            # ä»·æ ¼åˆç†æ€§æ£€æŸ¥
            if "current_price" in data:
                price = data["current_price"]
                if not isinstance(price, (int, float)) or price <= 0:
                    accuracy_issues.append("Invalid price value")
                elif price > 10000:  # å¼‚å¸¸é«˜ä»·æ ¼
                    accuracy_issues.append("Unusually high price")
        
        elif data_type == "fundamental_data":
            # è´¢åŠ¡æ•°æ®åˆç†æ€§æ£€æŸ¥
            if "market_cap" in data:
                market_cap = data["market_cap"]
                if market_cap and market_cap < 0:
                    accuracy_issues.append("Negative market cap")
        
        accuracy_score = 1.0 if not accuracy_issues else 0.5
        
        return {
            "score": accuracy_score,
            "issues": accuracy_issues,
            "critical": len(accuracy_issues) > 0,
            "issue": "; ".join(accuracy_issues) if accuracy_issues else None
        }
```

## 3. æ•°æ®æ¸…æ´—å™¨

### æ•°æ®æ¸…æ´—æµç¨‹
```python
class DataCleaner:
    """æ•°æ®æ¸…æ´—å™¨ - æ¸…ç†å’Œä¿®å¤æ•°æ®é—®é¢˜"""
    
    def __init__(self):
        self.cleaning_strategies = self._initialize_cleaning_strategies()
        self.outlier_detector = OutlierDetector()
        
    def clean_data(self, validated_data: Dict) -> Dict:
        """æ¸…æ´—æ•°æ®"""
        
        cleaned_data = {}
        cleaning_log = {}
        
        for data_type, data in validated_data["data"].items():
            cleaning_result = self._clean_data_type(data_type, data)
            cleaned_data[data_type] = cleaning_result["cleaned_data"]
            cleaning_log[data_type] = cleaning_result["cleaning_log"]
        
        return {
            "cleaned_data": cleaned_data,
            "cleaning_log": cleaning_log,
            "cleaning_summary": self._generate_cleaning_summary(cleaning_log)
        }
    
    def _clean_data_type(self, data_type: str, data: Dict) -> Dict:
        """æ¸…æ´—ç‰¹å®šç±»å‹çš„æ•°æ®"""
        
        cleaned_data = data.copy()
        cleaning_operations = []
        
        # å¤„ç†ç¼ºå¤±å€¼
        missing_value_result = self._handle_missing_values(data_type, cleaned_data)
        cleaned_data.update(missing_value_result["data"])
        cleaning_operations.extend(missing_value_result["operations"])
        
        # å¤„ç†å¼‚å¸¸å€¼
        outlier_result = self._handle_outliers(data_type, cleaned_data)
        cleaned_data.update(outlier_result["data"])
        cleaning_operations.extend(outlier_result["operations"])
        
        # æ•°æ®ç±»å‹è½¬æ¢
        type_conversion_result = self._convert_data_types(data_type, cleaned_data)
        cleaned_data.update(type_conversion_result["data"])
        cleaning_operations.extend(type_conversion_result["operations"])
        
        # æ•°æ®æ ¼å¼æ ‡å‡†åŒ–
        standardization_result = self._standardize_formats(data_type, cleaned_data)
        cleaned_data.update(standardization_result["data"])
        cleaning_operations.extend(standardization_result["operations"])
        
        return {
            "cleaned_data": cleaned_data,
            "cleaning_log": {
                "operations": cleaning_operations,
                "data_quality_improvement": self._measure_quality_improvement(data, cleaned_data)
            }
        }
    
    def _handle_missing_values(self, data_type: str, data: Dict) -> Dict:
        """å¤„ç†ç¼ºå¤±å€¼"""
        
        operations = []
        updated_data = {}
        
        if data_type == "price_data":
            # ä»·æ ¼æ•°æ®çš„ç¼ºå¤±å€¼å¤„ç†
            if "current_price" not in data or data["current_price"] is None:
                # å°è¯•ä»å†å²æ•°æ®æ¨æ–­
                if "previous_close" in data and data["previous_close"]:
                    updated_data["current_price"] = data["previous_close"]
                    operations.append("Imputed current_price from previous_close")
        
        elif data_type == "fundamental_data":
            # åŸºæœ¬é¢æ•°æ®çš„ç¼ºå¤±å€¼å¤„ç†
            if "market_cap" not in data or data["market_cap"] is None:
                # å°è¯•è®¡ç®—å¸‚å€¼
                if "shares_outstanding" in data and "current_price" in data:
                    if data["shares_outstanding"] and data["current_price"]:
                        updated_data["market_cap"] = data["shares_outstanding"] * data["current_price"]
                        operations.append("Calculated market_cap from shares and price")
        
        return {
            "data": updated_data,
            "operations": operations
        }
    
    def _handle_outliers(self, data_type: str, data: Dict) -> Dict:
        """å¤„ç†å¼‚å¸¸å€¼"""
        
        operations = []
        updated_data = {}
        
        if data_type == "price_data":
            # æ£€æŸ¥ä»·æ ¼å¼‚å¸¸å€¼
            if "current_price" in data:
                price = data["current_price"]
                if isinstance(price, (int, float)):
                    # ä½¿ç”¨å†å²ä»·æ ¼èŒƒå›´æ£€æŸ¥å¼‚å¸¸å€¼
                    if self._is_price_outlier(price, data):
                        # ä½¿ç”¨å‰ä¸€äº¤æ˜“æ—¥æ”¶ç›˜ä»·æ›¿ä»£
                        if "previous_close" in data:
                            updated_data["current_price"] = data["previous_close"]
                            operations.append(f"Replaced outlier price {price} with previous_close")
        
        return {
            "data": updated_data,
            "operations": operations
        }
```

## 4. æ•°æ®è½¬æ¢å™¨

### æ•°æ®æ ‡å‡†åŒ–å’Œè½¬æ¢
```python
class DataTransformer:
    """æ•°æ®è½¬æ¢å™¨ - æ ‡å‡†åŒ–å’Œè½¬æ¢æ•°æ®æ ¼å¼"""
    
    def __init__(self):
        self.transformation_rules = self._load_transformation_rules()
        self.unit_converter = UnitConverter()
        
    def transform_data(self, cleaned_data: Dict) -> Dict:
        """è½¬æ¢æ•°æ®"""
        
        transformed_data = {}
        transformation_log = {}
        
        for data_type, data in cleaned_data["cleaned_data"].items():
            transformation_result = self._transform_data_type(data_type, data)
            transformed_data[data_type] = transformation_result["transformed_data"]
            transformation_log[data_type] = transformation_result["transformation_log"]
        
        return {
            "transformed_data": transformed_data,
            "transformation_log": transformation_log,
            "transformation_summary": self._generate_transformation_summary(transformation_log)
        }
    
    def _transform_data_type(self, data_type: str, data: Dict) -> Dict:
        """è½¬æ¢ç‰¹å®šç±»å‹çš„æ•°æ®"""
        
        transformed_data = {}
        transformations = []
        
        if data_type == "price_data":
            transformed_data = self._transform_price_data(data)
            transformations.append("Price data standardization")
            
        elif data_type == "fundamental_data":
            transformed_data = self._transform_fundamental_data(data)
            transformations.append("Fundamental data normalization")
            
        elif data_type == "news_data":
            transformed_data = self._transform_news_data(data)
            transformations.append("News data processing")
            
        elif data_type == "social_data":
            transformed_data = self._transform_social_data(data)
            transformations.append("Social data analysis")
        
        return {
            "transformed_data": transformed_data,
            "transformation_log": {
                "transformations": transformations,
                "data_schema": self._generate_data_schema(transformed_data)
            }
        }
    
    def _transform_price_data(self, data: Dict) -> Dict:
        """è½¬æ¢ä»·æ ¼æ•°æ®"""
        
        transformed = {
            "symbol": data.get("symbol"),
            "price": {
                "current": float(data.get("current_price", 0)),
                "open": float(data.get("open", 0)),
                "high": float(data.get("high", 0)),
                "low": float(data.get("low", 0)),
                "previous_close": float(data.get("previous_close", 0))
            },
            "change": {
                "absolute": float(data.get("change", 0)),
                "percentage": float(data.get("change_percent", 0))
            },
            "volume": int(data.get("volume", 0)),
            "timestamp": self._standardize_timestamp(data.get("timestamp"))
        }
        
        # è®¡ç®—é¢å¤–æŒ‡æ ‡
        if transformed["price"]["current"] and transformed["price"]["previous_close"]:
            transformed["metrics"] = {
                "daily_return": (transformed["price"]["current"] - transformed["price"]["previous_close"]) / transformed["price"]["previous_close"],
                "volatility_indicator": abs(transformed["price"]["high"] - transformed["price"]["low"]) / transformed["price"]["current"] if transformed["price"]["current"] else 0
            }
        
        return transformed
    
    def _transform_fundamental_data(self, data: Dict) -> Dict:
        """è½¬æ¢åŸºæœ¬é¢æ•°æ®"""
        
        transformed = {
            "company_info": {
                "symbol": data.get("symbol"),
                "name": data.get("name"),
                "sector": data.get("sector"),
                "industry": data.get("industry"),
                "market_cap": self._normalize_market_cap(data.get("market_cap"))
            },
            "valuation_metrics": {
                "pe_ratio": float(data.get("pe_ratio", 0)) if data.get("pe_ratio") else None,
                "pb_ratio": float(data.get("pb_ratio", 0)) if data.get("pb_ratio") else None,
                "ps_ratio": float(data.get("ps_ratio", 0)) if data.get("ps_ratio") else None,
                "ev_ebitda": float(data.get("ev_ebitda", 0)) if data.get("ev_ebitda") else None
            },
            "financial_health": {
                "debt_to_equity": float(data.get("debt_to_equity", 0)) if data.get("debt_to_equity") else None,
                "current_ratio": float(data.get("current_ratio", 0)) if data.get("current_ratio") else None,
                "roe": float(data.get("roe", 0)) if data.get("roe") else None,
                "roa": float(data.get("roa", 0)) if data.get("roa") else None
            },
            "growth_metrics": {
                "revenue_growth": float(data.get("revenue_growth", 0)) if data.get("revenue_growth") else None,
                "earnings_growth": float(data.get("earnings_growth", 0)) if data.get("earnings_growth") else None,
                "book_value_growth": float(data.get("book_value_growth", 0)) if data.get("book_value_growth") else None
            }
        }
        
        return transformed
```

## 5. ç‰¹å¾å·¥ç¨‹å™¨

### ç‰¹å¾æå–å’Œç”Ÿæˆ
```python
class FeatureEngineer:
    """ç‰¹å¾å·¥ç¨‹å™¨ - ç”Ÿæˆåˆ†æç‰¹å¾"""
    
    def __init__(self):
        self.feature_generators = self._initialize_feature_generators()
        
    def engineer_features(self, transformed_data: Dict) -> Dict:
        """å·¥ç¨‹åŒ–ç‰¹å¾"""
        
        features = {}
        
        # ä»·æ ¼ç‰¹å¾
        if "price_data" in transformed_data:
            features["price_features"] = self._generate_price_features(transformed_data["price_data"])
        
        # åŸºæœ¬é¢ç‰¹å¾
        if "fundamental_data" in transformed_data:
            features["fundamental_features"] = self._generate_fundamental_features(transformed_data["fundamental_data"])
        
        # æŠ€æœ¯ç‰¹å¾
        if "technical_data" in transformed_data:
            features["technical_features"] = self._generate_technical_features(transformed_data["technical_data"])
        
        # æƒ…æ„Ÿç‰¹å¾
        sentiment_data = {}
        if "news_data" in transformed_data:
            sentiment_data["news"] = transformed_data["news_data"]
        if "social_data" in transformed_data:
            sentiment_data["social"] = transformed_data["social_data"]
        
        if sentiment_data:
            features["sentiment_features"] = self._generate_sentiment_features(sentiment_data)
        
        # ç»¼åˆç‰¹å¾
        features["composite_features"] = self._generate_composite_features(features)
        
        return {
            "features": features,
            "feature_metadata": self._generate_feature_metadata(features)
        }
    
    def _generate_price_features(self, price_data: Dict) -> Dict:
        """ç”Ÿæˆä»·æ ¼ç‰¹å¾"""
        
        price_info = price_data.get("price", {})
        
        features = {
            "price_momentum": self._calculate_price_momentum(price_info),
            "price_volatility": self._calculate_price_volatility(price_info),
            "price_trend": self._identify_price_trend(price_info),
            "support_resistance": self._identify_support_resistance(price_info),
            "volume_profile": self._analyze_volume_profile(price_data.get("volume", 0))
        }
        
        return features
    
    def _generate_fundamental_features(self, fundamental_data: Dict) -> Dict:
        """ç”ŸæˆåŸºæœ¬é¢ç‰¹å¾"""
        
        valuation = fundamental_data.get("valuation_metrics", {})
        health = fundamental_data.get("financial_health", {})
        growth = fundamental_data.get("growth_metrics", {})
        
        features = {
            "valuation_score": self._calculate_valuation_score(valuation),
            "financial_strength": self._calculate_financial_strength(health),
            "growth_quality": self._assess_growth_quality(growth),
            "profitability_trend": self._analyze_profitability_trend(fundamental_data),
            "competitive_position": self._assess_competitive_position(fundamental_data)
        }
        
        return features
```

## 6. æ•°æ®åˆ†å‘å™¨

### æ™ºèƒ½æ•°æ®è·¯ç”±
```python
class DataDispatcher:
    """æ•°æ®åˆ†å‘å™¨ - å°†å¤„ç†åçš„æ•°æ®åˆ†å‘ç»™æ™ºèƒ½ä½“"""
    
    def __init__(self):
        self.routing_rules = self._load_routing_rules()
        self.agent_requirements = self._load_agent_requirements()
        
    def dispatch_data(self, engineered_data: Dict, target_agents: List[str]) -> Dict:
        """åˆ†å‘æ•°æ®ç»™ç›®æ ‡æ™ºèƒ½ä½“"""
        
        dispatched_data = {}
        
        for agent in target_agents:
            agent_data = self._prepare_agent_data(agent, engineered_data)
            dispatched_data[agent] = agent_data
        
        return {
            "agent_data": dispatched_data,
            "dispatch_metadata": {
                "target_agents": target_agents,
                "dispatch_timestamp": datetime.now().isoformat(),
                "data_completeness": self._assess_dispatch_completeness(dispatched_data)
            }
        }
    
    def _prepare_agent_data(self, agent: str, data: Dict) -> Dict:
        """ä¸ºç‰¹å®šæ™ºèƒ½ä½“å‡†å¤‡æ•°æ®"""
        
        agent_requirements = self.agent_requirements.get(agent, {})
        required_features = agent_requirements.get("required_features", [])
        
        agent_data = {}
        
        # æ ¹æ®æ™ºèƒ½ä½“éœ€æ±‚ç­›é€‰æ•°æ®
        for feature_category in required_features:
            if feature_category in data["features"]:
                agent_data[feature_category] = data["features"][feature_category]
        
        # æ·»åŠ æ™ºèƒ½ä½“ç‰¹å®šçš„æ•°æ®æ ¼å¼åŒ–
        formatted_data = self._format_for_agent(agent, agent_data)
        
        return {
            "data": formatted_data,
            "metadata": {
                "agent": agent,
                "data_version": data.get("feature_metadata", {}).get("version"),
                "completeness_score": self._calculate_completeness_score(agent_data, required_features)
            }
        }
```

é€šè¿‡è¿™ä¸ªå®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹ï¼ŒTradingAgents ç¡®ä¿æ™ºèƒ½ä½“è·å¾—é«˜è´¨é‡ã€æ ‡å‡†åŒ–ã€ç›¸å…³çš„æ•°æ®ï¼Œä¸ºå‡†ç¡®çš„åˆ†æå’Œå†³ç­–æä¾›åšå®åŸºç¡€ã€‚


<!-- docs/data/data-sources.md -->

# æ•°æ®æºé›†æˆ (v0.1.4)

## æ¦‚è¿°

TradingAgents ä¸­æ–‡å¢å¼ºç‰ˆé›†æˆäº†å¤šç§é‡‘èæ•°æ®æºï¼Œç‰¹åˆ«åŠ å¼ºäº†å¯¹ä¸­å›½Aè‚¡å¸‚åœºçš„æ”¯æŒã€‚ä¸ºæ™ºèƒ½ä½“æä¾›å…¨é¢ã€å‡†ç¡®ã€å®æ—¶çš„å¸‚åœºä¿¡æ¯ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†æ”¯æŒçš„æ•°æ®æºã€APIé›†æˆæ–¹æ³•ã€æ•°æ®æ ¼å¼å’Œä½¿ç”¨æŒ‡å—ã€‚

## ğŸ¯ v0.1.4 æ•°æ®æºçŠ¶æ€

| æ•°æ®æº | å¸‚åœº | çŠ¶æ€ | è¯´æ˜ |
|--------|------|------|------|
| ğŸ‡¨ğŸ‡³ **é€šè¾¾ä¿¡API** | Aè‚¡ | âœ… å®Œæ•´æ”¯æŒ | å®æ—¶è¡Œæƒ…ã€å†å²æ•°æ®ã€æŠ€æœ¯æŒ‡æ ‡ |
| **FinnHub** | ç¾è‚¡ | âœ… å®Œæ•´æ”¯æŒ | å®æ—¶æ•°æ®ã€åŸºæœ¬é¢ã€æ–°é—» |
| **Google News** | å…¨çƒ | âœ… å®Œæ•´æ”¯æŒ | è´¢ç»æ–°é—»ã€å¸‚åœºèµ„è®¯ |
| **Reddit** | å…¨çƒ | âœ… å®Œæ•´æ”¯æŒ | ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æ |
| **MongoDB** | ç¼“å­˜ | âœ… å®Œæ•´æ”¯æŒ | æ•°æ®æŒä¹…åŒ–å­˜å‚¨ |
| **Redis** | ç¼“å­˜ | âœ… å®Œæ•´æ”¯æŒ | é«˜é€Ÿæ•°æ®ç¼“å­˜ |

## æ”¯æŒçš„æ•°æ®æº

### ğŸ‡¨ğŸ‡³ 1. é€šè¾¾ä¿¡API (æ–°å¢ v0.1.3)

#### ç®€ä»‹
é€šè¾¾ä¿¡APIæ˜¯ä¸­å›½é¢†å…ˆçš„è‚¡ç¥¨æ•°æ®æä¾›å•†ï¼Œä¸ºAè‚¡å¸‚åœºæä¾›å®æ—¶è¡Œæƒ…å’Œå†å²æ•°æ®ã€‚

#### æ•°æ®ç±»å‹
```python
tdx_data_types = {
    "å®æ—¶æ•°æ®": [
        "Aè‚¡å®æ—¶è¡Œæƒ…",
        "æˆäº¤é‡",
        "æ¶¨è·Œå¹…",
        "æ¢æ‰‹ç‡"
    ],
    "å†å²æ•°æ®": [
        "æ—¥Kçº¿æ•°æ®",
        "åˆ†é’Ÿçº§æ•°æ®",
        "å¤æƒæ•°æ®",
        "é™¤æƒé™¤æ¯"
    ],
    "æŠ€æœ¯æŒ‡æ ‡": [
        "MAç§»åŠ¨å¹³å‡",
        "MACD",
        "RSI",
        "KDJ"
    ],
    "å¸‚åœºæ•°æ®": [
        "æ¿å—åˆ†ç±»",
        "æ¦‚å¿µè‚¡",
        "é¾™è™æ¦œ",
        "èµ„é‡‘æµå‘"
    ]
}
```

#### ä½¿ç”¨ç¤ºä¾‹
```python
from tradingagents.dataflows.tdx_utils import get_stock_data

# è·å–Aè‚¡æ•°æ®
data = get_stock_data(
    stock_code="000001",  # å¹³å®‰é“¶è¡Œ
    start_date="2024-01-01",
    end_date="2024-12-31"
)
```

### 1. FinnHub API

#### ç®€ä»‹
FinnHub æ˜¯é¢†å…ˆçš„é‡‘èæ•°æ®æä¾›å•†ï¼Œæä¾›å®æ—¶è‚¡ç¥¨ä»·æ ¼ã€å…¬å¸åŸºæœ¬é¢æ•°æ®ã€æ–°é—»å’Œå¸‚åœºæŒ‡æ ‡ã€‚

#### æ•°æ®ç±»å‹
```python
finnhub_data_types = {
    "å®æ—¶æ•°æ®": [
        "è‚¡ç¥¨ä»·æ ¼",
        "äº¤æ˜“é‡",
        "å¸‚åœºæ·±åº¦",
        "å®æ—¶æ–°é—»"
    ],
    "åŸºæœ¬é¢æ•°æ®": [
        "è´¢åŠ¡æŠ¥è¡¨",
        "å…¬å¸æ¦‚å†µ",
        "åˆ†æå¸ˆè¯„çº§",
        "ç›ˆåˆ©é¢„æµ‹"
    ],
    "æŠ€æœ¯æŒ‡æ ‡": [
        "RSI",
        "MACD",
        "å¸ƒæ—å¸¦",
        "ç§»åŠ¨å¹³å‡çº¿"
    ],
    "å¸‚åœºæ•°æ®": [
        "IPOæ—¥å†",
        "åˆ†çº¢ä¿¡æ¯",
        "è‚¡ç¥¨åˆ†å‰²",
        "æœŸæƒæ•°æ®"
    ]
}
```

#### API é…ç½®
```python
# finnhub_utils.py
import finnhub

class FinnHubDataProvider:
    """FinnHub æ•°æ®æä¾›å™¨"""
    
    def __init__(self, api_key: str):
        self.client = finnhub.Client(api_key=api_key)
        self.rate_limiter = RateLimiter(calls_per_minute=60)  # å…è´¹ç‰ˆé™åˆ¶
    
    def get_stock_price(self, symbol: str) -> Dict:
        """è·å–è‚¡ç¥¨ä»·æ ¼"""
        with self.rate_limiter:
            quote = self.client.quote(symbol)
            return {
                "symbol": symbol,
                "current_price": quote.get("c"),
                "change": quote.get("d"),
                "change_percent": quote.get("dp"),
                "high": quote.get("h"),
                "low": quote.get("l"),
                "open": quote.get("o"),
                "previous_close": quote.get("pc"),
                "timestamp": quote.get("t")
            }
    
    def get_company_profile(self, symbol: str) -> Dict:
        """è·å–å…¬å¸æ¦‚å†µ"""
        with self.rate_limiter:
            profile = self.client.company_profile2(symbol=symbol)
            return {
                "symbol": symbol,
                "name": profile.get("name"),
                "industry": profile.get("finnhubIndustry"),
                "sector": profile.get("gsubind"),
                "market_cap": profile.get("marketCapitalization"),
                "shares_outstanding": profile.get("shareOutstanding"),
                "website": profile.get("weburl"),
                "logo": profile.get("logo"),
                "exchange": profile.get("exchange")
            }
    
    def get_financial_statements(self, symbol: str, statement_type: str = "ic") -> Dict:
        """è·å–è´¢åŠ¡æŠ¥è¡¨"""
        with self.rate_limiter:
            financials = self.client.financials(symbol, statement_type, "annual")
            return {
                "symbol": symbol,
                "statement_type": statement_type,
                "data": financials.get("financials", []),
                "currency": financials.get("currency"),
                "last_updated": financials.get("cik")
            }
```

#### ä½¿ç”¨ç¤ºä¾‹
```python
# åˆå§‹åŒ– FinnHub å®¢æˆ·ç«¯
finnhub_provider = FinnHubDataProvider(api_key=os.getenv("FINNHUB_API_KEY"))

# è·å–è‚¡ç¥¨ä»·æ ¼
price_data = finnhub_provider.get_stock_price("AAPL")
print(f"AAPL å½“å‰ä»·æ ¼: ${price_data['current_price']}")

# è·å–å…¬å¸ä¿¡æ¯
company_info = finnhub_provider.get_company_profile("AAPL")
print(f"å…¬å¸åç§°: {company_info['name']}")
```

### 2. Yahoo Finance

#### ç®€ä»‹
Yahoo Finance æä¾›å…è´¹çš„å†å²è‚¡ç¥¨æ•°æ®ã€è´¢åŠ¡ä¿¡æ¯å’Œå¸‚åœºæŒ‡æ ‡ï¼Œæ˜¯è·å–å†å²æ•°æ®çš„ä¼˜ç§€é€‰æ‹©ã€‚

#### æ•°æ®ç±»å‹
```python
yahoo_finance_data_types = {
    "å†å²æ•°æ®": [
        "è‚¡ç¥¨ä»·æ ¼å†å²",
        "äº¤æ˜“é‡å†å²",
        "è°ƒæ•´åä»·æ ¼",
        "è‚¡æ¯å†å²"
    ],
    "è´¢åŠ¡æ•°æ®": [
        "æŸç›Šè¡¨",
        "èµ„äº§è´Ÿå€ºè¡¨",
        "ç°é‡‘æµé‡è¡¨",
        "å…³é”®æŒ‡æ ‡"
    ],
    "å¸‚åœºæ•°æ®": [
        "æœŸæƒé“¾",
        "åˆ†æå¸ˆå»ºè®®",
        "æœºæ„æŒè‚¡",
        "å†…éƒ¨äººäº¤æ˜“"
    ]
}
```

#### API é›†æˆ
```python
# yfin_utils.py
import yfinance as yf
import pandas as pd

class YahooFinanceProvider:
    """Yahoo Finance æ•°æ®æä¾›å™¨"""
    
    def __init__(self):
        self.cache = {}
        self.cache_duration = 300  # 5åˆ†é’Ÿç¼“å­˜
    
    def get_historical_data(self, symbol: str, period: str = "1y") -> pd.DataFrame:
        """è·å–å†å²æ•°æ®"""
        cache_key = f"{symbol}_{period}"
        
        if self._is_cache_valid(cache_key):
            return self.cache[cache_key]["data"]
        
        ticker = yf.Ticker(symbol)
        hist_data = ticker.history(period=period)
        
        # ç¼“å­˜æ•°æ®
        self.cache[cache_key] = {
            "data": hist_data,
            "timestamp": time.time()
        }
        
        return hist_data
    
    def get_financial_info(self, symbol: str) -> Dict:
        """è·å–è´¢åŠ¡ä¿¡æ¯"""
        ticker = yf.Ticker(symbol)
        info = ticker.info
        
        return {
            "symbol": symbol,
            "market_cap": info.get("marketCap"),
            "enterprise_value": info.get("enterpriseValue"),
            "pe_ratio": info.get("trailingPE"),
            "pb_ratio": info.get("priceToBook"),
            "debt_to_equity": info.get("debtToEquity"),
            "roe": info.get("returnOnEquity"),
            "revenue_growth": info.get("revenueGrowth"),
            "profit_margins": info.get("profitMargins"),
            "beta": info.get("beta")
        }
    
    def get_technical_indicators(self, symbol: str, period: str = "1y") -> Dict:
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        hist_data = self.get_historical_data(symbol, period)
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
        hist_data["MA_20"] = hist_data["Close"].rolling(window=20).mean()
        hist_data["MA_50"] = hist_data["Close"].rolling(window=50).mean()
        
        # è®¡ç®— RSI
        hist_data["RSI"] = self._calculate_rsi(hist_data["Close"])
        
        # è®¡ç®— MACD
        macd_data = self._calculate_macd(hist_data["Close"])
        hist_data = pd.concat([hist_data, macd_data], axis=1)
        
        return {
            "symbol": symbol,
            "indicators": hist_data.tail(1).to_dict("records")[0],
            "trend_analysis": self._analyze_trend(hist_data),
            "support_resistance": self._find_support_resistance(hist_data)
        }
```

### 3. Reddit API

#### ç®€ä»‹
Reddit API æä¾›ç¤¾äº¤åª’ä½“è®¨è®ºæ•°æ®ï¼Œç”¨äºåˆ†ææŠ•èµ„è€…æƒ…ç»ªå’Œå¸‚åœºçƒ­ç‚¹ã€‚

#### æ•°æ®ç±»å‹
```python
reddit_data_types = {
    "è®¨è®ºæ•°æ®": [
        "çƒ­é—¨å¸–å­",
        "è¯„è®ºå†…å®¹",
        "ç”¨æˆ·äº’åŠ¨",
        "è¯é¢˜è¶‹åŠ¿"
    ],
    "æƒ…æ„Ÿæ•°æ®": [
        "æƒ…æ„Ÿææ€§",
        "æƒ…æ„Ÿå¼ºåº¦",
        "æƒ…æ„Ÿåˆ†å¸ƒ",
        "æƒ…æ„Ÿå˜åŒ–"
    ],
    "çƒ­åº¦æŒ‡æ ‡": [
        "æåŠé¢‘ç‡",
        "è®¨è®ºçƒ­åº¦",
        "ç”¨æˆ·å‚ä¸åº¦",
        "ä¼ æ’­é€Ÿåº¦"
    ]
}
```

#### API é›†æˆ
```python
# reddit_utils.py
import praw
from textblob import TextBlob

class RedditDataProvider:
    """Reddit æ•°æ®æä¾›å™¨"""
    
    def __init__(self, client_id: str, client_secret: str, user_agent: str):
        self.reddit = praw.Reddit(
            client_id=client_id,
            client_secret=client_secret,
            user_agent=user_agent
        )
        self.sentiment_analyzer = SentimentAnalyzer()
    
    def get_stock_discussions(self, symbol: str, subreddit: str = "stocks", limit: int = 100) -> List[Dict]:
        """è·å–è‚¡ç¥¨è®¨è®º"""
        discussions = []
        
        # æœç´¢ç›¸å…³å¸–å­
        for submission in self.reddit.subreddit(subreddit).search(symbol, limit=limit):
            # åˆ†ææƒ…æ„Ÿ
            sentiment = self.sentiment_analyzer.analyze(submission.title + " " + submission.selftext)
            
            discussions.append({
                "id": submission.id,
                "title": submission.title,
                "content": submission.selftext,
                "score": submission.score,
                "num_comments": submission.num_comments,
                "created_utc": submission.created_utc,
                "author": str(submission.author),
                "url": submission.url,
                "sentiment": sentiment
            })
        
        return discussions
    
    def analyze_sentiment_trends(self, discussions: List[Dict]) -> Dict:
        """åˆ†ææƒ…æ„Ÿè¶‹åŠ¿"""
        if not discussions:
            return {"error": "No discussions found"}
        
        # è®¡ç®—æ•´ä½“æƒ…æ„Ÿ
        sentiments = [d["sentiment"]["polarity"] for d in discussions]
        avg_sentiment = sum(sentiments) / len(sentiments)
        
        # æ—¶é—´åºåˆ—åˆ†æ
        time_series = self._create_sentiment_time_series(discussions)
        
        # çƒ­åº¦åˆ†æ
        engagement_metrics = self._calculate_engagement_metrics(discussions)
        
        return {
            "overall_sentiment": avg_sentiment,
            "sentiment_distribution": self._calculate_sentiment_distribution(sentiments),
            "time_series": time_series,
            "engagement_metrics": engagement_metrics,
            "trending_topics": self._extract_trending_topics(discussions)
        }
```

### 4. Google News

#### ç®€ä»‹
Google News API æä¾›å®æ—¶æ–°é—»æ•°æ®ï¼Œç”¨äºåˆ†æå¸‚åœºäº‹ä»¶å’Œæ–°é—»å¯¹è‚¡ä»·çš„å½±å“ã€‚

#### æ•°æ®ç±»å‹
```python
google_news_data_types = {
    "æ–°é—»å†…å®¹": [
        "æ–°é—»æ ‡é¢˜",
        "æ–°é—»æ­£æ–‡",
        "å‘å¸ƒæ—¶é—´",
        "æ–°é—»æ¥æº"
    ],
    "å½±å“åˆ†æ": [
        "æ–°é—»æƒ…æ„Ÿ",
        "å½±å“ç¨‹åº¦",
        "ç›¸å…³æ€§è¯„åˆ†",
        "æ—¶æ•ˆæ€§åˆ†æ"
    ],
    "äº‹ä»¶è¿½è¸ª": [
        "äº‹ä»¶æ—¶é—´çº¿",
        "å…³è”äº‹ä»¶",
        "å½±å“èŒƒå›´",
        "åç»­å‘å±•"
    ]
}
```

#### API é›†æˆ
```python
# googlenews_utils.py
from GoogleNews import GoogleNews
import requests
from bs4 import BeautifulSoup

class GoogleNewsProvider:
    """Google News æ•°æ®æä¾›å™¨"""
    
    def __init__(self):
        self.googlenews = GoogleNews()
        self.sentiment_analyzer = SentimentAnalyzer()
    
    def get_stock_news(self, symbol: str, days: int = 7) -> List[Dict]:
        """è·å–è‚¡ç¥¨ç›¸å…³æ–°é—»"""
        # è®¾ç½®æœç´¢å‚æ•°
        self.googlenews.clear()
        self.googlenews.set_time_range(f"{days}d")
        self.googlenews.set_lang("en")
        
        # æœç´¢æ–°é—»
        search_terms = [symbol, f"{symbol} stock", f"{symbol} earnings"]
        all_news = []
        
        for term in search_terms:
            self.googlenews.search(term)
            news_results = self.googlenews.results()
            
            for news in news_results:
                # è·å–æ–°é—»è¯¦æƒ…
                news_detail = self._get_news_detail(news)
                if news_detail:
                    all_news.append(news_detail)
        
        # å»é‡å’Œæ’åº
        unique_news = self._deduplicate_news(all_news)
        return sorted(unique_news, key=lambda x: x["published_date"], reverse=True)
    
    def _get_news_detail(self, news_item: Dict) -> Dict:
        """è·å–æ–°é—»è¯¦æƒ…"""
        try:
            # åˆ†ææ–°é—»æƒ…æ„Ÿ
            sentiment = self.sentiment_analyzer.analyze(news_item.get("title", ""))
            
            # è¯„ä¼°æ–°é—»é‡è¦æ€§
            importance = self._assess_news_importance(news_item)
            
            return {
                "title": news_item.get("title"),
                "link": news_item.get("link"),
                "published_date": news_item.get("date"),
                "source": news_item.get("media"),
                "sentiment": sentiment,
                "importance": importance,
                "relevance_score": self._calculate_relevance_score(news_item)
            }
        except Exception as e:
            print(f"Error processing news item: {e}")
            return None
    
    def analyze_news_impact(self, news_list: List[Dict], symbol: str) -> Dict:
        """åˆ†ææ–°é—»å½±å“"""
        if not news_list:
            return {"error": "No news found"}
        
        # æƒ…æ„Ÿåˆ†æ
        sentiment_analysis = self._analyze_news_sentiment(news_list)
        
        # å½±å“è¯„ä¼°
        impact_assessment = self._assess_news_impact(news_list, symbol)
        
        # æ—¶é—´çº¿åˆ†æ
        timeline_analysis = self._create_news_timeline(news_list)
        
        return {
            "sentiment_analysis": sentiment_analysis,
            "impact_assessment": impact_assessment,
            "timeline_analysis": timeline_analysis,
            "key_events": self._identify_key_events(news_list),
            "market_implications": self._analyze_market_implications(news_list, symbol)
        }
```

## æ•°æ®é›†æˆæ¥å£

### ç»Ÿä¸€æ•°æ®æ¥å£
```python
# interface.py
class DataInterface:
    """ç»Ÿä¸€æ•°æ®æ¥å£"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.providers = self._initialize_providers()
        self.cache_manager = CacheManager()
        
    def _initialize_providers(self) -> Dict:
        """åˆå§‹åŒ–æ•°æ®æä¾›å™¨"""
        providers = {}
        
        # FinnHub
        if self.config.get("finnhub_api_key"):
            providers["finnhub"] = FinnHubDataProvider(self.config["finnhub_api_key"])
        
        # Yahoo Finance
        providers["yahoo"] = YahooFinanceProvider()
        
        # Reddit
        if self.config.get("reddit_credentials"):
            providers["reddit"] = RedditDataProvider(**self.config["reddit_credentials"])
        
        # Google News
        providers["google_news"] = GoogleNewsProvider()
        
        return providers
    
    def get_comprehensive_data(self, symbol: str, date: str = None) -> Dict:
        """è·å–ç»¼åˆæ•°æ®"""
        data = {}
        
        # å¹¶è¡Œè·å–æ•°æ®
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = {
                executor.submit(self._get_price_data, symbol): "price_data",
                executor.submit(self._get_fundamental_data, symbol): "fundamental_data",
                executor.submit(self._get_news_data, symbol): "news_data",
                executor.submit(self._get_social_data, symbol): "social_data"
            }
            
            for future in as_completed(futures):
                data_type = futures[future]
                try:
                    data[data_type] = future.result()
                except Exception as e:
                    print(f"Error fetching {data_type}: {e}")
                    data[data_type] = {}
        
        return data
    
    def _get_price_data(self, symbol: str) -> Dict:
        """è·å–ä»·æ ¼æ•°æ®"""
        # ä¼˜å…ˆä½¿ç”¨ FinnHubï¼Œå¤‡ç”¨ Yahoo Finance
        if "finnhub" in self.providers:
            try:
                return self.providers["finnhub"].get_stock_price(symbol)
            except Exception:
                pass
        
        if "yahoo" in self.providers:
            hist_data = self.providers["yahoo"].get_historical_data(symbol, "5d")
            latest = hist_data.iloc[-1]
            return {
                "symbol": symbol,
                "current_price": latest["Close"],
                "change": latest["Close"] - latest["Open"],
                "high": latest["High"],
                "low": latest["Low"],
                "volume": latest["Volume"]
            }
        
        return {}
```

## æ•°æ®è´¨é‡æ§åˆ¶

### æ•°æ®éªŒè¯
```python
class DataValidator:
    """æ•°æ®éªŒè¯å™¨"""
    
    def validate_data(self, data: Dict, data_type: str) -> Tuple[bool, List[str]]:
        """éªŒè¯æ•°æ®è´¨é‡"""
        errors = []
        
        # åŸºæœ¬å®Œæ•´æ€§æ£€æŸ¥
        if not data:
            errors.append("Data is empty")
            return False, errors
        
        # ç‰¹å®šç±»å‹éªŒè¯
        if data_type == "price_data":
            errors.extend(self._validate_price_data(data))
        elif data_type == "fundamental_data":
            errors.extend(self._validate_fundamental_data(data))
        elif data_type == "news_data":
            errors.extend(self._validate_news_data(data))
        elif data_type == "social_data":
            errors.extend(self._validate_social_data(data))
        
        return len(errors) == 0, errors
    
    def _validate_price_data(self, data: Dict) -> List[str]:
        """éªŒè¯ä»·æ ¼æ•°æ®"""
        errors = []
        
        required_fields = ["symbol", "current_price"]
        for field in required_fields:
            if field not in data:
                errors.append(f"Missing required field: {field}")
        
        # ä»·æ ¼åˆç†æ€§æ£€æŸ¥
        if "current_price" in data:
            price = data["current_price"]
            if not isinstance(price, (int, float)) or price <= 0:
                errors.append("Invalid price value")
        
        return errors
```

## ä½¿ç”¨æœ€ä½³å®è·µ

### 1. API é™åˆ¶ç®¡ç†
```python
class RateLimiter:
    """API é™åˆ¶ç®¡ç†å™¨"""
    
    def __init__(self, calls_per_minute: int):
        self.calls_per_minute = calls_per_minute
        self.calls = []
    
    def __enter__(self):
        current_time = time.time()
        
        # æ¸…ç†è¿‡æœŸçš„è°ƒç”¨è®°å½•
        self.calls = [call_time for call_time in self.calls if current_time - call_time < 60]
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if len(self.calls) >= self.calls_per_minute:
            sleep_time = 60 - (current_time - self.calls[0])
            if sleep_time > 0:
                time.sleep(sleep_time)
        
        self.calls.append(current_time)
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        pass
```

### 2. é”™è¯¯å¤„ç†å’Œé‡è¯•
```python
def with_retry(max_retries: int = 3, delay: float = 1.0):
    """é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    time.sleep(delay * (2 ** attempt))  # æŒ‡æ•°é€€é¿
            return None
        return wrapper
    return decorator
```

### 3. æ•°æ®ç¼“å­˜ç­–ç•¥
```python
class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.cache = {}
        self.cache_ttl = {
            "price_data": 60,      # 1åˆ†é’Ÿ
            "fundamental_data": 3600,  # 1å°æ—¶
            "news_data": 1800,     # 30åˆ†é’Ÿ
            "social_data": 900     # 15åˆ†é’Ÿ
        }
    
    def get(self, key: str, data_type: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜æ•°æ®"""
        if key in self.cache:
            cached_item = self.cache[key]
            ttl = self.cache_ttl.get(data_type, 3600)
            
            if time.time() - cached_item["timestamp"] < ttl:
                return cached_item["data"]
            else:
                del self.cache[key]
        
        return None
    
    def set(self, key: str, data: Dict, data_type: str):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        self.cache[key] = {
            "data": data,
            "timestamp": time.time(),
            "type": data_type
        }
```

é€šè¿‡è¿™äº›æ•°æ®æºçš„é›†æˆï¼ŒTradingAgents èƒ½å¤Ÿè·å¾—å…¨é¢ã€å®æ—¶ã€é«˜è´¨é‡çš„å¸‚åœºæ•°æ®ï¼Œä¸ºæ™ºèƒ½ä½“çš„åˆ†æå’Œå†³ç­–æä¾›åšå®çš„æ•°æ®åŸºç¡€ã€‚


<!-- docs/data/tongdaxin-api-integration.md -->

# é€šè¾¾ä¿¡APIé›†æˆæŒ‡å—

## ğŸ¯ æ¦‚è¿°

é€šè¾¾ä¿¡APIä¸ºTradingAgents-CNæä¾›äº†é«˜è´¨é‡çš„ä¸­å›½è‚¡ç¥¨æ•°æ®ï¼ŒåŒ…æ‹¬Aè‚¡ã€æ·±è‚¡ã€åˆ›ä¸šæ¿ã€ç§‘åˆ›æ¿ç­‰æ‰€æœ‰æ¿å—çš„å®æ—¶è¡Œæƒ…å’Œå†å²æ•°æ®ã€‚

## ğŸŒŸ ä¼˜åŠ¿å¯¹æ¯”

### ğŸ“Š æ•°æ®è¦†ç›–å¯¹æ¯”

| æ•°æ®ç±»å‹ | é€šè¾¾ä¿¡API | Yahoo Finance | ä¼˜åŠ¿ |
|----------|-----------|---------------|------|
| **Aè‚¡å®æ—¶æ•°æ®** | âœ… å®Œæ•´è¦†ç›– | âŒ ä¸æ”¯æŒ | ğŸŸ¢ ç‹¬æœ‰ä¼˜åŠ¿ |
| **æ¸¯è‚¡æ•°æ®** | âœ… å®æ—¶æ•°æ® | âš ï¸ éƒ¨åˆ†æ”¯æŒ | ğŸŸ¢ æ›´å…¨é¢ |
| **æ•°æ®å®æ—¶æ€§** | âœ… ç§’çº§æ›´æ–° | âš ï¸ 15åˆ†é’Ÿå»¶è¿Ÿ | ğŸŸ¢ å®æ—¶æ€§å¼º |
| **æŠ€æœ¯æŒ‡æ ‡** | âœ… ä¸°å¯ŒæŒ‡æ ‡ | âœ… åŸºç¡€æŒ‡æ ‡ | ğŸŸ¡ ç›¸å½“ |
| **å†å²æ•°æ®** | âœ… å®Œæ•´å†å² | âœ… å®Œæ•´å†å² | ğŸŸ¡ ç›¸å½“ |
| **ä¸­æ–‡æ”¯æŒ** | âœ… åŸç”Ÿæ”¯æŒ | âŒ ä¸æ”¯æŒ | ğŸŸ¢ æœ¬åœŸåŒ– |

### ğŸ‡¨ğŸ‡³ æœ¬åœŸåŒ–ä¼˜åŠ¿

- **æ•°æ®æºæƒå¨**: ç›´æ¥å¯¹æ¥äº¤æ˜“æ‰€æ•°æ®
- **æ›´æ–°åŠæ—¶**: å®æ—¶è¡Œæƒ…ï¼Œæ— å»¶è¿Ÿ
- **ä¸­æ–‡æ”¯æŒ**: è‚¡ç¥¨åç§°ã€æ¿å—åˆ†ç±»ç­‰
- **æœ¬åœŸç‰¹è‰²**: æ¶¨è·Œåœã€STè‚¡ç¥¨ç­‰ç‰¹æ®Šæ ‡è®°
- **å…è´¹ä½¿ç”¨**: æ— éœ€APIå¯†é’¥ï¼Œå…è´¹è·å–æ•°æ®

## ğŸ”§ å®‰è£…å’Œé…ç½®

### 1. å®‰è£…ä¾èµ–

```bash
# æ–¹æ³•1: ä½¿ç”¨å®‰è£…è„šæœ¬
python install_tdx.py

# æ–¹æ³•2: æ‰‹åŠ¨å®‰è£…
pip install pytdx
```

### 2. éªŒè¯å®‰è£…

```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬
python test_tdx_integration.py
```

### 3. æ— éœ€é¢å¤–é…ç½®

é€šè¾¾ä¿¡APIä½¿ç”¨å…è´¹çš„å…¬å…±æœåŠ¡å™¨ï¼Œæ— éœ€ç”³è¯·APIå¯†é’¥æˆ–è¿›è¡Œé¢å¤–é…ç½®ã€‚

## ğŸ“Š æ”¯æŒçš„æ•°æ®ç±»å‹

### 1. å®æ—¶è¡Œæƒ…æ•°æ®

```python
# è·å–å®æ—¶æ•°æ®
realtime_data = {
    'code': '000001',
    'name': 'å¹³å®‰é“¶è¡Œ',
    'price': 12.34,
    'change_percent': 2.15,
    'volume': 1234567,
    'amount': 15234567.89,
    'bid_prices': [12.33, 12.32, 12.31, 12.30, 12.29],
    'ask_prices': [12.34, 12.35, 12.36, 12.37, 12.38],
    'update_time': '2024-01-01 15:00:00'
}
```

### 2. å†å²Kçº¿æ•°æ®

```python
# æ”¯æŒçš„å‘¨æœŸ
periods = {
    'D': 'æ—¥çº¿',
    'W': 'å‘¨çº¿', 
    'M': 'æœˆçº¿'
}

# æ•°æ®æ ¼å¼ (å…¼å®¹Yahoo Finance)
columns = ['Open', 'High', 'Low', 'Close', 'Volume', 'Amount']
```

### 3. æŠ€æœ¯æŒ‡æ ‡

```python
# æ”¯æŒçš„æŠ€æœ¯æŒ‡æ ‡
indicators = {
    'MA5': '5æ—¥ç§»åŠ¨å¹³å‡',
    'MA10': '10æ—¥ç§»åŠ¨å¹³å‡',
    'MA20': '20æ—¥ç§»åŠ¨å¹³å‡',
    'RSI': 'ç›¸å¯¹å¼ºå¼±æŒ‡æ•°',
    'MACD': 'MACDæŒ‡æ ‡',
    'BB_Upper': 'å¸ƒæ—å¸¦ä¸Šè½¨',
    'BB_Lower': 'å¸ƒæ—å¸¦ä¸‹è½¨'
}
```

### 4. å¸‚åœºæ¦‚è§ˆ

```python
# ä¸»è¦æŒ‡æ•°
indices = {
    'ä¸Šè¯æŒ‡æ•°': '000001',
    'æ·±è¯æˆæŒ‡': '399001', 
    'åˆ›ä¸šæ¿æŒ‡': '399006',
    'ç§‘åˆ›50': '000688'
}
```

## ğŸ¯ ä½¿ç”¨æ–¹æ³•

### 1. Webç•Œé¢ä½¿ç”¨

1. **å¯åŠ¨Webç•Œé¢**:
   ```bash
   python -m streamlit run web/app.py
   ```

2. **é€‰æ‹©Aè‚¡å¸‚åœº**:
   - åœ¨"é€‰æ‹©å¸‚åœº"ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹©"Aè‚¡"

3. **è¾“å…¥è‚¡ç¥¨ä»£ç **:
   ```
   000001  # å¹³å®‰é“¶è¡Œ
   600519  # è´µå·èŒ…å°
   000858  # äº”ç²®æ¶²
   300750  # å®å¾·æ—¶ä»£
   ```

4. **å¼€å§‹åˆ†æ**:
   - ç³»ç»Ÿå°†è‡ªåŠ¨ä½¿ç”¨é€šè¾¾ä¿¡APIè·å–å®æ—¶æ•°æ®

### 2. ç¼–ç¨‹æ¥å£ä½¿ç”¨

```python
from tradingagents.dataflows.tdx_utils import get_china_stock_data, get_china_market_overview

# è·å–è‚¡ç¥¨æ•°æ®
stock_data = get_china_stock_data('000001', '2024-01-01', '2024-01-31')
print(stock_data)

# è·å–å¸‚åœºæ¦‚è§ˆ
market_overview = get_china_market_overview()
print(market_overview)
```

### 3. åœ¨åˆ†æå¸ˆä¸­ä½¿ç”¨

```python
# æ–°å¢çš„å·¥å…·å‡½æ•°
toolkit.get_china_stock_data('000001', '2024-01-01', '2024-01-31')
toolkit.get_china_market_overview('2024-01-31')
```

## ğŸ“ˆ æ”¯æŒçš„è‚¡ç¥¨ä»£ç æ ¼å¼

### Aè‚¡ä»£ç è§„åˆ™

| ä»£ç å‰ç¼€ | å¸‚åœº | ç¤ºä¾‹ | è¯´æ˜ |
|----------|------|------|------|
| **000xxx** | æ·±åœ³ä¸»æ¿ | 000001 | å¹³å®‰é“¶è¡Œ |
| **002xxx** | æ·±åœ³ä¸­å°æ¿ | 002415 | æµ·åº·å¨è§† |
| **003xxx** | æ·±åœ³ä¸»æ¿ | 003816 | ä¸­å›½å¹¿æ ¸ |
| **300xxx** | åˆ›ä¸šæ¿ | 300750 | å®å¾·æ—¶ä»£ |
| **600xxx** | ä¸Šæµ·ä¸»æ¿ | 600519 | è´µå·èŒ…å° |
| **601xxx** | ä¸Šæµ·ä¸»æ¿ | 601318 | ä¸­å›½å¹³å®‰ |
| **603xxx** | ä¸Šæµ·ä¸»æ¿ | 603259 | è¯æ˜åº·å¾· |
| **688xxx** | ç§‘åˆ›æ¿ | 688981 | ä¸­èŠ¯å›½é™… |

### å¸¸ç”¨è‚¡ç¥¨ä»£ç 

```python
popular_stocks = {
    # é“¶è¡Œè‚¡
    '000001': 'å¹³å®‰é“¶è¡Œ',
    '600036': 'æ‹›å•†é“¶è¡Œ',
    '601398': 'å·¥å•†é“¶è¡Œ',
    
    # ç™½é…’è‚¡
    '600519': 'è´µå·èŒ…å°',
    '000858': 'äº”ç²®æ¶²',
    '000568': 'æ³¸å·è€çª–',
    
    # ç§‘æŠ€è‚¡
    '000002': 'ä¸‡ç§‘A',
    '000651': 'æ ¼åŠ›ç”µå™¨',
    '300750': 'å®å¾·æ—¶ä»£',
    
    # æ–°èƒ½æº
    '002594': 'æ¯”äºšè¿ª',
    '300274': 'é˜³å…‰ç”µæº'
}
```

## ğŸ” æŠ€æœ¯å®ç°ç»†èŠ‚

### 1. è¿æ¥æœºåˆ¶

```python
# ä½¿ç”¨å…è´¹çš„é€šè¾¾ä¿¡æœåŠ¡å™¨
servers = [
    ('119.147.212.81', 7709),  # ä¸»æœåŠ¡å™¨
    ('119.147.212.81', 7721)   # æ‰©å±•æœåŠ¡å™¨
]
```

### 2. æ•°æ®è·å–æµç¨‹

```mermaid
graph TD
    A[ç”¨æˆ·è¾“å…¥è‚¡ç¥¨ä»£ç ] --> B[è¿æ¥é€šè¾¾ä¿¡æœåŠ¡å™¨]
    B --> C[è·å–å®æ—¶æ•°æ®]
    B --> D[è·å–å†å²æ•°æ®]
    B --> E[è®¡ç®—æŠ€æœ¯æŒ‡æ ‡]
    C --> F[æ ¼å¼åŒ–æ•°æ®]
    D --> F
    E --> F
    F --> G[è¿”å›åˆ†ææŠ¥å‘Š]
```

### 3. é”™è¯¯å¤„ç†

```python
# è‡ªåŠ¨é‡è¿æœºåˆ¶
if not connected:
    success = connect()
    if not success:
        return fallback_data

# æ•°æ®éªŒè¯
if not data or len(data) == 0:
    return empty_result_with_message
```

## ğŸš¨ æ³¨æ„äº‹é¡¹

### 1. ç½‘ç»œè¦æ±‚

- **éœ€è¦ç½‘ç»œè¿æ¥**: é€šè¾¾ä¿¡APIéœ€è¦è¿æ¥åˆ°é€šè¾¾ä¿¡æœåŠ¡å™¨
- **æœåŠ¡å™¨ç¨³å®šæ€§**: ä¾èµ–é€šè¾¾ä¿¡å…è´¹æœåŠ¡å™¨çš„å¯ç”¨æ€§
- **è¿æ¥è¶…æ—¶**: ç½‘ç»œä¸ç¨³å®šæ—¶å¯èƒ½å‡ºç°è¿æ¥è¶…æ—¶

### 2. æ•°æ®é™åˆ¶

- **å†å²æ•°æ®**: å•æ¬¡æœ€å¤šè·å–800æ¡Kçº¿æ•°æ®
- **å®æ—¶æ•°æ®**: äº¤æ˜“æ—¶é—´å†…æ•°æ®æ›´æ–°é¢‘ç‡æœ€é«˜
- **æŠ€æœ¯æŒ‡æ ‡**: éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®è¿›è¡Œè®¡ç®—

### 3. ä½¿ç”¨å»ºè®®

- **å¤‡ç”¨æ–¹æ¡ˆ**: å»ºè®®åŒæ—¶é…ç½®Yahoo Financeä½œä¸ºå¤‡ç”¨æ•°æ®æº
- **æ•°æ®éªŒè¯**: é‡è¦å†³ç­–å‰å»ºè®®äº¤å‰éªŒè¯æ•°æ®
- **äº¤æ˜“æ—¶é—´**: éäº¤æ˜“æ—¶é—´è·å–çš„æ˜¯æœ€åäº¤æ˜“æ—¥æ•°æ®

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. è¿æ¥å¤±è´¥

```bash
âŒ é€šè¾¾ä¿¡APIè¿æ¥å¤±è´¥: [Errno 11001] getaddrinfo failed
```

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- å°è¯•é‡æ–°è¿è¡Œç¨‹åº
- æ£€æŸ¥é˜²ç«å¢™è®¾ç½®

#### 2. æ•°æ®è·å–å¤±è´¥

```bash
âš ï¸ æœªè·å–åˆ°è‚¡ç¥¨æ•°æ®
```

**è§£å†³æ–¹æ¡ˆ**:
- ç¡®è®¤è‚¡ç¥¨ä»£ç æ ¼å¼æ­£ç¡®
- æ£€æŸ¥è‚¡ç¥¨æ˜¯å¦å­˜åœ¨
- å°è¯•å…¶ä»–è‚¡ç¥¨ä»£ç 

#### 3. pytdxå®‰è£…å¤±è´¥

```bash
âŒ pytdxåº“å®‰è£…å¤±è´¥
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å‡çº§pip
python -m pip install --upgrade pip

# é‡æ–°å®‰è£…
pip install pytdx --no-cache-dir

# æˆ–ä½¿ç”¨å›½å†…é•œåƒ
pip install pytdx -i https://pypi.tuna.tsinghua.edu.cn/simple/
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ€§èƒ½ä¼˜åŒ–

```python
# å¤ç”¨è¿æ¥
provider = get_tdx_provider()  # å…¨å±€å®ä¾‹

# æ‰¹é‡è·å–æ•°æ®
stocks = ['000001', '600519', '000858']
for stock in stocks:
    data = provider.get_real_time_data(stock)
```

### 2. é”™è¯¯å¤„ç†

```python
try:
    data = get_china_stock_data(stock_code, start_date, end_date)
    if "è·å–å¤±è´¥" in data:
        # ä½¿ç”¨å¤‡ç”¨æ•°æ®æº
        fallback_data = get_yahoo_finance_data(stock_code)
except Exception as e:
    # è®°å½•é”™è¯¯å¹¶æä¾›ç”¨æˆ·å‹å¥½çš„æ¶ˆæ¯
    logger.error(f"æ•°æ®è·å–å¤±è´¥: {e}")
    return "æ•°æ®æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
```

### 3. æ•°æ®ç¼“å­˜

```python
# å®ç°ç®€å•çš„æ•°æ®ç¼“å­˜
cache = {}
cache_key = f"{stock_code}_{date}"

if cache_key in cache:
    return cache[cache_key]
else:
    data = fetch_data(stock_code, date)
    cache[cache_key] = data
    return data
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### æ•°æ®è·å–é€Ÿåº¦

| æ“ä½œ | å¹³å‡è€—æ—¶ | è¯´æ˜ |
|------|----------|------|
| **è¿æ¥æœåŠ¡å™¨** | 1-3ç§’ | é¦–æ¬¡è¿æ¥ |
| **å®æ—¶æ•°æ®** | 0.5-1ç§’ | å•åªè‚¡ç¥¨ |
| **å†å²æ•°æ®** | 2-5ç§’ | 30å¤©æ•°æ® |
| **æŠ€æœ¯æŒ‡æ ‡** | 1-2ç§’ | åŸºç¡€æŒ‡æ ‡ |
| **å¸‚åœºæ¦‚è§ˆ** | 3-5ç§’ | ä¸»è¦æŒ‡æ•° |

### æ•°æ®å‡†ç¡®æ€§

- **å®æ—¶æ•°æ®**: ä¸äº¤æ˜“æ‰€æ•°æ®ä¸€è‡´
- **å†å²æ•°æ®**: å¤æƒå¤„ç†å‡†ç¡®
- **æŠ€æœ¯æŒ‡æ ‡**: è®¡ç®—æ–¹æ³•æ ‡å‡†
- **ä¸­æ–‡åç§°**: å®˜æ–¹æ ‡å‡†åç§°

## ğŸ‰ æ€»ç»“

é€šè¾¾ä¿¡APIçš„é›†æˆä¸ºTradingAgents-CNå¸¦æ¥äº†ä»¥ä¸‹ä»·å€¼ï¼š

1. **ğŸ‡¨ğŸ‡³ æœ¬åœŸåŒ–ä¼˜åŠ¿**: å®Œæ•´çš„Aè‚¡æ•°æ®è¦†ç›–
2. **âš¡ å®æ—¶æ€§**: ç§’çº§æ•°æ®æ›´æ–°
3. **ğŸ’° æˆæœ¬ä¼˜åŠ¿**: å…è´¹ä½¿ç”¨ï¼Œæ— APIé™åˆ¶
4. **ğŸ”§ æ˜“ç”¨æ€§**: æ— éœ€å¤æ‚é…ç½®
5. **ğŸ“Š ä¸“ä¸šæ€§**: ä¸°å¯Œçš„æŠ€æœ¯æŒ‡æ ‡

ç°åœ¨æ‚¨å¯ä»¥åœ¨TradingAgents-CNä¸­æ— ç¼åˆ†æä¸­å›½è‚¡ç¥¨ï¼Œäº«å—ä¸“ä¸šçº§çš„æœ¬åœŸåŒ–è‚¡ç¥¨åˆ†æä½“éªŒï¼


<!-- docs/database_setup.md -->

# TradingAgents æ•°æ®åº“é…ç½®æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

TradingAgentsç°åœ¨æ”¯æŒMongoDBå’ŒRedisæ•°æ®åº“ï¼Œæä¾›æ•°æ®æŒä¹…åŒ–å­˜å‚¨å’Œé«˜æ€§èƒ½ç¼“å­˜åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### 1. å¯åŠ¨DockeræœåŠ¡

```bash
# Windows
scripts\start_services_alt_ports.bat

# Linux/Mac
scripts/start_services_alt_ports.sh
```

### 2. å®‰è£…Pythonä¾èµ–

```bash
pip install pymongo redis
```

### 3. åˆå§‹åŒ–æ•°æ®åº“

```bash
python scripts/init_database.py
```

### 4. å¯åŠ¨Webåº”ç”¨

```bash
cd web
python -m streamlit run app.py
```

## ğŸ”§ æœåŠ¡é…ç½®

### DockeræœåŠ¡ç«¯å£

ç”±äºæœ¬åœ°ç¯å¢ƒç«¯å£å†²çªï¼Œä½¿ç”¨äº†æ›¿ä»£ç«¯å£ï¼š

| æœåŠ¡ | é»˜è®¤ç«¯å£ | å®é™…ç«¯å£ | è®¿é—®åœ°å€ |
|------|----------|----------|----------|
| MongoDB | 27017 | **27018** | localhost:27018 |
| Redis | 6379 | **6380** | localhost:6380 |
| Redis Commander | 8081 | **8082** | http://localhost:8082 |

### è®¤è¯ä¿¡æ¯

- **ç”¨æˆ·å**: admin
- **å¯†ç **: tradingagents123
- **æ•°æ®åº“**: tradingagents

## ğŸ“Š æ•°æ®åº“ç»“æ„

### MongoDBé›†åˆ

1. **stock_data** - è‚¡ç¥¨å†å²æ•°æ®
   - ç´¢å¼•: (symbol, market_type), created_at, updated_at
   
2. **analysis_results** - åˆ†æç»“æœ
   - ç´¢å¼•: (symbol, analysis_type), created_at
   
3. **user_sessions** - ç”¨æˆ·ä¼šè¯
   - ç´¢å¼•: session_id, created_at, last_activity
   
4. **configurations** - ç³»ç»Ÿé…ç½®
   - ç´¢å¼•: (config_type, config_name), updated_at

### Redisç¼“å­˜ç»“æ„

- **é”®å‰ç¼€**: `tradingagents:`
- **TTLé…ç½®**:
  - ç¾è‚¡æ•°æ®: 2å°æ—¶
  - Aè‚¡æ•°æ®: 1å°æ—¶
  - æ–°é—»æ•°æ®: 4-6å°æ—¶
  - åŸºæœ¬é¢æ•°æ®: 12-24å°æ—¶

## ğŸ› ï¸ ç®¡ç†å·¥å…·

### Redis Commander
- è®¿é—®åœ°å€: http://localhost:8082
- åŠŸèƒ½: Redisæ•°æ®å¯è§†åŒ–ç®¡ç†

### ç¼“å­˜ç®¡ç†é¡µé¢
- è®¿é—®åœ°å€: http://localhost:8501 -> ç¼“å­˜ç®¡ç†
- åŠŸèƒ½: ç¼“å­˜ç»Ÿè®¡ã€æ¸…ç†ã€æµ‹è¯•

## ğŸ“ é…ç½®æ–‡ä»¶

### ç¯å¢ƒå˜é‡ (.env)

```bash
# MongoDBé…ç½®
MONGODB_HOST=localhost
MONGODB_PORT=27018
MONGODB_USERNAME=admin
MONGODB_PASSWORD=tradingagents123
MONGODB_DATABASE=tradingagents

# Redisé…ç½®
REDIS_HOST=localhost
REDIS_PORT=6380
REDIS_PASSWORD=tradingagents123
REDIS_DB=0
```

### é»˜è®¤é…ç½® (default_config.py)

æ•°æ®åº“é…ç½®å·²é›†æˆåˆ°é»˜è®¤é…ç½®ä¸­ï¼Œæ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–ã€‚

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ç«¯å£å†²çª**
   ```bash
   # æ£€æŸ¥ç«¯å£å ç”¨
   netstat -an | findstr :27018
   netstat -an | findstr :6380
   ```

2. **è¿æ¥å¤±è´¥**
   ```bash
   # æ£€æŸ¥Dockerå®¹å™¨çŠ¶æ€
   docker ps --filter "name=tradingagents-"
   
   # æŸ¥çœ‹å®¹å™¨æ—¥å¿—
   docker logs tradingagents-mongodb
   docker logs tradingagents-redis
   ```

3. **æƒé™é—®é¢˜**
   ```bash
   # é‡å¯å®¹å™¨
   docker restart tradingagents-mongodb tradingagents-redis
   ```

### é‡ç½®æ•°æ®åº“

```bash
# åœæ­¢å¹¶åˆ é™¤å®¹å™¨
docker stop tradingagents-mongodb tradingagents-redis tradingagents-redis-commander
docker rm tradingagents-mongodb tradingagents-redis tradingagents-redis-commander

# åˆ é™¤æ•°æ®å·ï¼ˆå¯é€‰ï¼Œä¼šä¸¢å¤±æ‰€æœ‰æ•°æ®ï¼‰
docker volume rm tradingagents_mongodb_data tradingagents_redis_data

# é‡æ–°å¯åŠ¨
scripts\start_services_alt_ports.bat
python scripts/init_database.py
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### ç¼“å­˜ç­–ç•¥

1. **åˆ†å±‚ç¼“å­˜**: Redis + æ–‡ä»¶ç¼“å­˜
2. **æ™ºèƒ½TTL**: æ ¹æ®æ•°æ®ç±»å‹è®¾ç½®ä¸åŒè¿‡æœŸæ—¶é—´
3. **å‹ç¼©å­˜å‚¨**: å¤§æ•°æ®è‡ªåŠ¨å‹ç¼©ï¼ˆå¯é…ç½®ï¼‰
4. **æ‰¹é‡æ“ä½œ**: æ”¯æŒæ‰¹é‡è¯»å†™

### ç›‘æ§æŒ‡æ ‡

- ç¼“å­˜å‘½ä¸­ç‡
- æ•°æ®åº“è¿æ¥æ•°
- å†…å­˜ä½¿ç”¨é‡
- å“åº”æ—¶é—´

## ğŸ” å®‰å…¨é…ç½®

### ç”Ÿäº§ç¯å¢ƒå»ºè®®

1. **ä¿®æ”¹é»˜è®¤å¯†ç **
2. **å¯ç”¨SSL/TLS**
3. **é…ç½®é˜²ç«å¢™è§„åˆ™**
4. **å®šæœŸå¤‡ä»½æ•°æ®**
5. **ç›‘æ§å¼‚å¸¸è®¿é—®**

## ğŸ“š APIä½¿ç”¨ç¤ºä¾‹

### Pythonä»£ç ç¤ºä¾‹

```python
from tradingagents.config.database_manager import get_database_manager

# è·å–æ•°æ®åº“ç®¡ç†å™¨
db_manager = get_database_manager()

# æ£€æŸ¥æ•°æ®åº“å¯ç”¨æ€§
if db_manager.is_mongodb_available():
    print("MongoDBå¯ç”¨")

if db_manager.is_redis_available():
    print("Rediså¯ç”¨")

# è·å–æ•°æ®åº“å®¢æˆ·ç«¯
mongodb_client = db_manager.get_mongodb_client()
redis_client = db_manager.get_redis_client()

# è·å–ç¼“å­˜ç»Ÿè®¡
stats = db_manager.get_cache_stats()
```

## ğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’

1. **æ•°æ®åŒæ­¥**: å®ç°å¤šå®ä¾‹æ•°æ®åŒæ­¥
2. **å¤‡ä»½ç­–ç•¥**: è‡ªåŠ¨å¤‡ä»½å’Œæ¢å¤
3. **æ€§èƒ½ç›‘æ§**: é›†æˆç›‘æ§ä»ªè¡¨æ¿
4. **é›†ç¾¤æ”¯æŒ**: MongoDBå’ŒRedisé›†ç¾¤é…ç½®
5. **æ•°æ®åˆ†æ**: å†…ç½®æ•°æ®åˆ†æå·¥å…·

---

**æ³¨æ„**: æœ¬é…ç½®é€‚ç”¨äºå¼€å‘å’Œæµ‹è¯•ç¯å¢ƒã€‚ç”Ÿäº§ç¯å¢ƒè¯·å‚è€ƒå®‰å…¨é…ç½®ç« èŠ‚è¿›è¡Œç›¸åº”è°ƒæ•´ã€‚


<!-- docs/development/branch-strategy.md -->

# åˆ†æ”¯ç®¡ç†ç­–ç•¥

## ğŸŒ¿ åˆ†æ”¯æ¶æ„è®¾è®¡

### ä¸»è¦åˆ†æ”¯

```
main (ç”Ÿäº§åˆ†æ”¯)
â”œâ”€â”€ develop (å¼€å‘ä¸»åˆ†æ”¯)
â”œâ”€â”€ feature/* (åŠŸèƒ½å¼€å‘åˆ†æ”¯)
â”œâ”€â”€ enhancement/* (ä¸­æ–‡å¢å¼ºåˆ†æ”¯)
â”œâ”€â”€ hotfix/* (ç´§æ€¥ä¿®å¤åˆ†æ”¯)
â”œâ”€â”€ release/* (å‘å¸ƒå‡†å¤‡åˆ†æ”¯)
â””â”€â”€ upstream-sync/* (ä¸Šæ¸¸åŒæ­¥åˆ†æ”¯)
```

### åˆ†æ”¯è¯´æ˜

#### ğŸ  **main** - ç”Ÿäº§ä¸»åˆ†æ”¯
- **ç”¨é€”**: ç¨³å®šçš„ç”Ÿäº§ç‰ˆæœ¬
- **ä¿æŠ¤**: å—ä¿æŠ¤ï¼Œåªèƒ½é€šè¿‡PRåˆå¹¶
- **æ¥æº**: developã€hotfixã€upstream-sync
- **ç‰¹ç‚¹**: å§‹ç»ˆä¿æŒå¯å‘å¸ƒçŠ¶æ€

#### ğŸš€ **develop** - å¼€å‘ä¸»åˆ†æ”¯
- **ç”¨é€”**: é›†æˆæ‰€æœ‰åŠŸèƒ½å¼€å‘
- **ä¿æŠ¤**: å—ä¿æŠ¤ï¼Œé€šè¿‡PRåˆå¹¶
- **æ¥æº**: featureã€enhancementåˆ†æ”¯
- **ç‰¹ç‚¹**: æœ€æ–°çš„å¼€å‘è¿›åº¦

#### âœ¨ **feature/** - åŠŸèƒ½å¼€å‘åˆ†æ”¯
- **å‘½å**: `feature/åŠŸèƒ½åç§°`
- **ç”¨é€”**: å¼€å‘æ–°åŠŸèƒ½
- **ç”Ÿå‘½å‘¨æœŸ**: çŸ­æœŸï¼ˆ1-2å‘¨ï¼‰
- **ç¤ºä¾‹**: `feature/portfolio-optimization`

#### ğŸ‡¨ğŸ‡³ **enhancement/** - ä¸­æ–‡å¢å¼ºåˆ†æ”¯
- **å‘½å**: `enhancement/å¢å¼ºåç§°`
- **ç”¨é€”**: ä¸­æ–‡æœ¬åœ°åŒ–å’Œå¢å¼ºåŠŸèƒ½
- **ç”Ÿå‘½å‘¨æœŸ**: ä¸­æœŸï¼ˆ2-4å‘¨ï¼‰
- **ç¤ºä¾‹**: `enhancement/chinese-llm-integration`

#### ğŸš¨ **hotfix/** - ç´§æ€¥ä¿®å¤åˆ†æ”¯
- **å‘½å**: `hotfix/ä¿®å¤æè¿°`
- **ç”¨é€”**: ç´§æ€¥Bugä¿®å¤
- **ç”Ÿå‘½å‘¨æœŸ**: çŸ­æœŸï¼ˆ1-3å¤©ï¼‰
- **ç¤ºä¾‹**: `hotfix/api-timeout-fix`

#### ğŸ“¦ **release/** - å‘å¸ƒå‡†å¤‡åˆ†æ”¯
- **å‘½å**: `release/ç‰ˆæœ¬å·`
- **ç”¨é€”**: å‘å¸ƒå‰çš„æœ€åå‡†å¤‡
- **ç”Ÿå‘½å‘¨æœŸ**: çŸ­æœŸï¼ˆ3-7å¤©ï¼‰
- **ç¤ºä¾‹**: `release/v1.1.0-cn`

#### ğŸ”„ **upstream-sync/** - ä¸Šæ¸¸åŒæ­¥åˆ†æ”¯
- **å‘½å**: `upstream-sync/æ—¥æœŸ`
- **ç”¨é€”**: åŒæ­¥ä¸Šæ¸¸æ›´æ–°
- **ç”Ÿå‘½å‘¨æœŸ**: ä¸´æ—¶ï¼ˆ1å¤©ï¼‰
- **ç¤ºä¾‹**: `upstream-sync/20240115`

## ğŸ”„ å·¥ä½œæµç¨‹

### åŠŸèƒ½å¼€å‘æµç¨‹

```mermaid
graph LR
    A[main] --> B[develop]
    B --> C[feature/new-feature]
    C --> D[å¼€å‘å’Œæµ‹è¯•]
    D --> E[PR to develop]
    E --> F[ä»£ç å®¡æŸ¥]
    F --> G[åˆå¹¶åˆ°develop]
    G --> H[æµ‹è¯•é›†æˆ]
    H --> I[PR to main]
    I --> J[å‘å¸ƒ]
```

### ä¸­æ–‡å¢å¼ºæµç¨‹

```mermaid
graph LR
    A[develop] --> B[enhancement/chinese-feature]
    B --> C[æœ¬åœ°åŒ–å¼€å‘]
    C --> D[ä¸­æ–‡æµ‹è¯•]
    D --> E[æ–‡æ¡£æ›´æ–°]
    E --> F[PR to develop]
    F --> G[å®¡æŸ¥å’Œåˆå¹¶]
```

### ç´§æ€¥ä¿®å¤æµç¨‹

```mermaid
graph LR
    A[main] --> B[hotfix/urgent-fix]
    B --> C[å¿«é€Ÿä¿®å¤]
    C --> D[æµ‹è¯•éªŒè¯]
    D --> E[PR to main]
    E --> F[ç«‹å³å‘å¸ƒ]
    F --> G[åˆå¹¶åˆ°develop]
```

## ğŸ“‹ åˆ†æ”¯æ“ä½œæŒ‡å—

### åˆ›å»ºåŠŸèƒ½åˆ†æ”¯

```bash
# ä»developåˆ›å»ºåŠŸèƒ½åˆ†æ”¯
git checkout develop
git pull origin develop
git checkout -b feature/portfolio-analysis

# å¼€å‘å®Œæˆåæ¨é€
git push -u origin feature/portfolio-analysis
```

### åˆ›å»ºä¸­æ–‡å¢å¼ºåˆ†æ”¯

```bash
# ä»developåˆ›å»ºå¢å¼ºåˆ†æ”¯
git checkout develop
git pull origin develop
git checkout -b enhancement/tushare-integration

# æ¨é€åˆ†æ”¯
git push -u origin enhancement/tushare-integration
```

### åˆ›å»ºç´§æ€¥ä¿®å¤åˆ†æ”¯

```bash
# ä»mainåˆ›å»ºä¿®å¤åˆ†æ”¯
git checkout main
git pull origin main
git checkout -b hotfix/api-error-fix

# æ¨é€åˆ†æ”¯
git push -u origin hotfix/api-error-fix
```

## ğŸ”’ åˆ†æ”¯ä¿æŠ¤è§„åˆ™

### mainåˆ†æ”¯ä¿æŠ¤
- âœ… è¦æ±‚PRå®¡æŸ¥
- âœ… è¦æ±‚çŠ¶æ€æ£€æŸ¥é€šè¿‡
- âœ… è¦æ±‚åˆ†æ”¯ä¸ºæœ€æ–°
- âœ… é™åˆ¶æ¨é€æƒé™
- âœ… é™åˆ¶å¼ºåˆ¶æ¨é€

### developåˆ†æ”¯ä¿æŠ¤
- âœ… è¦æ±‚PRå®¡æŸ¥
- âœ… è¦æ±‚CIé€šè¿‡
- âœ… å…è®¸ç®¡ç†å‘˜ç»•è¿‡

### åŠŸèƒ½åˆ†æ”¯
- âŒ æ— ç‰¹æ®Šä¿æŠ¤
- âœ… è‡ªåŠ¨åˆ é™¤å·²åˆå¹¶åˆ†æ”¯

## ğŸ·ï¸ å‘½åè§„èŒƒ

### åˆ†æ”¯å‘½å

```bash
# åŠŸèƒ½å¼€å‘
feature/åŠŸèƒ½åç§°-ç®€çŸ­æè¿°
feature/chinese-data-source
feature/risk-management-enhancement

# ä¸­æ–‡å¢å¼º
enhancement/å¢å¼ºç±»å‹-å…·ä½“å†…å®¹
enhancement/llm-baidu-integration
enhancement/chinese-financial-terms

# Bugä¿®å¤
hotfix/é—®é¢˜æè¿°
hotfix/memory-leak-fix
hotfix/config-loading-error

# å‘å¸ƒå‡†å¤‡
release/ç‰ˆæœ¬å·
release/v1.1.0-cn
release/v1.2.0-cn-beta
```

### æäº¤ä¿¡æ¯è§„èŒƒ

```bash
# åŠŸèƒ½å¼€å‘
feat(agents): æ·»åŠ é‡åŒ–åˆ†æå¸ˆæ™ºèƒ½ä½“
feat(data): é›†æˆTushareæ•°æ®æº

# ä¸­æ–‡å¢å¼º
enhance(llm): é›†æˆæ–‡å¿ƒä¸€è¨€API
enhance(docs): å®Œå–„ä¸­æ–‡æ–‡æ¡£ä½“ç³»

# Bugä¿®å¤
fix(api): ä¿®å¤APIè¶…æ—¶é—®é¢˜
fix(config): è§£å†³é…ç½®æ–‡ä»¶åŠ è½½é”™è¯¯

# æ–‡æ¡£æ›´æ–°
docs(readme): æ›´æ–°å®‰è£…æŒ‡å—
docs(api): æ·»åŠ APIä½¿ç”¨ç¤ºä¾‹
```

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### åˆ†æ”¯æµ‹è¯•è¦æ±‚

#### featureåˆ†æ”¯
- âœ… å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%
- âœ… åŠŸèƒ½æµ‹è¯•é€šè¿‡
- âœ… ä»£ç é£æ ¼æ£€æŸ¥

#### enhancementåˆ†æ”¯
- âœ… ä¸­æ–‡åŠŸèƒ½æµ‹è¯•
- âœ… å…¼å®¹æ€§æµ‹è¯•
- âœ… æ–‡æ¡£å®Œæ•´æ€§æ£€æŸ¥

#### developåˆ†æ”¯
- âœ… å®Œæ•´æµ‹è¯•å¥—ä»¶
- âœ… é›†æˆæµ‹è¯•
- âœ… æ€§èƒ½æµ‹è¯•

#### mainåˆ†æ”¯
- âœ… ç”Ÿäº§ç¯å¢ƒæµ‹è¯•
- âœ… ç«¯åˆ°ç«¯æµ‹è¯•
- âœ… å®‰å…¨æ‰«æ

## ğŸ“Š åˆ†æ”¯ç›‘æ§

### åˆ†æ”¯å¥åº·åº¦æŒ‡æ ‡

```bash
# æ£€æŸ¥åˆ†æ”¯çŠ¶æ€
git branch -a --merged    # å·²åˆå¹¶åˆ†æ”¯
git branch -a --no-merged # æœªåˆå¹¶åˆ†æ”¯

# æ£€æŸ¥åˆ†æ”¯å·®å¼‚
git log develop..main --oneline
git log feature/branch..develop --oneline

# æ£€æŸ¥åˆ†æ”¯å¤§å°
git rev-list --count develop..feature/branch
```

### å®šæœŸæ¸…ç†

```bash
# åˆ é™¤å·²åˆå¹¶çš„æœ¬åœ°åˆ†æ”¯
git branch --merged develop | grep -v "develop\|main" | xargs -n 1 git branch -d

# åˆ é™¤è¿œç¨‹è·Ÿè¸ªåˆ†æ”¯
git remote prune origin

# æ¸…ç†è¿‡æœŸåˆ†æ”¯
git for-each-ref --format='%(refname:short) %(committerdate)' refs/heads | awk '$2 <= "'$(date -d '30 days ago' '+%Y-%m-%d')'"' | cut -d' ' -f1
```

## ğŸš€ å‘å¸ƒæµç¨‹

### ç‰ˆæœ¬å‘å¸ƒæ­¥éª¤

1. **åˆ›å»ºå‘å¸ƒåˆ†æ”¯**
   ```bash
   git checkout develop
   git pull origin develop
   git checkout -b release/v1.1.0-cn
   ```

2. **ç‰ˆæœ¬å‡†å¤‡**
   ```bash
   # æ›´æ–°ç‰ˆæœ¬å·
   # æ›´æ–°CHANGELOG.md
   # æœ€åæµ‹è¯•
   ```

3. **åˆå¹¶åˆ°main**
   ```bash
   git checkout main
   git merge release/v1.1.0-cn
   git tag v1.1.0-cn
   git push origin main --tags
   ```

4. **å›åˆå¹¶åˆ°develop**
   ```bash
   git checkout develop
   git merge main
   git push origin develop
   ```

## ğŸ”§ è‡ªåŠ¨åŒ–å·¥å…·

### Git Hooks

```bash
# pre-commit hook
#!/bin/sh
# è¿è¡Œä»£ç é£æ ¼æ£€æŸ¥
black --check .
flake8 .

# pre-push hook
#!/bin/sh
# è¿è¡Œæµ‹è¯•
python -m pytest tests/
```

### GitHub Actions

```yaml
# åˆ†æ”¯ä¿æŠ¤æ£€æŸ¥
on:
  pull_request:
    branches: [main, develop]
    
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run tests
        run: python -m pytest
```

## ğŸš€ æ¨èçš„å¼€å‘å·¥ä½œæµ

### 1. æ—¥å¸¸åŠŸèƒ½å¼€å‘æµç¨‹

#### æ ‡å‡†åŠŸèƒ½å¼€å‘
```bash
# æ­¥éª¤1: åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
python scripts/branch_manager.py create feature portfolio-optimization -d "æŠ•èµ„ç»„åˆä¼˜åŒ–åŠŸèƒ½"

# æ­¥éª¤2: å¼€å‘åŠŸèƒ½
# ç¼–å†™ä»£ç ...
git add .
git commit -m "feat: æ·»åŠ æŠ•èµ„ç»„åˆä¼˜åŒ–ç®—æ³•"

# æ­¥éª¤3: å®šæœŸåŒæ­¥developåˆ†æ”¯
git fetch origin
git merge origin/develop  # æˆ–ä½¿ç”¨ git rebase origin/develop

# æ­¥éª¤4: æ¨é€åˆ°è¿œç¨‹
git push origin feature/portfolio-optimization

# æ­¥éª¤5: åˆ›å»ºPull Request
# åœ¨GitHubä¸Šåˆ›å»ºPR: feature/portfolio-optimization -> develop
# å¡«å†™PRæ¨¡æ¿ï¼ŒåŒ…å«åŠŸèƒ½æè¿°ã€æµ‹è¯•è¯´æ˜ç­‰

# æ­¥éª¤6: ä»£ç å®¡æŸ¥
# ç­‰å¾…å›¢é˜Ÿæˆå‘˜å®¡æŸ¥ï¼Œæ ¹æ®åé¦ˆä¿®æ”¹ä»£ç 

# æ­¥éª¤7: åˆå¹¶å’Œæ¸…ç†
# PRåˆå¹¶åï¼Œåˆ é™¤æœ¬åœ°å’Œè¿œç¨‹åˆ†æ”¯
python scripts/branch_manager.py delete feature/portfolio-optimization
```

#### åŠŸèƒ½å¼€å‘æ£€æŸ¥æ¸…å•
- [ ] åŠŸèƒ½éœ€æ±‚æ˜ç¡®ï¼Œæœ‰è¯¦ç»†çš„è®¾è®¡æ–‡æ¡£
- [ ] åˆ›å»ºäº†åˆé€‚çš„åˆ†æ”¯åç§°å’Œæè¿°
- [ ] ç¼–å†™äº†å®Œæ•´çš„å•å…ƒæµ‹è¯•
- [ ] ä»£ç ç¬¦åˆé¡¹ç›®ç¼–ç è§„èŒƒ
- [ ] æ›´æ–°äº†ç›¸å…³æ–‡æ¡£
- [ ] é€šè¿‡äº†æ‰€æœ‰è‡ªåŠ¨åŒ–æµ‹è¯•
- [ ] è¿›è¡Œäº†ä»£ç å®¡æŸ¥
- [ ] æµ‹è¯•äº†ä¸ç°æœ‰åŠŸèƒ½çš„å…¼å®¹æ€§

### 2. ä¸­æ–‡å¢å¼ºå¼€å‘æµç¨‹

#### æœ¬åœ°åŒ–åŠŸèƒ½å¼€å‘
```bash
# æ­¥éª¤1: åˆ›å»ºå¢å¼ºåˆ†æ”¯
python scripts/branch_manager.py create enhancement tushare-integration -d "é›†æˆTushare Aè‚¡æ•°æ®æº"

# æ­¥éª¤2: å¼€å‘ä¸­æ–‡åŠŸèƒ½
# é›†æˆä¸­æ–‡æ•°æ®æº
git add tradingagents/data/tushare_source.py
git commit -m "enhance(data): æ·»åŠ Tushareæ•°æ®æºé€‚é…å™¨"

# æ·»åŠ ä¸­æ–‡é…ç½®
git add config/chinese_config.yaml
git commit -m "enhance(config): æ·»åŠ ä¸­æ–‡å¸‚åœºé…ç½®"

# æ­¥éª¤3: æ›´æ–°ä¸­æ–‡æ–‡æ¡£
git add docs/data/tushare-integration.md
git commit -m "docs: æ·»åŠ Tushareé›†æˆæ–‡æ¡£"

# æ­¥éª¤4: ä¸­æ–‡åŠŸèƒ½æµ‹è¯•
python -m pytest tests/test_tushare_integration.py
git add tests/test_tushare_integration.py
git commit -m "test: æ·»åŠ Tushareé›†æˆæµ‹è¯•"

# æ­¥éª¤5: æ¨é€å’Œåˆå¹¶
git push origin enhancement/tushare-integration
# åˆ›å»ºPRåˆ°developåˆ†æ”¯
```

#### ä¸­æ–‡å¢å¼ºæ£€æŸ¥æ¸…å•
- [ ] åŠŸèƒ½é€‚é…ä¸­å›½é‡‘èå¸‚åœºç‰¹ç‚¹
- [ ] æ·»åŠ äº†å®Œæ•´çš„ä¸­æ–‡æ–‡æ¡£
- [ ] æ”¯æŒä¸­æ–‡é‡‘èæœ¯è¯­
- [ ] å…¼å®¹ç°æœ‰çš„å›½é™…åŒ–åŠŸèƒ½
- [ ] æµ‹è¯•äº†ä¸­æ–‡æ•°æ®å¤„ç†
- [ ] æ›´æ–°äº†é…ç½®æ–‡ä»¶å’Œç¤ºä¾‹

### 3. ç´§æ€¥ä¿®å¤æµç¨‹

#### ç”Ÿäº§ç¯å¢ƒBugä¿®å¤
```bash
# æ­¥éª¤1: ä»mainåˆ›å»ºä¿®å¤åˆ†æ”¯
python scripts/branch_manager.py create hotfix api-timeout-fix -d "ä¿®å¤APIè¯·æ±‚è¶…æ—¶é—®é¢˜"

# æ­¥éª¤2: å¿«é€Ÿå®šä½å’Œä¿®å¤
# åˆ†æé—®é¢˜æ ¹å› 
# å®æ–½æœ€å°åŒ–ä¿®å¤
git add tradingagents/api/client.py
git commit -m "fix: å¢åŠ APIè¯·æ±‚è¶…æ—¶é‡è¯•æœºåˆ¶"

# æ­¥éª¤3: ç´§æ€¥æµ‹è¯•
python -m pytest tests/test_api_client.py -v
# æ‰‹åŠ¨æµ‹è¯•å…³é”®è·¯å¾„

# æ­¥éª¤4: ç«‹å³éƒ¨ç½²åˆ°main
git push origin hotfix/api-timeout-fix
# åˆ›å»ºPRåˆ°mainï¼Œæ ‡è®°ä¸ºç´§æ€¥ä¿®å¤

# æ­¥éª¤5: åŒæ­¥åˆ°develop
git checkout develop
git merge main
git push origin develop
```

#### ç´§æ€¥ä¿®å¤æ£€æŸ¥æ¸…å•
- [ ] é—®é¢˜å½±å“è¯„ä¼°å’Œä¼˜å…ˆçº§ç¡®è®¤
- [ ] å®æ–½æœ€å°åŒ–ä¿®å¤æ–¹æ¡ˆ
- [ ] é€šè¿‡äº†å…³é”®è·¯å¾„æµ‹è¯•
- [ ] æœ‰å›æ»šè®¡åˆ’
- [ ] åŒæ­¥åˆ°æ‰€æœ‰ç›¸å…³åˆ†æ”¯
- [ ] é€šçŸ¥ç›¸å…³å›¢é˜Ÿæˆå‘˜

### 4. ç‰ˆæœ¬å‘å¸ƒæµç¨‹

#### æ­£å¼ç‰ˆæœ¬å‘å¸ƒ
```bash
# æ­¥éª¤1: åˆ›å»ºå‘å¸ƒåˆ†æ”¯
python scripts/branch_manager.py create release v1.1.0-cn -d "v1.1.0ä¸­æ–‡å¢å¼ºç‰ˆå‘å¸ƒ"

# æ­¥éª¤2: ç‰ˆæœ¬å‡†å¤‡
# æ›´æ–°ç‰ˆæœ¬å·
echo "1.1.0-cn" > VERSION
git add VERSION
git commit -m "bump: ç‰ˆæœ¬å·æ›´æ–°åˆ°v1.1.0-cn"

# æ›´æ–°å˜æ›´æ—¥å¿—
git add CHANGELOG.md
git commit -m "docs: æ›´æ–°v1.1.0-cnå˜æ›´æ—¥å¿—"

# æœ€ç»ˆæµ‹è¯•
python -m pytest tests/ --cov=tradingagents
python examples/full_test.py

# æ­¥éª¤3: åˆå¹¶åˆ°main
git checkout main
git merge release/v1.1.0-cn
git tag v1.1.0-cn
git push origin main --tags

# æ­¥éª¤4: å›åˆå¹¶åˆ°develop
git checkout develop
git merge main
git push origin develop

# æ­¥éª¤5: æ¸…ç†å‘å¸ƒåˆ†æ”¯
python scripts/branch_manager.py delete release/v1.1.0-cn
```

#### ç‰ˆæœ¬å‘å¸ƒæ£€æŸ¥æ¸…å•
- [ ] æ‰€æœ‰è®¡åˆ’åŠŸèƒ½å·²å®Œæˆå¹¶åˆå¹¶
- [ ] é€šè¿‡äº†å®Œæ•´çš„æµ‹è¯•å¥—ä»¶
- [ ] æ›´æ–°äº†ç‰ˆæœ¬å·å’Œå˜æ›´æ—¥å¿—
- [ ] åˆ›å»ºäº†ç‰ˆæœ¬æ ‡ç­¾
- [ ] å‡†å¤‡äº†å‘å¸ƒè¯´æ˜
- [ ] é€šçŸ¥äº†ç”¨æˆ·å’Œç¤¾åŒº

### 5. ä¸Šæ¸¸åŒæ­¥é›†æˆæµç¨‹

#### ä¸åŸé¡¹ç›®ä¿æŒåŒæ­¥
```bash
# æ­¥éª¤1: æ£€æŸ¥ä¸Šæ¸¸æ›´æ–°
python scripts/sync_upstream.py

# æ­¥éª¤2: å¦‚æœæœ‰æ›´æ–°ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºåŒæ­¥åˆ†æ”¯
# upstream-sync/20240115

# æ­¥éª¤3: è§£å†³å¯èƒ½çš„å†²çª
# ä¿æŠ¤æˆ‘ä»¬çš„ä¸­æ–‡æ–‡æ¡£å’Œå¢å¼ºåŠŸèƒ½
# é‡‡ç”¨ä¸Šæ¸¸çš„æ ¸å¿ƒä»£ç æ›´æ–°

# æ­¥éª¤4: æµ‹è¯•åŒæ­¥ç»“æœ
python -m pytest tests/
python examples/basic_example.py

# æ­¥éª¤5: åˆå¹¶åˆ°ä¸»åˆ†æ”¯
git checkout main
git merge upstream-sync/20240115
git push origin main

# æ­¥éª¤6: åŒæ­¥åˆ°develop
git checkout develop
git merge main
git push origin develop
```

## ğŸ“ˆ æœ€ä½³å®è·µ

### å¼€å‘å»ºè®®

1. **å°è€Œé¢‘ç¹çš„æäº¤** - æ¯ä¸ªæäº¤è§£å†³ä¸€ä¸ªå…·ä½“é—®é¢˜
2. **æè¿°æ€§åˆ†æ”¯å** - æ¸…æ¥šè¡¨è¾¾åˆ†æ”¯ç”¨é€”
3. **åŠæ—¶åŒæ­¥** - å®šæœŸä»developæ‹‰å–æœ€æ–°æ›´æ”¹
4. **å®Œæ•´æµ‹è¯•** - åˆå¹¶å‰ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡
5. **æ–‡æ¡£åŒæ­¥** - åŠŸèƒ½å¼€å‘åŒæ—¶æ›´æ–°æ–‡æ¡£

### åä½œè§„èŒƒ

1. **PRæ¨¡æ¿** - ä½¿ç”¨æ ‡å‡†çš„PRæè¿°æ¨¡æ¿
2. **ä»£ç å®¡æŸ¥** - è‡³å°‘ä¸€äººå®¡æŸ¥ååˆå¹¶
3. **å†²çªè§£å†³** - åŠæ—¶è§£å†³åˆå¹¶å†²çª
4. **åˆ†æ”¯æ¸…ç†** - åŠæ—¶åˆ é™¤å·²åˆå¹¶åˆ†æ”¯
5. **ç‰ˆæœ¬æ ‡è®°** - é‡è¦èŠ‚ç‚¹åˆ›å»ºç‰ˆæœ¬æ ‡ç­¾

### è´¨é‡ä¿è¯

1. **è‡ªåŠ¨åŒ–æµ‹è¯•** - æ¯ä¸ªPRéƒ½è¦é€šè¿‡CIæµ‹è¯•
2. **ä»£ç è¦†ç›–ç‡** - ä¿æŒ80%ä»¥ä¸Šçš„æµ‹è¯•è¦†ç›–ç‡
3. **æ€§èƒ½æµ‹è¯•** - é‡è¦åŠŸèƒ½è¦è¿›è¡Œæ€§èƒ½æµ‹è¯•
4. **å®‰å…¨æ‰«æ** - å®šæœŸè¿›è¡Œå®‰å…¨æ¼æ´æ‰«æ
5. **æ–‡æ¡£æ›´æ–°** - åŠŸèƒ½å˜æ›´åŒæ­¥æ›´æ–°æ–‡æ¡£

é€šè¿‡è¿™å¥—å®Œæ•´çš„åˆ†æ”¯ç®¡ç†ç­–ç•¥å’Œå¼€å‘å·¥ä½œæµï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿é¡¹ç›®å¼€å‘çš„æœ‰åºè¿›è¡Œï¼ŒåŒæ—¶ä¿æŒä»£ç è´¨é‡å’Œå‘å¸ƒç¨³å®šæ€§ã€‚


<!-- docs/development/development-workflow.md -->

# å¼€å‘å·¥ä½œæµæŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜ TradingAgents ä¸­æ–‡å¢å¼ºç‰ˆçš„æ ‡å‡†å¼€å‘å·¥ä½œæµç¨‹ï¼Œç¡®ä¿å›¢é˜Ÿåä½œçš„ä¸€è‡´æ€§å’Œä»£ç è´¨é‡ã€‚

## ğŸ”„ æ ¸å¿ƒå·¥ä½œæµç¨‹

### å·¥ä½œæµç¨‹å›¾

```mermaid
graph TD
    A[éœ€æ±‚åˆ†æ] --> B[åˆ›å»ºåˆ†æ”¯]
    B --> C[åŠŸèƒ½å¼€å‘]
    C --> D[ç¼–å†™æµ‹è¯•]
    D --> E[æ›´æ–°æ–‡æ¡£]
    E --> F[ä»£ç å®¡æŸ¥]
    F --> G{å®¡æŸ¥é€šè¿‡?}
    G -->|å¦| C
    G -->|æ˜¯| H[åˆå¹¶åˆ°develop]
    H --> I[é›†æˆæµ‹è¯•]
    I --> J{æµ‹è¯•é€šè¿‡?}
    J -->|å¦| K[ä¿®å¤é—®é¢˜]
    K --> C
    J -->|æ˜¯| L[å‘å¸ƒå‡†å¤‡]
    L --> M[åˆå¹¶åˆ°main]
    M --> N[ç‰ˆæœ¬å‘å¸ƒ]
```

## ğŸš€ è¯¦ç»†å·¥ä½œæµç¨‹

### 1. åŠŸèƒ½å¼€å‘å·¥ä½œæµ

#### 1.1 éœ€æ±‚åˆ†æé˜¶æ®µ
```bash
# ç¡®è®¤å¼€å‘éœ€æ±‚
# 1. é˜…è¯»éœ€æ±‚æ–‡æ¡£æˆ–Issueæè¿°
# 2. ç¡®è®¤æŠ€æœ¯æ–¹æ¡ˆå’Œå®ç°è·¯å¾„
# 3. è¯„ä¼°å¼€å‘æ—¶é—´å’Œèµ„æºéœ€æ±‚
# 4. ä¸å›¢é˜Ÿè®¨è®ºæŠ€æœ¯ç»†èŠ‚
```

#### 1.2 åˆ†æ”¯åˆ›å»ºé˜¶æ®µ
```bash
# ç¡®ä¿æœ¬åœ°developåˆ†æ”¯æ˜¯æœ€æ–°çš„
git checkout develop
git pull origin develop

# åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
python scripts/branch_manager.py create feature risk-management-v2 -d "é£é™©ç®¡ç†æ¨¡å—é‡æ„"

# éªŒè¯åˆ†æ”¯åˆ›å»º
git branch --show-current
# åº”è¯¥æ˜¾ç¤º: feature/risk-management-v2
```

#### 1.3 åŠŸèƒ½å¼€å‘é˜¶æ®µ
```bash
# å¼€å‘æ ¸å¿ƒåŠŸèƒ½
# 1. å®ç°ä¸»è¦åŠŸèƒ½é€»è¾‘
git add tradingagents/risk/manager_v2.py
git commit -m "feat(risk): å®ç°æ–°ç‰ˆé£é™©ç®¡ç†å™¨æ ¸å¿ƒé€»è¾‘"

# 2. æ·»åŠ é…ç½®æ”¯æŒ
git add config/risk_management_v2.yaml
git commit -m "feat(config): æ·»åŠ é£é™©ç®¡ç†v2é…ç½®æ–‡ä»¶"

# 3. é›†æˆåˆ°ä¸»æ¡†æ¶
git add tradingagents/graph/trading_graph.py
git commit -m "feat(graph): é›†æˆé£é™©ç®¡ç†v2åˆ°äº¤æ˜“å›¾"

# å®šæœŸåŒæ­¥developåˆ†æ”¯
git fetch origin
git rebase origin/develop  # æˆ–ä½¿ç”¨ merge
```

#### 1.4 æµ‹è¯•å¼€å‘é˜¶æ®µ
```bash
# ç¼–å†™å•å…ƒæµ‹è¯•
git add tests/risk/test_manager_v2.py
git commit -m "test(risk): æ·»åŠ é£é™©ç®¡ç†v2å•å…ƒæµ‹è¯•"

# ç¼–å†™é›†æˆæµ‹è¯•
git add tests/integration/test_risk_integration.py
git commit -m "test(integration): æ·»åŠ é£é™©ç®¡ç†é›†æˆæµ‹è¯•"

# è¿è¡Œæµ‹è¯•ç¡®ä¿é€šè¿‡
python -m pytest tests/risk/ -v
python -m pytest tests/integration/test_risk_integration.py -v
```

#### 1.5 æ–‡æ¡£æ›´æ–°é˜¶æ®µ
```bash
# æ›´æ–°APIæ–‡æ¡£
git add docs/api/risk-management.md
git commit -m "docs(api): æ›´æ–°é£é™©ç®¡ç†APIæ–‡æ¡£"

# æ·»åŠ ä½¿ç”¨ç¤ºä¾‹
git add examples/risk_management_example.py
git commit -m "docs(examples): æ·»åŠ é£é™©ç®¡ç†ä½¿ç”¨ç¤ºä¾‹"

# æ›´æ–°é…ç½®æ–‡æ¡£
git add docs/configuration/risk-config.md
git commit -m "docs(config): æ›´æ–°é£é™©ç®¡ç†é…ç½®æ–‡æ¡£"
```

#### 1.6 ä»£ç å®¡æŸ¥é˜¶æ®µ
```bash
# æ¨é€åˆ†æ”¯åˆ°è¿œç¨‹
git push origin feature/risk-management-v2

# åˆ›å»ºPull Request
# 1. è®¿é—®GitHubä»“åº“
# 2. åˆ›å»ºPR: feature/risk-management-v2 -> develop
# 3. å¡«å†™PRæ¨¡æ¿
# 4. æ·»åŠ å®¡æŸ¥è€…
# 5. ç­‰å¾…å®¡æŸ¥åé¦ˆ

# æ ¹æ®å®¡æŸ¥æ„è§ä¿®æ”¹ä»£ç 
git add .
git commit -m "fix(risk): æ ¹æ®å®¡æŸ¥æ„è§ä¿®å¤ä»£ç é£æ ¼é—®é¢˜"
git push origin feature/risk-management-v2
```

### 2. ä¸­æ–‡å¢å¼ºå¼€å‘å·¥ä½œæµ

#### 2.1 ä¸­æ–‡åŠŸèƒ½å¼€å‘
```bash
# åˆ›å»ºä¸­æ–‡å¢å¼ºåˆ†æ”¯
python scripts/branch_manager.py create enhancement akshare-integration -d "é›†æˆAkShareæ•°æ®æº"

# å¼€å‘ä¸­æ–‡æ•°æ®æºé€‚é…å™¨
git add tradingagents/data/akshare_adapter.py
git commit -m "enhance(data): æ·»åŠ AkShareæ•°æ®æºé€‚é…å™¨"

# æ·»åŠ ä¸­æ–‡é‡‘èæœ¯è¯­æ”¯æŒ
git add tradingagents/utils/chinese_terms.py
git commit -m "enhance(utils): æ·»åŠ ä¸­æ–‡é‡‘èæœ¯è¯­æ˜ å°„"

# é…ç½®ä¸­æ–‡å¸‚åœºå‚æ•°
git add config/chinese_markets/
git commit -m "enhance(config): æ·»åŠ ä¸­å›½é‡‘èå¸‚åœºé…ç½®"
```

#### 2.2 ä¸­æ–‡æ–‡æ¡£å¼€å‘
```bash
# æ·»åŠ ä¸­æ–‡ä½¿ç”¨æŒ‡å—
git add docs/data/akshare-integration.md
git commit -m "docs: æ·»åŠ AkShareé›†æˆä¸­æ–‡æŒ‡å—"

# æ›´æ–°ä¸­æ–‡ç¤ºä¾‹
git add examples/chinese_market_analysis.py
git commit -m "examples: æ·»åŠ ä¸­å›½å¸‚åœºåˆ†æç¤ºä¾‹"

# æ›´æ–°ä¸­æ–‡FAQ
git add docs/faq/chinese-features-faq.md
git commit -m "docs: æ·»åŠ ä¸­æ–‡åŠŸèƒ½å¸¸è§é—®é¢˜"
```

### 3. ç´§æ€¥ä¿®å¤å·¥ä½œæµ

#### 3.1 é—®é¢˜è¯†åˆ«å’Œè¯„ä¼°
```bash
# 1. ç¡®è®¤é—®é¢˜ä¸¥é‡ç¨‹åº¦
# 2. è¯„ä¼°å½±å“èŒƒå›´
# 3. åˆ¶å®šä¿®å¤æ–¹æ¡ˆ
# 4. ç¡®å®šä¿®å¤æ—¶é—´çº¿
```

#### 3.2 ç´§æ€¥ä¿®å¤å¼€å‘
```bash
# ä»mainåˆ†æ”¯åˆ›å»ºä¿®å¤åˆ†æ”¯
git checkout main
git pull origin main
python scripts/branch_manager.py create hotfix memory-leak-fix -d "ä¿®å¤å†…å­˜æ³„æ¼é—®é¢˜"

# å®æ–½æœ€å°åŒ–ä¿®å¤
git add tradingagents/core/memory_manager.py
git commit -m "fix: ä¿®å¤æ™ºèƒ½ä½“å†…å­˜æ³„æ¼é—®é¢˜"

# ç´§æ€¥æµ‹è¯•
python -m pytest tests/core/test_memory_manager.py -v
python tests/manual/memory_leak_test.py
```

#### 3.3 å¿«é€Ÿéƒ¨ç½²
```bash
# æ¨é€ä¿®å¤
git push origin hotfix/memory-leak-fix

# åˆ›å»ºç´§æ€¥PRåˆ°main
# æ ‡è®°ä¸ºç´§æ€¥ä¿®å¤ï¼Œè·³è¿‡å¸¸è§„å®¡æŸ¥æµç¨‹

# åˆå¹¶åç«‹å³åŒæ­¥åˆ°develop
git checkout develop
git merge main
git push origin develop
```

### 4. ç‰ˆæœ¬å‘å¸ƒå·¥ä½œæµ

#### 4.1 å‘å¸ƒå‡†å¤‡
```bash
# åˆ›å»ºå‘å¸ƒåˆ†æ”¯
python scripts/branch_manager.py create release v1.2.0-cn -d "v1.2.0ä¸­æ–‡å¢å¼ºç‰ˆå‘å¸ƒ"

# ç‰ˆæœ¬å·æ›´æ–°
echo "1.2.0-cn" > VERSION
git add VERSION
git commit -m "bump: ç‰ˆæœ¬æ›´æ–°åˆ°v1.2.0-cn"

# æ›´æ–°å˜æ›´æ—¥å¿—
# ç¼–è¾‘CHANGELOG.mdï¼Œæ·»åŠ æ–°ç‰ˆæœ¬çš„å˜æ›´å†…å®¹
git add CHANGELOG.md
git commit -m "docs: æ›´æ–°v1.2.0-cnå˜æ›´æ—¥å¿—"
```

#### 4.2 å‘å¸ƒæµ‹è¯•
```bash
# å®Œæ•´æµ‹è¯•å¥—ä»¶
python -m pytest tests/ --cov=tradingagents --cov-report=html

# æ€§èƒ½æµ‹è¯•
python tests/performance/benchmark_test.py

# é›†æˆæµ‹è¯•
python examples/full_integration_test.py

# æ–‡æ¡£æµ‹è¯•
# éªŒè¯æ‰€æœ‰æ–‡æ¡£é“¾æ¥å’Œç¤ºä¾‹ä»£ç 
```

#### 4.3 æ­£å¼å‘å¸ƒ
```bash
# åˆå¹¶åˆ°main
git checkout main
git merge release/v1.2.0-cn

# åˆ›å»ºç‰ˆæœ¬æ ‡ç­¾
git tag -a v1.2.0-cn -m "TradingAgentsä¸­æ–‡å¢å¼ºç‰ˆ v1.2.0"
git push origin main --tags

# åŒæ­¥åˆ°develop
git checkout develop
git merge main
git push origin develop

# æ¸…ç†å‘å¸ƒåˆ†æ”¯
python scripts/branch_manager.py delete release/v1.2.0-cn
```

## ğŸ“‹ å·¥ä½œæµæ£€æŸ¥æ¸…å•

### åŠŸèƒ½å¼€å‘æ£€æŸ¥æ¸…å•
- [ ] **éœ€æ±‚æ˜ç¡®**: åŠŸèƒ½éœ€æ±‚å’ŒéªŒæ”¶æ ‡å‡†æ¸…æ™°
- [ ] **è®¾è®¡æ–‡æ¡£**: æœ‰è¯¦ç»†çš„æŠ€æœ¯è®¾è®¡æ–‡æ¡£
- [ ] **åˆ†æ”¯å‘½å**: ä½¿ç”¨è§„èŒƒçš„åˆ†æ”¯å‘½å
- [ ] **ä»£ç è´¨é‡**: é€šè¿‡ä»£ç é£æ ¼æ£€æŸ¥
- [ ] **å•å…ƒæµ‹è¯•**: æµ‹è¯•è¦†ç›–ç‡è¾¾åˆ°80%ä»¥ä¸Š
- [ ] **é›†æˆæµ‹è¯•**: é€šè¿‡é›†æˆæµ‹è¯•
- [ ] **æ–‡æ¡£æ›´æ–°**: æ›´æ–°ç›¸å…³APIå’Œä½¿ç”¨æ–‡æ¡£
- [ ] **ç¤ºä¾‹ä»£ç **: æä¾›ä½¿ç”¨ç¤ºä¾‹
- [ ] **ä»£ç å®¡æŸ¥**: è‡³å°‘ä¸€äººå®¡æŸ¥é€šè¿‡
- [ ] **å‘åå…¼å®¹**: ç¡®ä¿å‘åå…¼å®¹æ€§

### ä¸­æ–‡å¢å¼ºæ£€æŸ¥æ¸…å•
- [ ] **å¸‚åœºé€‚é…**: é€‚é…ä¸­å›½é‡‘èå¸‚åœºç‰¹ç‚¹
- [ ] **æœ¯è¯­æ”¯æŒ**: æ”¯æŒä¸­æ–‡é‡‘èæœ¯è¯­
- [ ] **æ•°æ®æº**: é›†æˆä¸­æ–‡æ•°æ®æº
- [ ] **é…ç½®æ–‡ä»¶**: æ·»åŠ ä¸­æ–‡å¸‚åœºé…ç½®
- [ ] **ä¸­æ–‡æ–‡æ¡£**: å®Œæ•´çš„ä¸­æ–‡ä½¿ç”¨æ–‡æ¡£
- [ ] **ç¤ºä¾‹ä»£ç **: ä¸­æ–‡å¸‚åœºåˆ†æç¤ºä¾‹
- [ ] **æµ‹è¯•ç”¨ä¾‹**: ä¸­æ–‡åŠŸèƒ½æµ‹è¯•ç”¨ä¾‹
- [ ] **å…¼å®¹æ€§**: ä¸å›½é™…åŒ–åŠŸèƒ½å…¼å®¹

### å‘å¸ƒæ£€æŸ¥æ¸…å•
- [ ] **åŠŸèƒ½å®Œæ•´**: æ‰€æœ‰è®¡åˆ’åŠŸèƒ½å·²å®ç°
- [ ] **æµ‹è¯•é€šè¿‡**: å®Œæ•´æµ‹è¯•å¥—ä»¶é€šè¿‡
- [ ] **æ€§èƒ½éªŒè¯**: æ€§èƒ½æµ‹è¯•è¾¾æ ‡
- [ ] **æ–‡æ¡£å®Œæ•´**: æ‰€æœ‰æ–‡æ¡£å·²æ›´æ–°
- [ ] **ç‰ˆæœ¬æ ‡è®°**: æ­£ç¡®çš„ç‰ˆæœ¬å·å’Œæ ‡ç­¾
- [ ] **å˜æ›´æ—¥å¿—**: è¯¦ç»†çš„å˜æ›´è®°å½•
- [ ] **å‘å¸ƒè¯´æ˜**: å‡†å¤‡å‘å¸ƒå…¬å‘Š
- [ ] **å›æ»šè®¡åˆ’**: æœ‰åº”æ€¥å›æ»šæ–¹æ¡ˆ

## ğŸ”§ å·¥å…·å’Œè‡ªåŠ¨åŒ–

### å¼€å‘å·¥å…·
```bash
# åˆ†æ”¯ç®¡ç†
python scripts/branch_manager.py

# ä¸Šæ¸¸åŒæ­¥
python scripts/sync_upstream.py

# ä»£ç è´¨é‡æ£€æŸ¥
black tradingagents/
flake8 tradingagents/
mypy tradingagents/

# æµ‹è¯•è¿è¡Œ
python -m pytest tests/ -v --cov=tradingagents
```

### CI/CDé›†æˆ
- **GitHub Actions**: è‡ªåŠ¨åŒ–æµ‹è¯•å’Œéƒ¨ç½²
- **ä»£ç è´¨é‡**: è‡ªåŠ¨ä»£ç é£æ ¼å’Œè´¨é‡æ£€æŸ¥
- **æµ‹è¯•è¦†ç›–**: è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
- **æ–‡æ¡£æ„å»º**: è‡ªåŠ¨æ„å»ºå’Œéƒ¨ç½²æ–‡æ¡£

## ğŸ“ è·å–å¸®åŠ©

### æ–‡æ¡£èµ„æº
- [åˆ†æ”¯ç®¡ç†ç­–ç•¥](branch-strategy.md)
- [åˆ†æ”¯å¿«é€ŸæŒ‡å—](../../BRANCH_GUIDE.md)
- [ä¸Šæ¸¸åŒæ­¥æŒ‡å—](../maintenance/upstream-sync.md)

### è”ç³»æ–¹å¼
- **GitHub Issues**: [æäº¤é—®é¢˜](https://github.com/hsliuping/TradingAgents-CN/issues)
- **é‚®ç®±**: hsliup@163.com

é€šè¿‡éµå¾ªè¿™å¥—æ ‡å‡†åŒ–çš„å¼€å‘å·¥ä½œæµç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿é¡¹ç›®çš„é«˜è´¨é‡å¼€å‘å’Œç¨³å®šå‘å¸ƒã€‚


<!-- docs/development/project-structure.md -->

# é¡¹ç›®ç»“æ„è§„èŒƒ

## ğŸ“ ç›®å½•ç»„ç»‡åŸåˆ™

TradingAgents-CN é¡¹ç›®éµå¾ªæ¸…æ™°çš„ç›®å½•ç»“æ„è§„èŒƒï¼Œç¡®ä¿ä»£ç ç»„ç»‡æœ‰åºã€æ˜“äºç»´æŠ¤ã€‚

## ğŸ—ï¸ é¡¹ç›®æ ¹ç›®å½•ç»“æ„

```
TradingAgentsCN/
â”œâ”€â”€ ğŸ“ tradingagents/          # æ ¸å¿ƒä»£ç åŒ…
â”œâ”€â”€ ğŸ“ web/                    # Webç•Œé¢ä»£ç 
â”œâ”€â”€ ğŸ“ docs/                   # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ ğŸ“ tests/                  # æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ ğŸ“ scripts/                # å·¥å…·è„šæœ¬
â”œâ”€â”€ ğŸ“ env/                    # Pythonè™šæ‹Ÿç¯å¢ƒ
â”œâ”€â”€ ğŸ“„ README.md               # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ ğŸ“„ requirements.txt        # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ ğŸ“„ .env.example           # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ ğŸ“„ VERSION                 # ç‰ˆæœ¬å·
â””â”€â”€ ğŸ“„ CHANGELOG.md           # æ›´æ–°æ—¥å¿—
```

## ğŸ“‹ ç›®å½•èŒè´£è¯´æ˜

### ğŸ§ª tests/ - æµ‹è¯•ç›®å½•
**è§„åˆ™**: æ‰€æœ‰æµ‹è¯•ç›¸å…³çš„æ–‡ä»¶å¿…é¡»æ”¾åœ¨æ­¤ç›®å½•ä¸‹

#### å…è®¸çš„æ–‡ä»¶ç±»å‹ï¼š
- âœ… `test_*.py` - å•å…ƒæµ‹è¯•æ–‡ä»¶
- âœ… `*_test.py` - å¿«é€Ÿæµ‹è¯•è„šæœ¬
- âœ… `test_*_integration.py` - é›†æˆæµ‹è¯•
- âœ… `test_*_performance.py` - æ€§èƒ½æµ‹è¯•
- âœ… `check_*.py` - æ£€æŸ¥è„šæœ¬
- âœ… `debug_*.py` - è°ƒè¯•è„šæœ¬

#### å­ç›®å½•ç»„ç»‡ï¼š
```
tests/
â”œâ”€â”€ ğŸ“„ README.md                    # æµ‹è¯•è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ ğŸ“„ __init__.py                  # PythonåŒ…åˆå§‹åŒ–
â”œâ”€â”€ ğŸ“ integration/                 # é›†æˆæµ‹è¯•
â”œâ”€â”€ ğŸ“„ test_*.py                   # å•å…ƒæµ‹è¯•
â”œâ”€â”€ ğŸ“„ *_test.py                   # å¿«é€Ÿæµ‹è¯•
â””â”€â”€ ğŸ“„ test_*_performance.py       # æ€§èƒ½æµ‹è¯•
```

#### ç¤ºä¾‹æ–‡ä»¶ï¼š
- `test_analysis.py` - åˆ†æåŠŸèƒ½å•å…ƒæµ‹è¯•
- `fast_tdx_test.py` - é€šè¾¾ä¿¡APIå¿«é€Ÿæµ‹è¯•
- `test_tdx_integration.py` - é€šè¾¾ä¿¡APIé›†æˆæµ‹è¯•
- `test_redis_performance.py` - Redisæ€§èƒ½æµ‹è¯•

### ğŸ”§ scripts/ - å·¥å…·è„šæœ¬ç›®å½•
**è§„åˆ™**: ä»…æ”¾ç½®éæµ‹è¯•çš„å·¥å…·è„šæœ¬

#### å…è®¸çš„æ–‡ä»¶ç±»å‹ï¼š
- âœ… `release_*.py` - å‘å¸ƒè„šæœ¬
- âœ… `setup_*.py` - å®‰è£…é…ç½®è„šæœ¬
- âœ… `deploy_*.py` - éƒ¨ç½²è„šæœ¬
- âœ… `migrate_*.py` - æ•°æ®è¿ç§»è„šæœ¬
- âœ… `backup_*.py` - å¤‡ä»½è„šæœ¬

#### ä¸å…è®¸çš„æ–‡ä»¶ï¼š
- âŒ `test_*.py` - æµ‹è¯•æ–‡ä»¶åº”æ”¾åœ¨tests/
- âŒ `*_test.py` - æµ‹è¯•è„šæœ¬åº”æ”¾åœ¨tests/
- âŒ `check_*.py` - æ£€æŸ¥è„šæœ¬åº”æ”¾åœ¨tests/

### ğŸ“š docs/ - æ–‡æ¡£ç›®å½•
**è§„åˆ™**: æ‰€æœ‰é¡¹ç›®æ–‡æ¡£æŒ‰ç±»å‹ç»„ç»‡

#### ç›®å½•ç»“æ„ï¼š
```
docs/
â”œâ”€â”€ ğŸ“ guides/                     # ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ ğŸ“ development/                # å¼€å‘æ–‡æ¡£
â”œâ”€â”€ ğŸ“ data/                       # æ•°æ®æºæ–‡æ¡£
â”œâ”€â”€ ğŸ“ api/                        # APIæ–‡æ¡£
â””â”€â”€ ğŸ“ localization/               # æœ¬åœŸåŒ–æ–‡æ¡£
```

### ğŸŒ web/ - Webç•Œé¢ç›®å½•
**è§„åˆ™**: Webç›¸å…³ä»£ç ç»Ÿä¸€ç®¡ç†

#### ç›®å½•ç»“æ„ï¼š
```
web/
â”œâ”€â”€ ğŸ“„ app.py                      # ä¸»åº”ç”¨å…¥å£
â”œâ”€â”€ ğŸ“ components/                 # UIç»„ä»¶
â”œâ”€â”€ ğŸ“ utils/                      # Webå·¥å…·å‡½æ•°
â”œâ”€â”€ ğŸ“ static/                     # é™æ€èµ„æº
â””â”€â”€ ğŸ“ templates/                  # æ¨¡æ¿æ–‡ä»¶
```

### ğŸ§  tradingagents/ - æ ¸å¿ƒä»£ç åŒ…
**è§„åˆ™**: æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ä»£ç 

#### ç›®å½•ç»“æ„ï¼š
```
tradingagents/
â”œâ”€â”€ ğŸ“ agents/                     # æ™ºèƒ½ä½“ä»£ç 
â”œâ”€â”€ ğŸ“ dataflows/                  # æ•°æ®æµå¤„ç†
â”œâ”€â”€ ğŸ“ tools/                      # å·¥å…·å‡½æ•°
â””â”€â”€ ğŸ“ utils/                      # é€šç”¨å·¥å…·
```

## ğŸš« ç¦æ­¢çš„æ–‡ä»¶ä½ç½®

### æ ¹ç›®å½•ç¦æ­¢é¡¹ï¼š
- âŒ `test_*.py` - å¿…é¡»æ”¾åœ¨tests/
- âŒ `*_test.py` - å¿…é¡»æ”¾åœ¨tests/
- âŒ `debug_*.py` - å¿…é¡»æ”¾åœ¨tests/
- âŒ `check_*.py` - å¿…é¡»æ”¾åœ¨tests/
- âŒ ä¸´æ—¶æ–‡ä»¶å’Œè°ƒè¯•æ–‡ä»¶
- âŒ IDEé…ç½®æ–‡ä»¶ï¼ˆåº”åœ¨.gitignoreä¸­ï¼‰

### scripts/ç›®å½•ç¦æ­¢é¡¹ï¼š
- âŒ ä»»ä½•æµ‹è¯•ç›¸å…³æ–‡ä»¶
- âŒ è°ƒè¯•è„šæœ¬
- âŒ æ£€æŸ¥è„šæœ¬

## âœ… æ–‡ä»¶å‘½åè§„èŒƒ

### æµ‹è¯•æ–‡ä»¶å‘½åï¼š
- **å•å…ƒæµ‹è¯•**: `test_<module_name>.py`
- **é›†æˆæµ‹è¯•**: `test_<feature>_integration.py`
- **æ€§èƒ½æµ‹è¯•**: `test_<component>_performance.py`
- **å¿«é€Ÿæµ‹è¯•**: `<component>_test.py`
- **æ£€æŸ¥è„šæœ¬**: `check_<feature>.py`
- **è°ƒè¯•è„šæœ¬**: `debug_<issue>.py`

### å·¥å…·è„šæœ¬å‘½åï¼š
- **å‘å¸ƒè„šæœ¬**: `release_v<version>.py`
- **å®‰è£…è„šæœ¬**: `setup_<component>.py`
- **éƒ¨ç½²è„šæœ¬**: `deploy_<environment>.py`

### æ–‡æ¡£æ–‡ä»¶å‘½åï¼š
- **ä½¿ç”¨æŒ‡å—**: `<feature>-guide.md`
- **æŠ€æœ¯æ–‡æ¡£**: `<component>-integration.md`
- **APIæ–‡æ¡£**: `<api>-api.md`

## ğŸ” é¡¹ç›®ç»“æ„æ£€æŸ¥

### è‡ªåŠ¨æ£€æŸ¥è„šæœ¬
åˆ›å»º `tests/check_project_structure.py` æ¥éªŒè¯é¡¹ç›®ç»“æ„ï¼š

```python
def check_no_tests_in_root():
    """æ£€æŸ¥æ ¹ç›®å½•æ²¡æœ‰æµ‹è¯•æ–‡ä»¶"""
    
def check_no_tests_in_scripts():
    """æ£€æŸ¥scriptsç›®å½•æ²¡æœ‰æµ‹è¯•æ–‡ä»¶"""
    
def check_all_tests_in_tests_dir():
    """æ£€æŸ¥æ‰€æœ‰æµ‹è¯•æ–‡ä»¶éƒ½åœ¨testsç›®å½•"""
```

### æ‰‹åŠ¨æ£€æŸ¥æ¸…å•
å‘å¸ƒå‰æ£€æŸ¥ï¼š
- [ ] æ ¹ç›®å½•æ²¡æœ‰test_*.pyæ–‡ä»¶
- [ ] æ ¹ç›®å½•æ²¡æœ‰*_test.pyæ–‡ä»¶
- [ ] scripts/ç›®å½•æ²¡æœ‰æµ‹è¯•æ–‡ä»¶
- [ ] æ‰€æœ‰æµ‹è¯•æ–‡ä»¶éƒ½åœ¨tests/ç›®å½•
- [ ] tests/README.mdå·²æ›´æ–°
- [ ] æ–‡æ¡£ä¸­çš„è·¯å¾„å¼•ç”¨æ­£ç¡®

## ğŸ“ æœ€ä½³å®è·µ

### 1. æ–°å¢æµ‹è¯•æ–‡ä»¶
```bash
# âœ… æ­£ç¡®ï¼šåœ¨testsç›®å½•åˆ›å»º
touch tests/test_new_feature.py

# âŒ é”™è¯¯ï¼šåœ¨æ ¹ç›®å½•åˆ›å»º
touch test_new_feature.py
```

### 2. è¿è¡Œæµ‹è¯•
```bash
# âœ… æ­£ç¡®ï¼šæŒ‡å®štestsç›®å½•
python tests/fast_tdx_test.py
python -m pytest tests/

# âŒ é”™è¯¯ï¼šä»æ ¹ç›®å½•è¿è¡Œ
python fast_tdx_test.py
```

### 3. æ–‡æ¡£å¼•ç”¨
```markdown
<!-- âœ… æ­£ç¡®ï¼šä½¿ç”¨å®Œæ•´è·¯å¾„ -->
è¿è¡Œæµ‹è¯•ï¼š`python tests/fast_tdx_test.py`

<!-- âŒ é”™è¯¯ï¼šä½¿ç”¨ç›¸å¯¹è·¯å¾„ -->
è¿è¡Œæµ‹è¯•ï¼š`python fast_tdx_test.py`
```

## ğŸ”§ è¿ç§»ç°æœ‰æ–‡ä»¶

å¦‚æœå‘ç°æ–‡ä»¶ä½ç½®ä¸ç¬¦åˆè§„èŒƒï¼š

### ç§»åŠ¨æµ‹è¯•æ–‡ä»¶åˆ°testsç›®å½•ï¼š
```bash
# Windows
move test_*.py tests\
move *_test.py tests\

# Linux/macOS
mv test_*.py tests/
mv *_test.py tests/
```

### æ›´æ–°å¼•ç”¨ï¼š
1. æ›´æ–°æ–‡æ¡£ä¸­çš„è·¯å¾„å¼•ç”¨
2. æ›´æ–°è„šæœ¬ä¸­çš„importè·¯å¾„
3. æ›´æ–°CI/CDé…ç½®ä¸­çš„æµ‹è¯•è·¯å¾„

## ğŸ¯ éµå¾ªè§„èŒƒçš„å¥½å¤„

1. **æ¸…æ™°çš„é¡¹ç›®ç»“æ„** - æ–°å¼€å‘è€…å®¹æ˜“ç†è§£
2. **ä¾¿äºç»´æŠ¤** - æ–‡ä»¶ä½ç½®å¯é¢„æµ‹
3. **è‡ªåŠ¨åŒ–å‹å¥½** - CI/CDè„šæœ¬æ›´ç®€å•
4. **é¿å…æ··ä¹±** - æµ‹è¯•å’Œä¸šåŠ¡ä»£ç åˆ†ç¦»
5. **ä¸“ä¸šå½¢è±¡** - ç¬¦åˆå¼€æºé¡¹ç›®æ ‡å‡†

---

**è¯·ä¸¥æ ¼éµå¾ªæ­¤é¡¹ç›®ç»“æ„è§„èŒƒï¼Œç¡®ä¿ä»£ç åº“çš„æ•´æ´å’Œä¸“ä¸šæ€§ï¼** ğŸ“âœ¨


<!-- docs/examples/advanced-examples.md -->

# é«˜çº§ä½¿ç”¨ç¤ºä¾‹

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›äº† TradingAgents æ¡†æ¶çš„é«˜çº§ä½¿ç”¨ç¤ºä¾‹ï¼ŒåŒ…æ‹¬è‡ªå®šä¹‰æ™ºèƒ½ä½“å¼€å‘ã€å¤æ‚ç­–ç•¥å®ç°ã€æ€§èƒ½ä¼˜åŒ–å’Œç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ç­‰é«˜çº§åŠŸèƒ½ã€‚

## ç¤ºä¾‹ 1: è‡ªå®šä¹‰åˆ†æå¸ˆæ™ºèƒ½ä½“

### åˆ›å»ºé‡åŒ–åˆ†æå¸ˆ
```python
from tradingagents.agents.analysts.base_analyst import BaseAnalyst
import numpy as np
import pandas as pd

class QuantitativeAnalyst(BaseAnalyst):
    """é‡åŒ–åˆ†æå¸ˆ - åŸºäºæ•°å­¦æ¨¡å‹çš„åˆ†æ"""

    def __init__(self, llm, config):
        super().__init__(llm, config)
        self.models = self._initialize_quant_models()

    def _initialize_quant_models(self):
        """åˆå§‹åŒ–é‡åŒ–æ¨¡å‹"""
        return {
            "mean_reversion": MeanReversionModel(),
            "momentum": MomentumModel(),
            "volatility": VolatilityModel(),
            "correlation": CorrelationModel()
        }

    def perform_analysis(self, data: Dict) -> Dict:
        """æ‰§è¡Œé‡åŒ–åˆ†æ"""

        price_data = data.get("price_data", {})
        historical_data = data.get("historical_data", pd.DataFrame())

        if historical_data.empty:
            return {"error": "No historical data available"}

        # 1. ç»Ÿè®¡å¥—åˆ©åˆ†æ
        stat_arb_signals = self._statistical_arbitrage_analysis(historical_data)

        # 2. åŠ¨é‡å› å­åˆ†æ
        momentum_signals = self._momentum_factor_analysis(historical_data)

        # 3. å‡å€¼å›å½’åˆ†æ
        mean_reversion_signals = self._mean_reversion_analysis(historical_data)

        # 4. æ³¢åŠ¨ç‡åˆ†æ
        volatility_analysis = self._volatility_analysis(historical_data)

        # 5. é£é™©è°ƒæ•´æ”¶ç›Šåˆ†æ
        risk_adjusted_metrics = self._risk_adjusted_analysis(historical_data)

        # 6. ç»¼åˆé‡åŒ–è¯„åˆ†
        quant_score = self._calculate_quant_score({
            "stat_arb": stat_arb_signals,
            "momentum": momentum_signals,
            "mean_reversion": mean_reversion_signals,
            "volatility": volatility_analysis,
            "risk_adjusted": risk_adjusted_metrics
        })

        return {
            "statistical_arbitrage": stat_arb_signals,
            "momentum_analysis": momentum_signals,
            "mean_reversion": mean_reversion_signals,
            "volatility_analysis": volatility_analysis,
            "risk_metrics": risk_adjusted_metrics,
            "quantitative_score": quant_score,
            "model_confidence": self._calculate_model_confidence(quant_score),
            "trading_signals": self._generate_trading_signals(quant_score)
        }

    def _statistical_arbitrage_analysis(self, data: pd.DataFrame) -> Dict:
        """ç»Ÿè®¡å¥—åˆ©åˆ†æ"""

        returns = data['Close'].pct_change().dropna()

        # Z-Score è®¡ç®—
        rolling_mean = returns.rolling(window=20).mean()
        rolling_std = returns.rolling(window=20).std()
        z_score = (returns - rolling_mean) / rolling_std

        # åæ•´æ€§æ£€éªŒ
        adf_statistic, adf_pvalue = self._adf_test(data['Close'])

        # åŠè¡°æœŸè®¡ç®—
        half_life = self._calculate_half_life(returns)

        return {
            "current_z_score": z_score.iloc[-1] if not z_score.empty else 0,
            "z_score_percentile": self._calculate_percentile(z_score.iloc[-1], z_score),
            "adf_statistic": adf_statistic,
            "adf_pvalue": adf_pvalue,
            "is_stationary": adf_pvalue < 0.05,
            "half_life_days": half_life,
            "signal_strength": abs(z_score.iloc[-1]) if not z_score.empty else 0
        }

    def _momentum_factor_analysis(self, data: pd.DataFrame) -> Dict:
        """åŠ¨é‡å› å­åˆ†æ"""

        # å¤šæ—¶é—´æ¡†æ¶åŠ¨é‡
        momentum_1m = self._calculate_momentum(data, 21)    # 1ä¸ªæœˆ
        momentum_3m = self._calculate_momentum(data, 63)    # 3ä¸ªæœˆ
        momentum_6m = self._calculate_momentum(data, 126)   # 6ä¸ªæœˆ
        momentum_12m = self._calculate_momentum(data, 252)  # 12ä¸ªæœˆ

        # åŠ¨é‡å¼ºåº¦
        momentum_strength = self._calculate_momentum_strength(data)

        # åŠ¨é‡æŒç»­æ€§
        momentum_persistence = self._calculate_momentum_persistence(data)

        return {
            "momentum_1m": momentum_1m,
            "momentum_3m": momentum_3m,
            "momentum_6m": momentum_6m,
            "momentum_12m": momentum_12m,
            "momentum_strength": momentum_strength,
            "momentum_persistence": momentum_persistence,
            "momentum_score": (momentum_1m + momentum_3m + momentum_6m) / 3,
            "momentum_trend": "bullish" if momentum_3m > 0.05 else "bearish" if momentum_3m < -0.05 else "neutral"
        }
```

## ç¤ºä¾‹ 2: å¤šèµ„äº§ç»„åˆåˆ†æ

### æŠ•èµ„ç»„åˆä¼˜åŒ–å™¨
```python
class PortfolioOptimizer:
    """æŠ•èµ„ç»„åˆä¼˜åŒ–å™¨ - å¤šèµ„äº§é…ç½®ä¼˜åŒ–"""

    def __init__(self, config: Dict):
        self.config = config
        self.risk_models = self._initialize_risk_models()
        self.optimization_methods = self._initialize_optimization_methods()

    def optimize_portfolio(self, symbols: List[str], target_date: str,
                          constraints: Dict = None) -> Dict:
        """ä¼˜åŒ–æŠ•èµ„ç»„åˆé…ç½®"""

        # 1. æ”¶é›†æ‰€æœ‰èµ„äº§æ•°æ®
        assets_data = self._collect_multi_asset_data(symbols, target_date)

        # 2. è®¡ç®—é¢„æœŸæ”¶ç›Š
        expected_returns = self._calculate_expected_returns(assets_data)

        # 3. æ„å»ºåæ–¹å·®çŸ©é˜µ
        covariance_matrix = self._build_covariance_matrix(assets_data)

        # 4. é£é™©æ¨¡å‹åˆ†æ
        risk_analysis = self._analyze_portfolio_risk(assets_data, covariance_matrix)

        # 5. å¤šç›®æ ‡ä¼˜åŒ–
        optimization_results = self._multi_objective_optimization(
            expected_returns, covariance_matrix, constraints
        )

        # 6. æƒ…æ™¯åˆ†æ
        scenario_analysis = self._perform_scenario_analysis(
            optimization_results, assets_data
        )

        return {
            "assets_analysis": assets_data,
            "expected_returns": expected_returns,
            "risk_analysis": risk_analysis,
            "optimal_weights": optimization_results["weights"],
            "portfolio_metrics": optimization_results["metrics"],
            "scenario_analysis": scenario_analysis,
            "rebalancing_schedule": self._generate_rebalancing_schedule(optimization_results)
        }

    def _collect_multi_asset_data(self, symbols: List[str], target_date: str) -> Dict:
        """æ”¶é›†å¤šèµ„äº§æ•°æ®"""

        assets_data = {}

        # å¹¶è¡Œåˆ†ææ‰€æœ‰èµ„äº§
        with ThreadPoolExecutor(max_workers=len(symbols)) as executor:
            future_to_symbol = {
                executor.submit(self._analyze_single_asset, symbol, target_date): symbol
                for symbol in symbols
            }

            for future in as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                try:
                    asset_analysis = future.result()
                    assets_data[symbol] = asset_analysis
                except Exception as e:
                    print(f"Error analyzing {symbol}: {e}")
                    assets_data[symbol] = {"error": str(e)}

        return assets_data

    def _analyze_single_asset(self, symbol: str, target_date: str) -> Dict:
        """åˆ†æå•ä¸ªèµ„äº§"""

        # ä½¿ç”¨ TradingAgents åˆ†æå•ä¸ªèµ„äº§
        ta = TradingAgentsGraph(debug=False, config=self.config)
        state, decision = ta.propagate(symbol, target_date)

        # æå–å…³é”®æŒ‡æ ‡
        return {
            "symbol": symbol,
            "decision": decision,
            "fundamental_score": state.analyst_reports.get("fundamentals", {}).get("overall_score", 0.5),
            "technical_score": state.analyst_reports.get("technical", {}).get("technical_score", 0.5),
            "sentiment_score": (
                state.analyst_reports.get("news", {}).get("news_score", 0.5) +
                state.analyst_reports.get("social", {}).get("social_score", 0.5)
            ) / 2,
            "risk_score": decision.get("risk_score", 0.5),
            "confidence": decision.get("confidence", 0.5)
        }

    def _multi_objective_optimization(self, expected_returns: np.ndarray,
                                    cov_matrix: np.ndarray, constraints: Dict) -> Dict:
        """å¤šç›®æ ‡ä¼˜åŒ–"""

        from scipy.optimize import minimize

        n_assets = len(expected_returns)

        # ç›®æ ‡å‡½æ•°ï¼šæœ€å¤§åŒ–å¤æ™®æ¯”ç‡
        def objective(weights):
            portfolio_return = np.sum(weights * expected_returns)
            portfolio_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
            sharpe_ratio = portfolio_return / portfolio_risk if portfolio_risk > 0 else 0
            return -sharpe_ratio  # æœ€å°åŒ–è´Ÿå¤æ™®æ¯”ç‡

        # çº¦æŸæ¡ä»¶
        constraints_list = [
            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}  # æƒé‡å’Œä¸º1
        ]

        # æ·»åŠ è‡ªå®šä¹‰çº¦æŸ
        if constraints:
            if 'max_weight' in constraints:
                for i in range(n_assets):
                    constraints_list.append({
                        'type': 'ineq',
                        'fun': lambda x, i=i: constraints['max_weight'] - x[i]
                    })

            if 'min_weight' in constraints:
                for i in range(n_assets):
                    constraints_list.append({
                        'type': 'ineq',
                        'fun': lambda x, i=i: x[i] - constraints['min_weight']
                    })

        # è¾¹ç•Œæ¡ä»¶
        bounds = tuple((0, 1) for _ in range(n_assets))

        # åˆå§‹çŒœæµ‹
        x0 = np.array([1/n_assets] * n_assets)

        # ä¼˜åŒ–
        result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints_list)

        if result.success:
            optimal_weights = result.x
            portfolio_return = np.sum(optimal_weights * expected_returns)
            portfolio_risk = np.sqrt(np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights)))
            sharpe_ratio = portfolio_return / portfolio_risk if portfolio_risk > 0 else 0

            return {
                "weights": optimal_weights,
                "metrics": {
                    "expected_return": portfolio_return,
                    "expected_risk": portfolio_risk,
                    "sharpe_ratio": sharpe_ratio,
                    "optimization_success": True
                }
            }
        else:
            # å¦‚æœä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç­‰æƒé‡
            equal_weights = np.array([1/n_assets] * n_assets)
            return {
                "weights": equal_weights,
                "metrics": {
                    "expected_return": np.sum(equal_weights * expected_returns),
                    "expected_risk": np.sqrt(np.dot(equal_weights.T, np.dot(cov_matrix, equal_weights))),
                    "sharpe_ratio": 0,
                    "optimization_success": False,
                    "error": result.message
                }
            }
```

## ç¤ºä¾‹ 3: å®æ—¶äº¤æ˜“ç³»ç»Ÿ

### å®æ—¶ç›‘æ§å’Œæ‰§è¡Œç³»ç»Ÿ
```python
class RealTimeTradingSystem:
    """å®æ—¶äº¤æ˜“ç³»ç»Ÿ"""

    def __init__(self, config: Dict):
        self.config = config
        self.trading_agents = {}
        self.position_manager = PositionManager()
        self.risk_monitor = RealTimeRiskMonitor()
        self.execution_engine = ExecutionEngine()
        self.market_data_feed = MarketDataFeed()

    async def start_real_time_trading(self, watchlist: List[str]):
        """å¯åŠ¨å®æ—¶äº¤æ˜“"""

        print(f"å¯åŠ¨å®æ—¶äº¤æ˜“ç³»ç»Ÿï¼Œç›‘æ§ {len(watchlist)} åªè‚¡ç¥¨...")

        # åˆå§‹åŒ–æ¯åªè‚¡ç¥¨çš„äº¤æ˜“æ™ºèƒ½ä½“
        for symbol in watchlist:
            self.trading_agents[symbol] = TradingAgentsGraph(
                debug=False,
                config=self.config
            )

        # å¯åŠ¨å¸‚åœºæ•°æ®è®¢é˜…
        await self.market_data_feed.subscribe(watchlist)

        # å¯åŠ¨ä¸»äº¤æ˜“å¾ªç¯
        await self._main_trading_loop(watchlist)

    async def _main_trading_loop(self, watchlist: List[str]):
        """ä¸»äº¤æ˜“å¾ªç¯"""

        while True:
            try:
                # è·å–æœ€æ–°å¸‚åœºæ•°æ®
                market_updates = await self.market_data_feed.get_updates()

                # å¹¶è¡Œå¤„ç†æ‰€æœ‰è‚¡ç¥¨
                tasks = []
                for symbol in watchlist:
                    if symbol in market_updates:
                        task = self._process_symbol_update(symbol, market_updates[symbol])
                        tasks.append(task)

                if tasks:
                    await asyncio.gather(*tasks, return_exceptions=True)

                # é£é™©æ£€æŸ¥
                await self._perform_risk_checks()

                # çŸ­æš‚ä¼‘çœ 
                await asyncio.sleep(1)

            except Exception as e:
                print(f"äº¤æ˜“å¾ªç¯é”™è¯¯: {e}")
                await asyncio.sleep(5)

    async def _process_symbol_update(self, symbol: str, market_data: Dict):
        """å¤„ç†å•ä¸ªè‚¡ç¥¨çš„å¸‚åœºæ›´æ–°"""

        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆ†æ
            if self._should_reanalyze(symbol, market_data):

                # æ‰§è¡Œå¿«é€Ÿåˆ†æ
                analysis_result = await self._quick_analysis(symbol, market_data)

                # æ£€æŸ¥äº¤æ˜“ä¿¡å·
                trading_signals = self._extract_trading_signals(analysis_result)

                # æ‰§è¡Œäº¤æ˜“å†³ç­–
                if trading_signals["action"] != "hold":
                    await self._execute_trading_decision(symbol, trading_signals)

                # æ›´æ–°ä»“ä½ç›‘æ§
                await self._update_position_monitoring(symbol, analysis_result)

        except Exception as e:
            print(f"å¤„ç† {symbol} æ›´æ–°æ—¶å‡ºé”™: {e}")

    def _should_reanalyze(self, symbol: str, market_data: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°åˆ†æ"""

        # ä»·æ ¼å˜åŠ¨é˜ˆå€¼
        price_change_threshold = 0.02  # 2%

        current_price = market_data.get("price", 0)
        last_analysis_price = self.trading_agents[symbol].last_analysis_price if hasattr(self.trading_agents[symbol], 'last_analysis_price') else 0

        if last_analysis_price == 0:
            return True

        price_change = abs(current_price - last_analysis_price) / last_analysis_price

        # å¦‚æœä»·æ ¼å˜åŠ¨è¶…è¿‡é˜ˆå€¼ï¼Œæˆ–è€…è·ç¦»ä¸Šæ¬¡åˆ†æè¶…è¿‡ä¸€å®šæ—¶é—´
        time_threshold = 300  # 5åˆ†é’Ÿ
        last_analysis_time = getattr(self.trading_agents[symbol], 'last_analysis_time', 0)
        time_since_last = time.time() - last_analysis_time

        return price_change > price_change_threshold or time_since_last > time_threshold

    async def _quick_analysis(self, symbol: str, market_data: Dict) -> Dict:
        """å¿«é€Ÿåˆ†æ"""

        # ä½¿ç”¨ç®€åŒ–é…ç½®è¿›è¡Œå¿«é€Ÿåˆ†æ
        quick_config = self.config.copy()
        quick_config.update({
            "max_debate_rounds": 1,
            "max_risk_discuss_rounds": 1,
            "quick_think_llm": "gpt-4o-mini"  # ä½¿ç”¨å¿«é€Ÿæ¨¡å‹
        })

        # åˆ›å»ºå¿«é€Ÿåˆ†ææ™ºèƒ½ä½“
        quick_agent = TradingAgentsGraph(
            selected_analysts=["market", "news"],  # åªä½¿ç”¨å…³é”®åˆ†æå¸ˆ
            debug=False,
            config=quick_config
        )

        # æ‰§è¡Œåˆ†æ
        current_date = datetime.now().strftime("%Y-%m-%d")
        state, decision = quick_agent.propagate(symbol, current_date)

        # è®°å½•åˆ†ææ—¶é—´å’Œä»·æ ¼
        self.trading_agents[symbol].last_analysis_time = time.time()
        self.trading_agents[symbol].last_analysis_price = market_data.get("price", 0)

        return {
            "state": state,
            "decision": decision,
            "market_data": market_data,
            "analysis_timestamp": time.time()
        }
```

## ç¤ºä¾‹ 4: ç­–ç•¥å›æµ‹æ¡†æ¶

### é«˜çº§å›æµ‹ç³»ç»Ÿ
```python
class AdvancedBacktester:
    """é«˜çº§å›æµ‹ç³»ç»Ÿ"""

    def __init__(self, config: Dict):
        self.config = config
        self.performance_analyzer = PerformanceAnalyzer()
        self.risk_analyzer = RiskAnalyzer()
        self.transaction_cost_model = TransactionCostModel()

    def run_comprehensive_backtest(self, strategy_config: Dict,
                                 start_date: str, end_date: str,
                                 universe: List[str]) -> Dict:
        """è¿è¡Œç»¼åˆå›æµ‹"""

        print(f"å¼€å§‹å›æµ‹: {start_date} åˆ° {end_date}, è‚¡ç¥¨æ± : {len(universe)} åª")

        # 1. æ•°æ®å‡†å¤‡
        historical_data = self._prepare_historical_data(universe, start_date, end_date)

        # 2. ç­–ç•¥æ‰§è¡Œ
        trading_history = self._execute_strategy(strategy_config, historical_data)

        # 3. æ€§èƒ½åˆ†æ
        performance_metrics = self._analyze_performance(trading_history)

        # 4. é£é™©åˆ†æ
        risk_metrics = self._analyze_risk(trading_history)

        # 5. å½’å› åˆ†æ
        attribution_analysis = self._perform_attribution_analysis(trading_history)

        # 6. æ•æ„Ÿæ€§åˆ†æ
        sensitivity_analysis = self._perform_sensitivity_analysis(strategy_config, historical_data)

        return {
            "strategy_config": strategy_config,
            "backtest_period": {"start": start_date, "end": end_date},
            "universe": universe,
            "trading_history": trading_history,
            "performance_metrics": performance_metrics,
            "risk_metrics": risk_metrics,
            "attribution_analysis": attribution_analysis,
            "sensitivity_analysis": sensitivity_analysis,
            "summary": self._generate_backtest_summary(performance_metrics, risk_metrics)
        }

    def _execute_strategy(self, strategy_config: Dict, historical_data: Dict) -> List[Dict]:
        """æ‰§è¡Œç­–ç•¥"""

        trading_history = []
        portfolio = Portfolio(initial_capital=strategy_config.get("initial_capital", 1000000))

        # æŒ‰æ—¥æœŸé¡ºåºæ‰§è¡Œ
        dates = sorted(historical_data.keys())

        for date in dates:
            daily_data = historical_data[date]

            # ä¸ºæ¯åªè‚¡ç¥¨ç”Ÿæˆäº¤æ˜“ä¿¡å·
            daily_signals = {}
            for symbol in daily_data:
                try:
                    # ä½¿ç”¨ TradingAgents ç”Ÿæˆä¿¡å·
                    signal = self._generate_trading_signal(symbol, date, daily_data[symbol])
                    daily_signals[symbol] = signal
                except Exception as e:
                    print(f"ç”Ÿæˆ {symbol} ä¿¡å·æ—¶å‡ºé”™: {e}")
                    continue

            # æ‰§è¡ŒæŠ•èµ„ç»„åˆé‡å¹³è¡¡
            portfolio_changes = self._rebalance_portfolio(
                portfolio, daily_signals, daily_data, strategy_config
            )

            # è®°å½•äº¤æ˜“å†å²
            if portfolio_changes:
                trading_history.extend(portfolio_changes)

            # æ›´æ–°æŠ•èµ„ç»„åˆä»·å€¼
            portfolio.update_value(daily_data)

        return trading_history

    def _analyze_performance(self, trading_history: List[Dict]) -> Dict:
        """åˆ†æç­–ç•¥æ€§èƒ½"""

        # è®¡ç®—æ”¶ç›Šåºåˆ—
        returns = self._calculate_returns(trading_history)

        # åŸºç¡€æ€§èƒ½æŒ‡æ ‡
        total_return = self._calculate_total_return(returns)
        annualized_return = self._calculate_annualized_return(returns)
        volatility = self._calculate_volatility(returns)
        sharpe_ratio = self._calculate_sharpe_ratio(returns)

        # é«˜çº§æ€§èƒ½æŒ‡æ ‡
        sortino_ratio = self._calculate_sortino_ratio(returns)
        calmar_ratio = self._calculate_calmar_ratio(returns)
        max_drawdown = self._calculate_max_drawdown(returns)

        # èƒœç‡åˆ†æ
        win_rate = self._calculate_win_rate(trading_history)
        profit_factor = self._calculate_profit_factor(trading_history)

        return {
            "total_return": total_return,
            "annualized_return": annualized_return,
            "volatility": volatility,
            "sharpe_ratio": sharpe_ratio,
            "sortino_ratio": sortino_ratio,
            "calmar_ratio": calmar_ratio,
            "max_drawdown": max_drawdown,
            "win_rate": win_rate,
            "profit_factor": profit_factor,
            "total_trades": len(trading_history),
            "avg_holding_period": self._calculate_avg_holding_period(trading_history)
        }
```

è¿™äº›é«˜çº§ç¤ºä¾‹å±•ç¤ºäº† TradingAgents æ¡†æ¶çš„æ‰©å±•èƒ½åŠ›å’Œåœ¨å¤æ‚é‡‘èåº”ç”¨ä¸­çš„ä½¿ç”¨æ–¹æ³•ã€‚é€šè¿‡è¿™äº›ç¤ºä¾‹ï¼Œæ‚¨å¯ä»¥æ„å»ºæ›´åŠ å¤æ‚å’Œä¸“ä¸šçš„äº¤æ˜“ç³»ç»Ÿã€‚

<!-- docs/examples/basic-examples.md -->

# åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›äº† TradingAgents æ¡†æ¶çš„åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹å¹¶äº†è§£å„ç§åŠŸèƒ½çš„ä½¿ç”¨æ–¹æ³•ã€‚

## ç¤ºä¾‹ 1: åŸºæœ¬è‚¡ç¥¨åˆ†æ

### æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼
```python
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

# ä½¿ç”¨é»˜è®¤é…ç½®
ta = TradingAgentsGraph(debug=True, config=DEFAULT_CONFIG.copy())

# åˆ†æè‹¹æœå…¬å¸è‚¡ç¥¨
state, decision = ta.propagate("AAPL", "2024-01-15")

print(f"æ¨èåŠ¨ä½œ: {decision['action']}")
print(f"ç½®ä¿¡åº¦: {decision['confidence']:.2f}")
print(f"æ¨ç†: {decision['reasoning']}")
```

### è¾“å‡ºç¤ºä¾‹
```
æ¨èåŠ¨ä½œ: buy
ç½®ä¿¡åº¦: 0.75
æ¨ç†: åŸºäºå¼ºåŠ²çš„åŸºæœ¬é¢æ•°æ®å’Œç§¯æçš„æŠ€æœ¯æŒ‡æ ‡ï¼Œå»ºè®®ä¹°å…¥AAPLè‚¡ç¥¨...
```

## ç¤ºä¾‹ 2: è‡ªå®šä¹‰é…ç½®åˆ†æ

### é…ç½®ä¼˜åŒ–çš„åˆ†æ
```python
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

def analyze_with_custom_config(symbol, date):
    """ä½¿ç”¨è‡ªå®šä¹‰é…ç½®è¿›è¡Œåˆ†æ"""
    
    # åˆ›å»ºè‡ªå®šä¹‰é…ç½®
    config = DEFAULT_CONFIG.copy()
    config.update({
        "deep_think_llm": "gpt-4o-mini",      # ä½¿ç”¨ç»æµæ¨¡å‹
        "quick_think_llm": "gpt-4o-mini",     # ä½¿ç”¨ç»æµæ¨¡å‹
        "max_debate_rounds": 2,               # å¢åŠ è¾©è®ºè½®æ¬¡
        "max_risk_discuss_rounds": 1,         # é£é™©è®¨è®ºè½®æ¬¡
        "online_tools": True,                 # ä½¿ç”¨å®æ—¶æ•°æ®
    })
    
    # é€‰æ‹©ç‰¹å®šçš„åˆ†æå¸ˆ
    selected_analysts = ["market", "fundamentals", "news"]
    
    # åˆå§‹åŒ–åˆ†æå™¨
    ta = TradingAgentsGraph(
        selected_analysts=selected_analysts,
        debug=True,
        config=config
    )
    
    print(f"å¼€å§‹åˆ†æ {symbol} ({date})...")
    
    # æ‰§è¡Œåˆ†æ
    state, decision = ta.propagate(symbol, date)
    
    return state, decision

# ä½¿ç”¨ç¤ºä¾‹
state, decision = analyze_with_custom_config("TSLA", "2024-01-15")

print("\n=== åˆ†æç»“æœ ===")
print(f"è‚¡ç¥¨: TSLA")
print(f"åŠ¨ä½œ: {decision['action']}")
print(f"æ•°é‡: {decision.get('quantity', 0)}")
print(f"ç½®ä¿¡åº¦: {decision['confidence']:.1%}")
print(f"é£é™©è¯„åˆ†: {decision['risk_score']:.1%}")
```

## ç¤ºä¾‹ 3: æ‰¹é‡è‚¡ç¥¨åˆ†æ

### åˆ†æå¤šåªè‚¡ç¥¨
```python
import pandas as pd
from datetime import datetime, timedelta

def batch_analysis(symbols, date):
    """æ‰¹é‡åˆ†æå¤šåªè‚¡ç¥¨"""
    
    # é…ç½®
    config = DEFAULT_CONFIG.copy()
    config["max_debate_rounds"] = 1  # å‡å°‘è¾©è®ºè½®æ¬¡ä»¥æé«˜é€Ÿåº¦
    config["online_tools"] = True
    
    ta = TradingAgentsGraph(debug=False, config=config)
    
    results = []
    
    for symbol in symbols:
        try:
            print(f"æ­£åœ¨åˆ†æ {symbol}...")
            
            # æ‰§è¡Œåˆ†æ
            state, decision = ta.propagate(symbol, date)
            
            # æ”¶é›†ç»“æœ
            result = {
                "symbol": symbol,
                "action": decision.get("action", "hold"),
                "confidence": decision.get("confidence", 0.5),
                "risk_score": decision.get("risk_score", 0.5),
                "reasoning": decision.get("reasoning", "")[:100] + "..."  # æˆªå–å‰100å­—ç¬¦
            }
            
            results.append(result)
            print(f"âœ… {symbol}: {result['action']} (ç½®ä¿¡åº¦: {result['confidence']:.1%})")
            
        except Exception as e:
            print(f"âŒ {symbol}: åˆ†æå¤±è´¥ - {e}")
            results.append({
                "symbol": symbol,
                "action": "error",
                "confidence": 0.0,
                "risk_score": 1.0,
                "reasoning": f"åˆ†æå¤±è´¥: {e}"
            })
    
    return pd.DataFrame(results)

# ä½¿ç”¨ç¤ºä¾‹
tech_stocks = ["AAPL", "GOOGL", "MSFT", "TSLA", "NVDA"]
analysis_date = "2024-01-15"

results_df = batch_analysis(tech_stocks, analysis_date)

print("\n=== æ‰¹é‡åˆ†æç»“æœ ===")
print(results_df[["symbol", "action", "confidence", "risk_score"]])

# ç­›é€‰ä¹°å…¥å»ºè®®
buy_recommendations = results_df[results_df["action"] == "buy"]
print(f"\nä¹°å…¥å»ºè®® ({len(buy_recommendations)} åª):")
for _, row in buy_recommendations.iterrows():
    print(f"  {row['symbol']}: ç½®ä¿¡åº¦ {row['confidence']:.1%}")
```

## ç¤ºä¾‹ 4: ä¸åŒLLMæä¾›å•†å¯¹æ¯”

### å¯¹æ¯”ä¸åŒLLMçš„åˆ†æç»“æœ
```python
def compare_llm_providers(symbol, date):
    """å¯¹æ¯”ä¸åŒLLMæä¾›å•†çš„åˆ†æç»“æœ"""
    
    providers_config = {
        "OpenAI": {
            "llm_provider": "openai",
            "deep_think_llm": "gpt-4o-mini",
            "quick_think_llm": "gpt-4o-mini",
        },
        "Google": {
            "llm_provider": "google",
            "deep_think_llm": "gemini-pro",
            "quick_think_llm": "gemini-pro",
        },
        # æ³¨æ„: éœ€è¦ç›¸åº”çš„APIå¯†é’¥
    }
    
    results = {}
    
    for provider_name, provider_config in providers_config.items():
        try:
            print(f"ä½¿ç”¨ {provider_name} åˆ†æ {symbol}...")
            
            # åˆ›å»ºé…ç½®
            config = DEFAULT_CONFIG.copy()
            config.update(provider_config)
            config["max_debate_rounds"] = 1
            
            # åˆå§‹åŒ–åˆ†æå™¨
            ta = TradingAgentsGraph(debug=False, config=config)
            
            # æ‰§è¡Œåˆ†æ
            state, decision = ta.propagate(symbol, date)
            
            results[provider_name] = {
                "action": decision.get("action", "hold"),
                "confidence": decision.get("confidence", 0.5),
                "risk_score": decision.get("risk_score", 0.5),
            }
            
            print(f"âœ… {provider_name}: {results[provider_name]['action']}")
            
        except Exception as e:
            print(f"âŒ {provider_name}: å¤±è´¥ - {e}")
            results[provider_name] = {"error": str(e)}
    
    return results

# ä½¿ç”¨ç¤ºä¾‹
comparison_results = compare_llm_providers("AAPL", "2024-01-15")

print("\n=== LLMæä¾›å•†å¯¹æ¯”ç»“æœ ===")
for provider, result in comparison_results.items():
    if "error" not in result:
        print(f"{provider}:")
        print(f"  åŠ¨ä½œ: {result['action']}")
        print(f"  ç½®ä¿¡åº¦: {result['confidence']:.1%}")
        print(f"  é£é™©è¯„åˆ†: {result['risk_score']:.1%}")
    else:
        print(f"{provider}: é”™è¯¯ - {result['error']}")
```

## ç¤ºä¾‹ 5: å†å²å›æµ‹åˆ†æ

### ç®€å•çš„å†å²å›æµ‹
```python
from datetime import datetime, timedelta
import matplotlib.pyplot as plt

def historical_backtest(symbol, start_date, end_date, interval_days=7):
    """ç®€å•çš„å†å²å›æµ‹"""
    
    # é…ç½®
    config = DEFAULT_CONFIG.copy()
    config["max_debate_rounds"] = 1
    config["online_tools"] = True
    
    ta = TradingAgentsGraph(debug=False, config=config)
    
    # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨
    current_date = datetime.strptime(start_date, "%Y-%m-%d")
    end_date_obj = datetime.strptime(end_date, "%Y-%m-%d")
    
    results = []
    
    while current_date <= end_date_obj:
        date_str = current_date.strftime("%Y-%m-%d")
        
        try:
            print(f"åˆ†æ {symbol} åœ¨ {date_str}...")
            
            # æ‰§è¡Œåˆ†æ
            state, decision = ta.propagate(symbol, date_str)
            
            result = {
                "date": date_str,
                "action": decision.get("action", "hold"),
                "confidence": decision.get("confidence", 0.5),
                "risk_score": decision.get("risk_score", 0.5),
            }
            
            results.append(result)
            print(f"  {result['action']} (ç½®ä¿¡åº¦: {result['confidence']:.1%})")
            
        except Exception as e:
            print(f"  é”™è¯¯: {e}")
        
        # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªæ—¥æœŸ
        current_date += timedelta(days=interval_days)
    
    return pd.DataFrame(results)

# ä½¿ç”¨ç¤ºä¾‹
backtest_results = historical_backtest(
    symbol="AAPL",
    start_date="2024-01-01",
    end_date="2024-01-31",
    interval_days=7
)

print("\n=== å†å²å›æµ‹ç»“æœ ===")
print(backtest_results)

# ç»Ÿè®¡åˆ†æ
action_counts = backtest_results["action"].value_counts()
print(f"\nåŠ¨ä½œåˆ†å¸ƒ:")
for action, count in action_counts.items():
    print(f"  {action}: {count} æ¬¡")

avg_confidence = backtest_results["confidence"].mean()
print(f"\nå¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.1%}")
```

## ç¤ºä¾‹ 6: å®æ—¶ç›‘æ§

### å®æ—¶è‚¡ç¥¨ç›‘æ§
```python
import time
from datetime import datetime

def real_time_monitor(symbols, check_interval=300):
    """å®æ—¶ç›‘æ§è‚¡ç¥¨"""
    
    config = DEFAULT_CONFIG.copy()
    config["max_debate_rounds"] = 1
    config["online_tools"] = True
    
    ta = TradingAgentsGraph(debug=False, config=config)
    
    print(f"å¼€å§‹ç›‘æ§ {len(symbols)} åªè‚¡ç¥¨...")
    print(f"æ£€æŸ¥é—´éš”: {check_interval} ç§’")
    print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§\n")
    
    try:
        while True:
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            current_date = datetime.now().strftime("%Y-%m-%d")
            
            print(f"=== {current_time} ===")
            
            for symbol in symbols:
                try:
                    # æ‰§è¡Œåˆ†æ
                    state, decision = ta.propagate(symbol, current_date)
                    
                    action = decision.get("action", "hold")
                    confidence = decision.get("confidence", 0.5)
                    
                    # è¾“å‡ºç»“æœ
                    status_emoji = "ğŸŸ¢" if action == "buy" else "ğŸ”´" if action == "sell" else "ğŸŸ¡"
                    print(f"{status_emoji} {symbol}: {action.upper()} (ç½®ä¿¡åº¦: {confidence:.1%})")
                    
                    # é«˜ç½®ä¿¡åº¦ä¹°å…¥/å–å‡ºæé†’
                    if confidence > 0.8 and action in ["buy", "sell"]:
                        print(f"  âš ï¸  é«˜ç½®ä¿¡åº¦{action}ä¿¡å·!")
                
                except Exception as e:
                    print(f"âŒ {symbol}: åˆ†æå¤±è´¥ - {e}")
            
            print(f"ä¸‹æ¬¡æ£€æŸ¥: {check_interval} ç§’å\n")
            time.sleep(check_interval)
    
    except KeyboardInterrupt:
        print("\nç›‘æ§å·²åœæ­¢")

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆæ³¨é‡Šæ‰ä»¥é¿å…é•¿æ—¶é—´è¿è¡Œï¼‰
# watch_list = ["AAPL", "GOOGL", "TSLA"]
# real_time_monitor(watch_list, check_interval=300)  # æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
```

## ç¤ºä¾‹ 7: é”™è¯¯å¤„ç†å’Œé‡è¯•

### å¥å£®çš„åˆ†æå‡½æ•°
```python
import time
from typing import Optional, Tuple

def robust_analysis(symbol: str, date: str, max_retries: int = 3) -> Optional[Tuple[dict, dict]]:
    """å¸¦é”™è¯¯å¤„ç†å’Œé‡è¯•çš„åˆ†æå‡½æ•°"""
    
    config = DEFAULT_CONFIG.copy()
    config["max_debate_rounds"] = 1
    
    for attempt in range(max_retries):
        try:
            print(f"åˆ†æ {symbol} (å°è¯• {attempt + 1}/{max_retries})...")
            
            ta = TradingAgentsGraph(debug=False, config=config)
            state, decision = ta.propagate(symbol, date)
            
            # éªŒè¯ç»“æœ
            if not decision or "action" not in decision:
                raise ValueError("åˆ†æç»“æœæ— æ•ˆ")
            
            print(f"âœ… åˆ†ææˆåŠŸ: {decision['action']}")
            return state, decision
            
        except Exception as e:
            print(f"âŒ å°è¯• {attempt + 1} å¤±è´¥: {e}")
            
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                print(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                print(f"æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†")
                return None

# ä½¿ç”¨ç¤ºä¾‹
result = robust_analysis("AAPL", "2024-01-15", max_retries=3)

if result:
    state, decision = result
    print(f"æœ€ç»ˆç»“æœ: {decision['action']}")
else:
    print("åˆ†æå¤±è´¥")
```

## ç¤ºä¾‹ 8: ç»“æœä¿å­˜å’ŒåŠ è½½

### ä¿å­˜åˆ†æç»“æœ
```python
import json
import pickle
from datetime import datetime

def save_analysis_result(symbol, date, state, decision, format="json"):
    """ä¿å­˜åˆ†æç»“æœ"""
    
    # åˆ›å»ºç»“æœç›®å½•
    import os
    results_dir = "analysis_results"
    os.makedirs(results_dir, exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{symbol}_{date}_{timestamp}"
    
    # å‡†å¤‡æ•°æ®
    result_data = {
        "symbol": symbol,
        "date": date,
        "timestamp": timestamp,
        "decision": decision,
        "state_summary": {
            "analyst_reports": getattr(state, "analyst_reports", {}),
            "research_reports": getattr(state, "research_reports", {}),
            "trader_decision": getattr(state, "trader_decision", {}),
            "risk_assessment": getattr(state, "risk_assessment", {}),
        }
    }
    
    if format == "json":
        filepath = os.path.join(results_dir, f"{filename}.json")
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(result_data, f, indent=2, ensure_ascii=False)
    
    elif format == "pickle":
        filepath = os.path.join(results_dir, f"{filename}.pkl")
        with open(filepath, "wb") as f:
            pickle.dump(result_data, f)
    
    print(f"ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
    return filepath

# ä½¿ç”¨ç¤ºä¾‹
ta = TradingAgentsGraph(debug=False, config=DEFAULT_CONFIG.copy())
state, decision = ta.propagate("AAPL", "2024-01-15")

# ä¿å­˜ç»“æœ
save_analysis_result("AAPL", "2024-01-15", state, decision, format="json")
```

è¿™äº›åŸºæœ¬ç¤ºä¾‹å±•ç¤ºäº† TradingAgents æ¡†æ¶çš„ä¸»è¦åŠŸèƒ½å’Œä½¿ç”¨æ¨¡å¼ã€‚æ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚ä¿®æ”¹å’Œæ‰©å±•è¿™äº›ç¤ºä¾‹ã€‚


<!-- docs/faq/faq.md -->

# å¸¸è§é—®é¢˜è§£ç­” (FAQ)

## æ¦‚è¿°

æœ¬æ–‡æ¡£æ”¶é›†äº†ç”¨æˆ·åœ¨ä½¿ç”¨ TradingAgents æ¡†æ¶æ—¶æœ€å¸¸é‡åˆ°çš„é—®é¢˜å’Œè§£ç­”ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿè§£å†³å¸¸è§é—®é¢˜ã€‚

## ğŸš€ å®‰è£…å’Œé…ç½®

### Q1: å®‰è£…æ—¶å‡ºç°ä¾èµ–å†²çªæ€ä¹ˆåŠï¼Ÿ

**A:** ä¾èµ–å†²çªé€šå¸¸æ˜¯ç”±äºä¸åŒåŒ…çš„ç‰ˆæœ¬è¦æ±‚ä¸å…¼å®¹å¯¼è‡´çš„ã€‚è§£å†³æ–¹æ³•ï¼š

```bash
# æ–¹æ³•1: ä½¿ç”¨æ–°çš„è™šæ‹Ÿç¯å¢ƒ
conda create -n tradingagents-clean python=3.11
conda activate tradingagents-clean
pip install -r requirements.txt

# æ–¹æ³•2: ä½¿ç”¨ pip-tools è§£å†³å†²çª
pip install pip-tools
pip-compile requirements.in
pip-sync requirements.txt

# æ–¹æ³•3: é€ä¸ªå®‰è£…æ ¸å¿ƒä¾èµ–
pip install langchain-openai langgraph finnhub-python pandas
```

### Q2: API å¯†é’¥è®¾ç½®åä»ç„¶æŠ¥é”™ï¼Ÿ

**A:** æ£€æŸ¥ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š

1. **ç¯å¢ƒå˜é‡è®¾ç½®**ï¼š
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
echo $OPENAI_API_KEY
echo $FINNHUB_API_KEY

# Windows ç”¨æˆ·
echo %OPENAI_API_KEY%
echo %FINNHUB_API_KEY%
```

2. **å¯†é’¥æ ¼å¼éªŒè¯**ï¼š
```python
import os
# OpenAI å¯†é’¥åº”è¯¥ä»¥ 'sk-' å¼€å¤´
openai_key = os.getenv('OPENAI_API_KEY')
print(f"OpenAI Key: {openai_key[:10]}..." if openai_key else "Not set")

# FinnHub å¯†é’¥æ˜¯å­—æ¯æ•°å­—ç»„åˆ
finnhub_key = os.getenv('FINNHUB_API_KEY')
print(f"FinnHub Key: {finnhub_key[:10]}..." if finnhub_key else "Not set")
```

3. **æƒé™æ£€æŸ¥**ï¼š
```python
# æµ‹è¯• API è¿æ¥
import openai
import finnhub

# æµ‹è¯• OpenAI
try:
    client = openai.OpenAI()
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": "Hello"}],
        max_tokens=5
    )
    print("OpenAI API è¿æ¥æˆåŠŸ")
except Exception as e:
    print(f"OpenAI API é”™è¯¯: {e}")

# æµ‹è¯• FinnHub
try:
    finnhub_client = finnhub.Client(api_key=os.getenv('FINNHUB_API_KEY'))
    quote = finnhub_client.quote('AAPL')
    print("FinnHub API è¿æ¥æˆåŠŸ")
except Exception as e:
    print(f"FinnHub API é”™è¯¯: {e}")
```

### Q3: æ”¯æŒå“ªäº› Python ç‰ˆæœ¬ï¼Ÿ

**A:** TradingAgents æ”¯æŒ Python 3.10, 3.11, å’Œ 3.12ã€‚æ¨èä½¿ç”¨ Python 3.11 ä»¥è·å¾—æœ€ä½³æ€§èƒ½å’Œå…¼å®¹æ€§ã€‚

```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬
python --version

# å¦‚æœç‰ˆæœ¬ä¸ç¬¦åˆè¦æ±‚ï¼Œä½¿ç”¨ pyenv å®‰è£…
pyenv install 3.11.7
pyenv global 3.11.7
```

## ğŸ’° æˆæœ¬å’Œä½¿ç”¨

### Q4: ä½¿ç”¨ TradingAgents çš„æˆæœ¬æ˜¯å¤šå°‘ï¼Ÿ

**A:** æˆæœ¬ä¸»è¦æ¥è‡ª LLM API è°ƒç”¨ï¼š

**å…¸å‹æˆæœ¬ä¼°ç®—**ï¼ˆå•æ¬¡åˆ†æï¼‰ï¼š
- **ç»æµæ¨¡å¼**ï¼š$0.01-0.05ï¼ˆä½¿ç”¨ gpt-4o-miniï¼‰
- **æ ‡å‡†æ¨¡å¼**ï¼š$0.05-0.15ï¼ˆä½¿ç”¨ gpt-4oï¼‰
- **é«˜ç²¾åº¦æ¨¡å¼**ï¼š$0.10-0.30ï¼ˆä½¿ç”¨ gpt-4o + å¤šè½®è¾©è®ºï¼‰

**æˆæœ¬ä¼˜åŒ–å»ºè®®**ï¼š
```python
# ä½æˆæœ¬é…ç½®
cost_optimized_config = {
    "deep_think_llm": "gpt-4o-mini",
    "quick_think_llm": "gpt-4o-mini",
    "max_debate_rounds": 1,
    "max_risk_discuss_rounds": 1,
    "online_tools": False  # ä½¿ç”¨ç¼“å­˜æ•°æ®
}
```

### Q5: å¦‚ä½•æ§åˆ¶ API è°ƒç”¨æˆæœ¬ï¼Ÿ

**A:** å¤šç§æˆæœ¬æ§åˆ¶ç­–ç•¥ï¼š

1. **è®¾ç½®é¢„ç®—é™åˆ¶**ï¼š
```python
class BudgetController:
    def __init__(self, daily_budget=50):
        self.daily_budget = daily_budget
        self.current_usage = 0
    
    def check_budget(self, estimated_cost):
        if self.current_usage + estimated_cost > self.daily_budget:
            raise Exception("Daily budget exceeded")
        return True
```

2. **ä½¿ç”¨ç¼“å­˜**ï¼š
```python
config = {
    "online_tools": False,  # ä½¿ç”¨ç¼“å­˜æ•°æ®
    "cache_duration": 3600  # 1å°æ—¶ç¼“å­˜
}
```

3. **é€‰æ‹©æ€§åˆ†æå¸ˆ**ï¼š
```python
# åªä½¿ç”¨æ ¸å¿ƒåˆ†æå¸ˆ
selected_analysts = ["market", "fundamentals"]  # è€Œä¸æ˜¯å…¨éƒ¨å››ä¸ª
```

## ğŸ”§ æŠ€æœ¯é—®é¢˜

### Q6: åˆ†æé€Ÿåº¦å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

**A:** å¤šç§ä¼˜åŒ–æ–¹æ³•ï¼š

1. **å¹¶è¡Œå¤„ç†**ï¼š
```python
config = {
    "parallel_analysis": True,
    "max_workers": 4
}
```

2. **ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹**ï¼š
```python
config = {
    "deep_think_llm": "gpt-4o-mini",  # æ›´å¿«çš„æ¨¡å‹
    "quick_think_llm": "gpt-4o-mini"
}
```

3. **å‡å°‘è¾©è®ºè½®æ¬¡**ï¼š
```python
config = {
    "max_debate_rounds": 1,
    "max_risk_discuss_rounds": 1
}
```

4. **å¯ç”¨ç¼“å­˜**ï¼š
```python
config = {
    "online_tools": True,
    "cache_enabled": True
}
```

### Q7: å†…å­˜ä½¿ç”¨è¿‡é«˜æ€ä¹ˆè§£å†³ï¼Ÿ

**A:** å†…å­˜ä¼˜åŒ–ç­–ç•¥ï¼š

1. **é™åˆ¶ç¼“å­˜å¤§å°**ï¼š
```python
config = {
    "memory_cache": {
        "max_size": 500,  # å‡å°‘ç¼“å­˜é¡¹æ•°é‡
        "cleanup_threshold": 0.7
    }
}
```

2. **åˆ†æ‰¹å¤„ç†**ï¼š
```python
# åˆ†æ‰¹åˆ†æå¤šåªè‚¡ç¥¨
def batch_analysis(symbols, batch_size=5):
    for i in range(0, len(symbols), batch_size):
        batch = symbols[i:i+batch_size]
        # å¤„ç†æ‰¹æ¬¡
        yield analyze_batch(batch)
```

3. **æ¸…ç†èµ„æº**ï¼š
```python
import gc

def analyze_with_cleanup(symbol, date):
    try:
        result = ta.propagate(symbol, date)
        return result
    finally:
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
```

### Q8: ç½‘ç»œè¿æ¥ä¸ç¨³å®šå¯¼è‡´åˆ†æå¤±è´¥ï¼Ÿ

**A:** ç½‘ç»œé—®é¢˜è§£å†³æ–¹æ¡ˆï¼š

1. **é‡è¯•æœºåˆ¶**ï¼š
```python
import time
from functools import wraps

def retry_on_failure(max_retries=3, delay=1):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    time.sleep(delay * (2 ** attempt))
            return None
        return wrapper
    return decorator

@retry_on_failure(max_retries=3)
def robust_analysis(symbol, date):
    return ta.propagate(symbol, date)
```

2. **è¶…æ—¶è®¾ç½®**ï¼š
```python
config = {
    "timeout": 60,  # 60ç§’è¶…æ—¶
    "connect_timeout": 10
}
```

3. **ä»£ç†è®¾ç½®**ï¼š
```python
import os
os.environ['HTTP_PROXY'] = 'http://proxy.company.com:8080'
os.environ['HTTPS_PROXY'] = 'https://proxy.company.com:8080'
```

## ğŸ“Š æ•°æ®å’Œåˆ†æ

### Q9: æŸäº›è‚¡ç¥¨æ— æ³•è·å–æ•°æ®ï¼Ÿ

**A:** æ•°æ®è·å–é—®é¢˜æ’æŸ¥ï¼š

1. **æ£€æŸ¥è‚¡ç¥¨ä»£ç **ï¼š
```python
# ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è‚¡ç¥¨ä»£ç æ ¼å¼
symbols = {
    "US": "AAPL",           # ç¾è‚¡
    "HK": "0700.HK",        # æ¸¯è‚¡
    "CN": "000001.SZ"       # Aè‚¡
}
```

2. **éªŒè¯æ•°æ®æº**ï¼š
```python
def check_data_availability(symbol):
    try:
        # æ£€æŸ¥ FinnHub
        finnhub_data = finnhub_client.quote(symbol)
        print(f"FinnHub: {symbol} - OK")
    except:
        print(f"FinnHub: {symbol} - Failed")
    
    try:
        # æ£€æŸ¥ Yahoo Finance
        import yfinance as yf
        ticker = yf.Ticker(symbol)
        info = ticker.info
        print(f"Yahoo: {symbol} - OK")
    except:
        print(f"Yahoo: {symbol} - Failed")
```

3. **ä½¿ç”¨å¤‡ç”¨æ•°æ®æº**ï¼š
```python
config = {
    "data_sources": {
        "primary": "finnhub",
        "fallback": ["yahoo", "alpha_vantage"]
    }
}
```

### Q10: åˆ†æç»“æœä¸å‡†ç¡®æˆ–ä¸åˆç†ï¼Ÿ

**A:** æé«˜åˆ†æå‡†ç¡®æ€§çš„æ–¹æ³•ï¼š

1. **å¢åŠ è¾©è®ºè½®æ¬¡**ï¼š
```python
config = {
    "max_debate_rounds": 3,  # å¢åŠ è¾©è®ºè½®æ¬¡
    "max_risk_discuss_rounds": 2
}
```

2. **ä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹**ï¼š
```python
config = {
    "deep_think_llm": "gpt-4o",  # ä½¿ç”¨æ›´å¼ºçš„æ¨¡å‹
    "quick_think_llm": "gpt-4o-mini"
}
```

3. **è°ƒæ•´åˆ†æå¸ˆæƒé‡**ï¼š
```python
config = {
    "analyst_weights": {
        "fundamentals": 0.4,  # å¢åŠ åŸºæœ¬é¢æƒé‡
        "technical": 0.3,
        "news": 0.2,
        "social": 0.1
    }
}
```

4. **å¯ç”¨æ›´å¤šæ•°æ®æº**ï¼š
```python
config = {
    "online_tools": True,
    "data_sources": ["finnhub", "yahoo", "reddit", "google_news"]
}
```

## ğŸ› ï¸ å¼€å‘å’Œæ‰©å±•

### Q11: å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰æ™ºèƒ½ä½“ï¼Ÿ

**A:** åˆ›å»ºè‡ªå®šä¹‰æ™ºèƒ½ä½“çš„æ­¥éª¤ï¼š

1. **ç»§æ‰¿åŸºç¡€ç±»**ï¼š
```python
from tradingagents.agents.analysts.base_analyst import BaseAnalyst

class CustomAnalyst(BaseAnalyst):
    def __init__(self, llm, config):
        super().__init__(llm, config)
        self.custom_tools = self._initialize_custom_tools()
    
    def perform_analysis(self, data: Dict) -> Dict:
        # å®ç°è‡ªå®šä¹‰åˆ†æé€»è¾‘
        return {
            "custom_score": 0.75,
            "custom_insights": ["insight1", "insight2"],
            "recommendation": "buy"
        }
```

2. **æ³¨å†Œåˆ°æ¡†æ¶**ï¼š
```python
# åœ¨é…ç½®ä¸­æ·»åŠ è‡ªå®šä¹‰æ™ºèƒ½ä½“
config = {
    "custom_analysts": {
        "custom": CustomAnalyst
    }
}
```

### Q12: å¦‚ä½•é›†æˆæ–°çš„æ•°æ®æºï¼Ÿ

**A:** é›†æˆæ–°æ•°æ®æºçš„æ–¹æ³•ï¼š

1. **åˆ›å»ºæ•°æ®æä¾›å™¨**ï¼š
```python
class CustomDataProvider:
    def __init__(self, api_key):
        self.api_key = api_key
    
    def get_data(self, symbol):
        # å®ç°æ•°æ®è·å–é€»è¾‘
        return {"custom_metric": 0.85}
```

2. **æ³¨å†Œæ•°æ®æº**ï¼š
```python
config = {
    "custom_data_sources": {
        "custom_provider": CustomDataProvider
    }
}
```

## ğŸš¨ é”™è¯¯å¤„ç†

### Q13: å¸¸è§é”™è¯¯ä»£ç åŠè§£å†³æ–¹æ³•

**A:** ä¸»è¦é”™è¯¯ç±»å‹å’Œè§£å†³æ–¹æ¡ˆï¼š

| é”™è¯¯ç±»å‹ | åŸå›  | è§£å†³æ–¹æ³• |
|---------|------|---------|
| `API_KEY_INVALID` | APIå¯†é’¥æ— æ•ˆ | æ£€æŸ¥å¯†é’¥æ ¼å¼å’Œæƒé™ |
| `RATE_LIMIT_EXCEEDED` | è¶…è¿‡APIé™åˆ¶ | é™ä½è°ƒç”¨é¢‘ç‡æˆ–å‡çº§è´¦æˆ· |
| `NETWORK_TIMEOUT` | ç½‘ç»œè¶…æ—¶ | æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´ |
| `DATA_NOT_FOUND` | æ•°æ®ä¸å­˜åœ¨ | æ£€æŸ¥è‚¡ç¥¨ä»£ç ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®æº |
| `INSUFFICIENT_MEMORY` | å†…å­˜ä¸è¶³ | å‡å°‘ç¼“å­˜å¤§å°ï¼Œåˆ†æ‰¹å¤„ç† |

### Q14: å¦‚ä½•å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Ÿ

**A:** è°ƒè¯•æ¨¡å¼é…ç½®ï¼š

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# å¯ç”¨è°ƒè¯•æ¨¡å¼
config = {
    "debug": True,
    "log_level": "DEBUG",
    "save_intermediate_results": True
}

# ä½¿ç”¨è°ƒè¯•é…ç½®
ta = TradingAgentsGraph(debug=True, config=config)
```

## ğŸ“ è·å–å¸®åŠ©

### Q15: åœ¨å“ªé‡Œå¯ä»¥è·å¾—æ›´å¤šå¸®åŠ©ï¼Ÿ

**A:** å¤šç§è·å–å¸®åŠ©çš„æ¸ é“ï¼š

1. **å®˜æ–¹æ–‡æ¡£**: [docs/README.md](../README.md)
2. **GitHub Issues**: [æäº¤é—®é¢˜](https://github.com/TauricResearch/TradingAgents/issues)
3. **Discord ç¤¾åŒº**: [åŠ å…¥è®¨è®º](https://discord.com/invite/hk9PGKShPK)
4. **é‚®ç®±æ”¯æŒ**: support@tauric.ai

### Q16: å¦‚ä½•æŠ¥å‘Š Bugï¼Ÿ

**A:** Bug æŠ¥å‘Šæ¨¡æ¿ï¼š

```markdown
## Bug æè¿°
ç®€è¦æè¿°é‡åˆ°çš„é—®é¢˜

## å¤ç°æ­¥éª¤
1. æ‰§è¡Œçš„ä»£ç 
2. ä½¿ç”¨çš„é…ç½®
3. è¾“å…¥çš„å‚æ•°

## é¢„æœŸè¡Œä¸º
æè¿°æœŸæœ›çš„ç»“æœ

## å®é™…è¡Œä¸º
æè¿°å®é™…å‘ç”Ÿçš„æƒ…å†µ

## ç¯å¢ƒä¿¡æ¯
- Python ç‰ˆæœ¬:
- TradingAgents ç‰ˆæœ¬:
- æ“ä½œç³»ç»Ÿ:
- ç›¸å…³ä¾èµ–ç‰ˆæœ¬:

## é”™è¯¯æ—¥å¿—
ç²˜è´´å®Œæ•´çš„é”™è¯¯ä¿¡æ¯
```

å¦‚æœæ‚¨çš„é—®é¢˜æ²¡æœ‰åœ¨è¿™é‡Œæ‰¾åˆ°ç­”æ¡ˆï¼Œè¯·é€šè¿‡ä¸Šè¿°æ¸ é“è”ç³»æˆ‘ä»¬è·å–å¸®åŠ©ã€‚


<!-- docs/guides/a-share-analysis-guide.md -->

# Aè‚¡åˆ†æä½¿ç”¨æŒ‡å—

## ğŸ¯ æ¦‚è¿°

TradingAgents-CN v0.1.3 æ–°å¢äº†å®Œæ•´çš„Aè‚¡å¸‚åœºæ”¯æŒï¼Œé€šè¿‡é›†æˆé€šè¾¾ä¿¡APIï¼Œä¸ºç”¨æˆ·æä¾›å®æ—¶çš„Aè‚¡æ•°æ®åˆ†æèƒ½åŠ›ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¡®ä¿ç¯å¢ƒé…ç½®

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
.\env\Scripts\Activate.ps1  # Windows
source env/bin/activate     # Linux/macOS

# ç¡®ä¿å·²å®‰è£…é€šè¾¾ä¿¡APIæ”¯æŒ
pip install pytdx
```

### 2. å¯åŠ¨Webç•Œé¢

```bash
python -m streamlit run web/app.py
```

### 3. é€‰æ‹©Aè‚¡å¸‚åœº

åœ¨Webç•Œé¢ä¸­ï¼š
1. åœ¨"é€‰æ‹©å¸‚åœº"ä¸‹æ‹‰æ¡†ä¸­é€‰æ‹© **"Aè‚¡"**
2. åœ¨è‚¡ç¥¨ä»£ç è¾“å…¥æ¡†ä¸­è¾“å…¥Aè‚¡ä»£ç 
3. é€‰æ‹©åˆ†æå¸ˆå’Œç ”ç©¶æ·±åº¦
4. ç‚¹å‡»"å¼€å§‹åˆ†æ"

## ğŸ“Š æ”¯æŒçš„Aè‚¡ä»£ç æ ¼å¼

### ä¸»è¦æ¿å—ä»£ç è§„åˆ™

| ä»£ç å‰ç¼€ | å¸‚åœºæ¿å— | ç¤ºä¾‹ä»£ç  | è‚¡ç¥¨åç§° |
|----------|----------|----------|----------|
| **000xxx** | æ·±åœ³ä¸»æ¿ | 000001 | å¹³å®‰é“¶è¡Œ |
| **002xxx** | æ·±åœ³ä¸­å°æ¿ | 002415 | æµ·åº·å¨è§† |
| **003xxx** | æ·±åœ³ä¸»æ¿ | 003816 | ä¸­å›½å¹¿æ ¸ |
| **300xxx** | åˆ›ä¸šæ¿ | 300750 | å®å¾·æ—¶ä»£ |
| **600xxx** | ä¸Šæµ·ä¸»æ¿ | 600519 | è´µå·èŒ…å° |
| **601xxx** | ä¸Šæµ·ä¸»æ¿ | 601318 | ä¸­å›½å¹³å®‰ |
| **603xxx** | ä¸Šæµ·ä¸»æ¿ | 603259 | è¯æ˜åº·å¾· |
| **688xxx** | ç§‘åˆ›æ¿ | 688981 | ä¸­èŠ¯å›½é™… |

### çƒ­é—¨è‚¡ç¥¨ä»£ç ç¤ºä¾‹

#### ğŸ¦ é“¶è¡Œè‚¡
- `000001` - å¹³å®‰é“¶è¡Œ
- `600036` - æ‹›å•†é“¶è¡Œ
- `601398` - å·¥å•†é“¶è¡Œ
- `601288` - å†œä¸šé“¶è¡Œ

#### ğŸ· ç™½é…’è‚¡
- `600519` - è´µå·èŒ…å°
- `000858` - äº”ç²®æ¶²
- `000568` - æ³¸å·è€çª–
- `002304` - æ´‹æ²³è‚¡ä»½

#### ğŸ”‹ æ–°èƒ½æº
- `300750` - å®å¾·æ—¶ä»£
- `002594` - æ¯”äºšè¿ª
- `300274` - é˜³å…‰ç”µæº
- `002460` - èµ£é”‹é”‚ä¸š

#### ğŸ’» ç§‘æŠ€è‚¡
- `000002` - ä¸‡ç§‘A
- `000651` - æ ¼åŠ›ç”µå™¨
- `002415` - æµ·åº·å¨è§†
- `000725` - äº¬ä¸œæ–¹A

## ğŸ”§ æ•°æ®æºè¯´æ˜

### é€šè¾¾ä¿¡APIä¼˜åŠ¿

| ç‰¹æ€§ | é€šè¾¾ä¿¡API | Yahoo Finance | ä¼˜åŠ¿è¯´æ˜ |
|------|-----------|---------------|----------|
| **Aè‚¡è¦†ç›–** | âœ… å®Œæ•´è¦†ç›– | âŒ ä¸æ”¯æŒ | ç‹¬æœ‰çš„Aè‚¡æ•°æ®æº |
| **å®æ—¶æ€§** | âœ… ç§’çº§æ›´æ–° | âš ï¸ 15åˆ†é’Ÿå»¶è¿Ÿ | é€‚åˆæ—¥å†…äº¤æ˜“åˆ†æ |
| **ä¸­æ–‡æ”¯æŒ** | âœ… åŸç”Ÿä¸­æ–‡ | âŒ è‹±æ–‡ä¸ºä¸» | è‚¡ç¥¨åç§°ã€æ¿å—ä¸­æ–‡æ˜¾ç¤º |
| **æˆæœ¬** | âœ… å®Œå…¨å…è´¹ | âœ… å…è´¹ | æ— APIè°ƒç”¨é™åˆ¶ |
| **é…ç½®å¤æ‚åº¦** | âœ… é›¶é…ç½® | âœ… é›¶é…ç½® | å³è£…å³ç”¨ |

### å¯ç”¨æœåŠ¡å™¨

ç³»ç»Ÿè‡ªåŠ¨ä½¿ç”¨ç»è¿‡æµ‹è¯•çš„å¯ç”¨æœåŠ¡å™¨ï¼š
- æ­¦æ±‰ç”µä¿¡ä¸»ç«™1 (119.97.185.59:7709)
- å¹¿å·åŒçº¿ä¸»ç«™7 (116.205.183.150:7709)
- å¹¿å·åŒçº¿ä¸»ç«™6 (116.205.171.132:7709)
- åŒ—äº¬åŒçº¿ä¸»ç«™4 (124.70.75.113:7709)
- ç­‰10ä¸ªéªŒè¯å¯ç”¨çš„æœåŠ¡å™¨

## ğŸ“ˆ åˆ†æåŠŸèƒ½ç‰¹è‰²

### 1. å®æ—¶è¡Œæƒ…æ•°æ®

- **å½“å‰ä»·æ ¼**: å®æ—¶è‚¡ä»·æ›´æ–°
- **æ¶¨è·Œå¹…**: å½“æ—¥æ¶¨è·Œå¹…åº¦å’Œæ¶¨è·Œé‡‘é¢
- **æˆäº¤é‡**: å®æ—¶æˆäº¤é‡å’Œæˆäº¤é¢
- **äº”æ¡£ä¹°å–**: ä¹°ä¸€åˆ°ä¹°äº”ã€å–ä¸€åˆ°å–äº”ä»·æ ¼å’Œæ•°é‡

### 2. å†å²æ•°æ®åˆ†æ

- **Kçº¿æ•°æ®**: æ—¥çº¿ã€å‘¨çº¿ã€æœˆçº¿å†å²æ•°æ®
- **æŠ€æœ¯æŒ‡æ ‡**: MAã€RSIã€MACDã€å¸ƒæ—å¸¦ç­‰
- **ä»·æ ¼èµ°åŠ¿**: å†å²ä»·æ ¼å˜åŒ–è¶‹åŠ¿åˆ†æ
- **æˆäº¤é‡åˆ†æ**: é‡ä»·å…³ç³»åˆ†æ

### 3. Aè‚¡ç‰¹è‰²åˆ†æ

- **æ¶¨è·Œåœåˆ†æ**: è¯†åˆ«æ¶¨åœã€è·Œåœç­‰Aè‚¡ç‰¹æœ‰ç°è±¡
- **STè‚¡ç¥¨è¯†åˆ«**: ç‰¹åˆ«å¤„ç†è‚¡ç¥¨çš„é£é™©æç¤º
- **æ¿å—è½®åŠ¨**: Aè‚¡ç‰¹æœ‰çš„æ¿å—è½®åŠ¨è§„å¾‹åˆ†æ
- **æ”¿ç­–å½±å“**: ä¸­å›½æ”¿ç­–å¯¹è‚¡ä»·çš„å½±å“åˆ†æ

## ğŸ• äº¤æ˜“æ—¶é—´è¯´æ˜

### Aè‚¡äº¤æ˜“æ—¶é—´

- **ä¸Šåˆ**: 09:30 - 11:30
- **ä¸‹åˆ**: 13:00 - 15:00
- **ä¼‘å¸‚**: å‘¨æœ«ã€æ³•å®šèŠ‚å‡æ—¥

### æ•°æ®è·å–è¯´æ˜

| æ—¶é—´æ®µ | æ•°æ®ç±»å‹ | è¯´æ˜ |
|--------|----------|------|
| **äº¤æ˜“æ—¶é—´** | å®æ—¶æ•°æ® | ç§’çº§æ›´æ–°çš„å®æ—¶è¡Œæƒ… |
| **éäº¤æ˜“æ—¶é—´** | æ”¶ç›˜æ•°æ® | æ˜¾ç¤ºæœ€åäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»· |
| **å‘¨æœ«/èŠ‚å‡æ—¥** | å†å²æ•°æ® | å¯è·å–å†å²Kçº¿å’ŒæŠ€æœ¯æŒ‡æ ‡ |

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: åˆ†æè´µå·èŒ…å°

1. é€‰æ‹©å¸‚åœº: **Aè‚¡**
2. è¾“å…¥ä»£ç : **600519**
3. é€‰æ‹©åˆ†æå¸ˆ: **å…¨éƒ¨åˆ†æå¸ˆ**
4. ç ”ç©¶æ·±åº¦: **æ·±åº¦åˆ†æ**
5. ç‚¹å‡»"å¼€å§‹åˆ†æ"

**é¢„æœŸç»“æœ**:
- å®æ—¶è‚¡ä»·å’Œæ¶¨è·Œå¹…
- æŠ€æœ¯æŒ‡æ ‡åˆ†æ
- åŸºæœ¬é¢è¯„ä¼°
- æ–°é—»å’Œç¤¾äº¤åª’ä½“æƒ…ç»ª
- ç»¼åˆæŠ•èµ„å»ºè®®

### ç¤ºä¾‹2: åˆ†æå®å¾·æ—¶ä»£

1. é€‰æ‹©å¸‚åœº: **Aè‚¡**
2. è¾“å…¥ä»£ç : **300750**
3. é€‰æ‹©åˆ†æå¸ˆ: **æŠ€æœ¯åˆ†æå¸ˆ + åŸºæœ¬é¢åˆ†æå¸ˆ**
4. ç ”ç©¶æ·±åº¦: **æ ‡å‡†åˆ†æ**
5. ç‚¹å‡»"å¼€å§‹åˆ†æ"

**é¢„æœŸç»“æœ**:
- åˆ›ä¸šæ¿è‚¡ç¥¨ç‰¹è‰²åˆ†æ
- æ–°èƒ½æºè¡Œä¸šè¶‹åŠ¿
- æŠ€æœ¯å½¢æ€è¯†åˆ«
- ä¼°å€¼æ°´å¹³è¯„ä¼°

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. ç½‘ç»œè¦æ±‚

- éœ€è¦ç¨³å®šçš„ç½‘ç»œè¿æ¥è®¿é—®é€šè¾¾ä¿¡æœåŠ¡å™¨
- å¦‚æœè¿æ¥å¤±è´¥ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å°è¯•å¤‡ç”¨æœåŠ¡å™¨
- å»ºè®®åœ¨ç½‘ç»œç¯å¢ƒè‰¯å¥½æ—¶è¿›è¡Œåˆ†æ

### 2. æ•°æ®å‡†ç¡®æ€§

- å®æ—¶æ•°æ®æ¥æºäºé€šè¾¾ä¿¡å…è´¹æœåŠ¡å™¨
- é‡è¦æŠ•èµ„å†³ç­–å»ºè®®äº¤å‰éªŒè¯å¤šä¸ªæ•°æ®æº
- ç³»ç»Ÿæä¾›çš„æ˜¯åˆ†æå»ºè®®ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®

### 3. ä½¿ç”¨é™åˆ¶

- é€šè¾¾ä¿¡APIä¸ºå…è´¹æœåŠ¡ï¼Œå¯èƒ½å­˜åœ¨è®¿é—®é™åˆ¶
- å»ºè®®åˆç†ä½¿ç”¨ï¼Œé¿å…é¢‘ç¹è¯·æ±‚
- å¦‚é‡åˆ°è¿æ¥é—®é¢˜ï¼Œå¯ç¨åé‡è¯•

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. è¿æ¥å¤±è´¥

**é—®é¢˜**: æ˜¾ç¤º"é€šè¾¾ä¿¡APIè¿æ¥å¤±è´¥"

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
ping 119.97.185.59

# é‡æ–°æµ‹è¯•æœåŠ¡å™¨
python tests/fast_tdx_test.py

# æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
```

#### 2. æ•°æ®è·å–å¤±è´¥

**é—®é¢˜**: è¿æ¥æˆåŠŸä½†æ— æ³•è·å–æ•°æ®

**è§£å†³æ–¹æ¡ˆ**:
- ç¡®è®¤è‚¡ç¥¨ä»£ç æ ¼å¼æ­£ç¡®
- æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¶é—´
- å°è¯•å…¶ä»–è‚¡ç¥¨ä»£ç éªŒè¯

#### 3. åˆ†æé€Ÿåº¦æ…¢

**é—®é¢˜**: Aè‚¡åˆ†ææ¯”ç¾è‚¡æ…¢

**è§£å†³æ–¹æ¡ˆ**:
- é€‰æ‹©è¾ƒå°‘çš„åˆ†æå¸ˆ
- é™ä½ç ”ç©¶æ·±åº¦
- æ£€æŸ¥ç½‘ç»œè¿æ¥è´¨é‡

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. åˆ†æå¸ˆé€‰æ‹©

- **å¿«é€Ÿåˆ†æ**: é€‰æ‹©1-2ä¸ªæ ¸å¿ƒåˆ†æå¸ˆ
- **å…¨é¢åˆ†æ**: é€‰æ‹©æ‰€æœ‰åˆ†æå¸ˆï¼ˆè€—æ—¶è¾ƒé•¿ï¼‰
- **ä¸“é¡¹åˆ†æ**: æ ¹æ®éœ€æ±‚é€‰æ‹©ç‰¹å®šåˆ†æå¸ˆ

### 2. ç ”ç©¶æ·±åº¦

- **å¿«é€Ÿ**: 2-4åˆ†é’Ÿï¼Œé€‚åˆæ—¥å†…äº¤æ˜“
- **æ ‡å‡†**: 5-8åˆ†é’Ÿï¼Œé€‚åˆçŸ­æœŸæŠ•èµ„
- **æ·±åº¦**: 10-15åˆ†é’Ÿï¼Œé€‚åˆé•¿æœŸæŠ•èµ„
- **å…¨é¢**: 15-25åˆ†é’Ÿï¼Œé€‚åˆé‡è¦å†³ç­–

### 3. ä½¿ç”¨æŠ€å·§

- åœ¨äº¤æ˜“æ—¶é—´è¿›è¡Œåˆ†æè·å¾—æœ€æ–°æ•°æ®
- æ‰¹é‡åˆ†æå¤šåªè‚¡ç¥¨æ—¶é€‚å½“é—´éš”
- ä¿å­˜åˆ†æç»“æœä¾›åç»­å‚è€ƒ

## ğŸ‰ æ€»ç»“

TradingAgents-CN v0.1.3 çš„Aè‚¡æ”¯æŒä¸ºä¸­å›½æŠ•èµ„è€…æä¾›äº†ï¼š

1. **ğŸ‡¨ğŸ‡³ æœ¬åœŸåŒ–ä½“éªŒ**: å®Œæ•´çš„Aè‚¡æ•°æ®è¦†ç›–
2. **âš¡ å®æ—¶åˆ†æ**: ç§’çº§æ•°æ®æ›´æ–°
3. **ğŸ’° é›¶æˆæœ¬**: å…è´¹çš„æ•°æ®æº
4. **ğŸ”§ æ˜“ç”¨æ€§**: é›¶é…ç½®å³ç”¨
5. **ğŸ“Š ä¸“ä¸šæ€§**: å¤šç»´åº¦åˆ†ææ¡†æ¶

ç°åœ¨æ‚¨å¯ä»¥åƒåˆ†æç¾è‚¡ä¸€æ ·ï¼Œå¯¹Aè‚¡è¿›è¡Œä¸“ä¸šçš„å¤šæ™ºèƒ½ä½“åä½œåˆ†æï¼


<!-- docs/guides/config-management-guide.md -->

# é…ç½®ç®¡ç†å’Œæˆæœ¬ç»Ÿè®¡ä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

TradingAgents-CN v0.1.3 æ–°å¢äº†å®Œæ•´çš„é…ç½®ç®¡ç†å’Œæˆæœ¬ç»Ÿè®¡ç³»ç»Ÿï¼Œè®©æ‚¨å¯ä»¥ï¼š

- ğŸ”§ **ç»Ÿä¸€ç®¡ç†APIå¯†é’¥å’Œæ¨¡å‹é…ç½®**
- ğŸ’° **å®æ—¶è·Ÿè¸ªTokenä½¿ç”¨å’Œæˆæœ¬**
- ğŸ“Š **æŸ¥çœ‹è¯¦ç»†çš„ä½¿ç”¨ç»Ÿè®¡å’Œè¶‹åŠ¿**
- âš™ï¸ **è‡ªå®šä¹‰ç³»ç»Ÿè®¾ç½®å’Œè´¹ç‡**

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨Webç•Œé¢

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
.\env\Scripts\Activate.ps1  # Windows
source env/bin/activate     # Linux/macOS

# å¯åŠ¨Webåº”ç”¨
python -m streamlit run web/app.py
```

### 2. è®¿é—®é…ç½®ç®¡ç†

1. åœ¨Webç•Œé¢å·¦ä¾§é€‰æ‹© **"âš™ï¸ é…ç½®ç®¡ç†"**
2. é€‰æ‹©è¦ç®¡ç†çš„åŠŸèƒ½ï¼š
   - **æ¨¡å‹é…ç½®** - ç®¡ç†APIå¯†é’¥å’Œæ¨¡å‹å‚æ•°
   - **å®šä»·è®¾ç½®** - è®¾ç½®å„ä¾›åº”å•†çš„è´¹ç‡
   - **ä½¿ç”¨ç»Ÿè®¡** - æŸ¥çœ‹Tokenä½¿ç”¨å’Œæˆæœ¬ç»Ÿè®¡
   - **ç³»ç»Ÿè®¾ç½®** - é…ç½®ç³»ç»Ÿé»˜è®¤å‚æ•°

## ğŸ¤– æ¨¡å‹é…ç½®ç®¡ç†

### æ”¯æŒçš„æ¨¡å‹ä¾›åº”å•†

| ä¾›åº”å•† | æ¨¡å‹ç¤ºä¾‹ | è´§å¸ | è¯´æ˜ |
|--------|----------|------|------|
| **é˜¿é‡Œç™¾ç‚¼** | qwen-turbo, qwen-plus-latest, qwen-max | CNY | å›½äº§æ¨¡å‹ï¼Œæ¨èä½¿ç”¨ |
| **OpenAI** | gpt-3.5-turbo, gpt-4, gpt-4-turbo | USD | å›½é™…é¢†å…ˆæ¨¡å‹ |
| **Google** | gemini-pro, gemini-pro-vision | USD | Googleæœ€æ–°æ¨¡å‹ |
| **Anthropic** | claude-3-sonnet, claude-3-opus | USD | é«˜è´¨é‡å¯¹è¯æ¨¡å‹ |

### é…ç½®æ­¥éª¤

#### **æ·»åŠ æ–°æ¨¡å‹**

1. è¿›å…¥ **"æ¨¡å‹é…ç½®"** é¡µé¢
2. åœ¨ **"æ·»åŠ æ–°æ¨¡å‹"** éƒ¨åˆ†å¡«å†™ï¼š
   - **ä¾›åº”å•†**: é€‰æ‹©æ¨¡å‹æä¾›å•†
   - **æ¨¡å‹åç§°**: è¾“å…¥å…·ä½“æ¨¡å‹åï¼ˆå¦‚ qwen-plus-latestï¼‰
   - **APIå¯†é’¥**: è¾“å…¥æ‚¨çš„APIå¯†é’¥
   - **æœ€å¤§Tokenæ•°**: è®¾ç½®è¾“å‡ºé™åˆ¶ï¼ˆ1000-32000ï¼‰
   - **æ¸©åº¦å‚æ•°**: æ§åˆ¶è¾“å‡ºéšæœºæ€§ï¼ˆ0.0-2.0ï¼‰
   - **å¯ç”¨æ¨¡å‹**: æ˜¯å¦åœ¨åˆ†æä¸­ä½¿ç”¨

3. ç‚¹å‡» **"æ·»åŠ æ¨¡å‹"** ä¿å­˜

#### **ç¼–è¾‘ç°æœ‰æ¨¡å‹**

1. åœ¨æ¨¡å‹åˆ—è¡¨ä¸­é€‰æ‹©è¦ç¼–è¾‘çš„æ¨¡å‹
2. ä¿®æ”¹ç›¸åº”å‚æ•°
3. ç‚¹å‡» **"ä¿å­˜é…ç½®"**

### æ¨¡å‹é…ç½®ç¤ºä¾‹

```json
{
  "provider": "dashscope",
  "model_name": "qwen-plus-latest",
  "api_key": "sk-your-api-key-here",
  "max_tokens": 4000,
  "temperature": 0.7,
  "enabled": true
}
```

## ğŸ’° å®šä»·è®¾ç½®ç®¡ç†

### é»˜è®¤è´¹ç‡è¡¨

#### **é˜¿é‡Œç™¾ç‚¼ (CNY/1000 tokens)**
| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ | è¾“å‡ºä»·æ ¼ | è¯´æ˜ |
|------|----------|----------|------|
| qwen-turbo | Â¥0.002 | Â¥0.006 | å¿«é€Ÿå“åº” |
| qwen-plus | Â¥0.004 | Â¥0.012 | å¹³è¡¡æ€§èƒ½ |
| qwen-max | Â¥0.020 | Â¥0.060 | æœ€å¼ºæ€§èƒ½ |

#### **OpenAI (USD/1000 tokens)**
| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ | è¾“å‡ºä»·æ ¼ | è¯´æ˜ |
|------|----------|----------|------|
| gpt-3.5-turbo | $0.0015 | $0.002 | ç»æµå®ç”¨ |
| gpt-4 | $0.03 | $0.06 | å¼ºå¤§æ€§èƒ½ |
| gpt-4-turbo | $0.01 | $0.03 | ä¼˜åŒ–ç‰ˆæœ¬ |

#### **Google (USD/1000 tokens)**
| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ | è¾“å‡ºä»·æ ¼ | è¯´æ˜ |
|------|----------|----------|------|
| gemini-pro | $0.00025 | $0.0005 | é«˜æ€§ä»·æ¯” |
| gemini-pro-vision | $0.00025 | $0.0005 | æ”¯æŒå›¾åƒ |

### è‡ªå®šä¹‰å®šä»·

1. è¿›å…¥ **"å®šä»·è®¾ç½®"** é¡µé¢
2. é€‰æ‹©è¦ç¼–è¾‘çš„æ¨¡å‹å®šä»·
3. ä¿®æ”¹ï¼š
   - **è¾“å…¥ä»·æ ¼**: æ¯1000ä¸ªè¾“å…¥tokençš„ä»·æ ¼
   - **è¾“å‡ºä»·æ ¼**: æ¯1000ä¸ªè¾“å‡ºtokençš„ä»·æ ¼
   - **è´§å¸**: CNY/USD/EUR
4. ç‚¹å‡» **"ä¿å­˜å®šä»·"**

## ğŸ“Š ä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬åˆ†æ

### ç»Ÿè®¡æ•°æ®ç±»å‹

#### **æ€»ä½“ç»Ÿè®¡**
- **æ€»æˆæœ¬**: æŒ‡å®šæ—¶é—´å†…çš„æ€»èŠ±è´¹
- **æ€»è¯·æ±‚æ•°**: APIè°ƒç”¨æ¬¡æ•°
- **è¾“å…¥Token**: æ€»è¾“å…¥tokenæ•°é‡
- **è¾“å‡ºToken**: æ€»è¾“å‡ºtokenæ•°é‡

#### **æŒ‰ä¾›åº”å•†ç»Ÿè®¡**
- **å„ä¾›åº”å•†æˆæœ¬åˆ†å¸ƒ**
- **ä½¿ç”¨é¢‘ç‡å¯¹æ¯”**
- **å¹³å‡æˆæœ¬åˆ†æ**

#### **ä½¿ç”¨è¶‹åŠ¿**
- **æ¯æ—¥æˆæœ¬è¶‹åŠ¿å›¾**
- **æ¯æ—¥è¯·æ±‚æ•°è¶‹åŠ¿**
- **æˆæœ¬å˜åŒ–åˆ†æ**

### æŸ¥çœ‹ç»Ÿè®¡

1. è¿›å…¥ **"ä½¿ç”¨ç»Ÿè®¡"** é¡µé¢
2. é€‰æ‹©ç»Ÿè®¡æ—¶é—´èŒƒå›´ï¼š
   - æœ€è¿‘7å¤©
   - æœ€è¿‘30å¤©
   - æœ€è¿‘90å¤©
   - æœ€è¿‘365å¤©
3. æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡å›¾è¡¨å’Œæ•°æ®

### æˆæœ¬æ§åˆ¶

#### **è®¾ç½®æˆæœ¬è­¦å‘Š**
1. è¿›å…¥ **"ç³»ç»Ÿè®¾ç½®"** é¡µé¢
2. è®¾ç½® **"æˆæœ¬è­¦å‘Šé˜ˆå€¼"**
3. å½“æ—¥æˆæœ¬è¶…è¿‡é˜ˆå€¼æ—¶ä¼šæ”¶åˆ°è­¦å‘Š

#### **æˆæœ¬ä¼˜åŒ–å»ºè®®**
- **é€‰æ‹©åˆé€‚çš„æ¨¡å‹**: æ ¹æ®éœ€æ±‚é€‰æ‹©æ€§ä»·æ¯”æœ€é«˜çš„æ¨¡å‹
- **æ§åˆ¶Tokenä½¿ç”¨**: åˆç†è®¾ç½®æœ€å¤§Tokenæ•°
- **ç›‘æ§ä½¿ç”¨è¶‹åŠ¿**: å®šæœŸæŸ¥çœ‹æˆæœ¬ç»Ÿè®¡

## âš™ï¸ ç³»ç»Ÿè®¾ç½®

### åŸºæœ¬è®¾ç½®

| è®¾ç½®é¡¹ | è¯´æ˜ | é»˜è®¤å€¼ |
|--------|------|--------|
| **é»˜è®¤ä¾›åº”å•†** | æ–°åˆ†ææ—¶çš„é»˜è®¤æ¨¡å‹ä¾›åº”å•† | dashscope |
| **é»˜è®¤æ¨¡å‹** | é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹åç§° | qwen-turbo |
| **å¯ç”¨æˆæœ¬è·Ÿè¸ª** | æ˜¯å¦è®°å½•Tokenä½¿ç”¨å’Œæˆæœ¬ | å¯ç”¨ |
| **æˆæœ¬è­¦å‘Šé˜ˆå€¼** | æ—¥æˆæœ¬è¶…è¿‡æ­¤å€¼æ—¶è­¦å‘Š | Â¥100 |
| **é¦–é€‰è´§å¸** | æˆæœ¬æ˜¾ç¤ºçš„é¦–é€‰è´§å¸ | CNY |
| **è‡ªåŠ¨ä¿å­˜ä½¿ç”¨è®°å½•** | æ˜¯å¦è‡ªåŠ¨ä¿å­˜ä½¿ç”¨è®°å½• | å¯ç”¨ |
| **æœ€å¤§ä½¿ç”¨è®°å½•æ•°** | ä¿ç•™çš„æœ€å¤§è®°å½•æ•°é‡ | 10000 |

### æ•°æ®ç®¡ç†

#### **å¯¼å‡ºé…ç½®**
- å¯¼å‡ºæ‰€æœ‰é…ç½®åˆ°JSONæ–‡ä»¶
- ä¾¿äºå¤‡ä»½å’Œè¿ç§»

#### **æ¸…ç©ºä½¿ç”¨è®°å½•**
- æ¸…ç©ºæ‰€æœ‰Tokenä½¿ç”¨è®°å½•
- é‡Šæ”¾å­˜å‚¨ç©ºé—´

#### **é‡ç½®é…ç½®**
- æ¢å¤æ‰€æœ‰é…ç½®åˆ°é»˜è®¤å€¼
- è°¨æ…ä½¿ç”¨æ­¤åŠŸèƒ½

## ğŸ”§ é«˜çº§åŠŸèƒ½

### Tokenä½¿ç”¨è·Ÿè¸ª

ç³»ç»Ÿä¼šè‡ªåŠ¨è·Ÿè¸ªæ¯æ¬¡åˆ†æçš„Tokenä½¿ç”¨ï¼š

```python
# è‡ªåŠ¨è®°å½•çš„ä¿¡æ¯
{
    "timestamp": "2025-06-28T10:30:00",
    "provider": "dashscope",
    "model_name": "qwen-plus",
    "input_tokens": 2500,
    "output_tokens": 1200,
    "cost": 0.024,
    "session_id": "analysis_abc123_20250628_1030",
    "analysis_type": "Aè‚¡_analysis"
}
```

### æˆæœ¬è®¡ç®—å…¬å¼

```
æ€»æˆæœ¬ = (è¾“å…¥Tokenæ•° / 1000) Ã— è¾“å…¥å•ä»· + (è¾“å‡ºTokenæ•° / 1000) Ã— è¾“å‡ºå•ä»·
```

### ä¼šè¯è·Ÿè¸ª

æ¯æ¬¡åˆ†æéƒ½ä¼šç”Ÿæˆå”¯ä¸€çš„ä¼šè¯IDï¼Œç”¨äºï¼š
- è·Ÿè¸ªå•æ¬¡åˆ†æçš„å®Œæ•´æˆæœ¬
- åˆ†æä¸åŒç±»å‹ä»»åŠ¡çš„æˆæœ¬å·®å¼‚
- ä¼˜åŒ–Tokenä½¿ç”¨ç­–ç•¥

## ğŸ“ˆ ä½¿ç”¨åœºæ™¯ç¤ºä¾‹

### åœºæ™¯1ï¼šæˆæœ¬é¢„ç®—ç®¡ç†

**ç›®æ ‡**: æ§åˆ¶æœˆåº¦AIä½¿ç”¨æˆæœ¬åœ¨Â¥500ä»¥å†…

**æ“ä½œ**:
1. è®¾ç½®æˆæœ¬è­¦å‘Šé˜ˆå€¼ä¸ºÂ¥16.67ï¼ˆ500/30å¤©ï¼‰
2. é€‰æ‹©æ€§ä»·æ¯”é«˜çš„æ¨¡å‹ï¼ˆå¦‚qwen-turboï¼‰
3. å®šæœŸæŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡ï¼Œè°ƒæ•´ä½¿ç”¨é¢‘ç‡

### åœºæ™¯2ï¼šå¤šæ¨¡å‹å¯¹æ¯”

**ç›®æ ‡**: æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ€§ä»·æ¯”

**æ“ä½œ**:
1. é…ç½®å¤šä¸ªæ¨¡å‹ï¼ˆqwen-turbo, qwen-plus, gpt-3.5-turboï¼‰
2. å¯¹åŒä¸€è‚¡ç¥¨è¿›è¡Œå¤šæ¬¡åˆ†æ
3. åœ¨ä½¿ç”¨ç»Ÿè®¡ä¸­æ¯”è¾ƒæˆæœ¬å’Œæ•ˆæœ

### åœºæ™¯3ï¼šå›¢é˜Ÿä½¿ç”¨ç®¡ç†

**ç›®æ ‡**: ç®¡ç†å›¢é˜Ÿçš„AIä½¿ç”¨æˆæœ¬

**æ“ä½œ**:
1. ä¸ºä¸åŒå›¢é˜Ÿæˆå‘˜é…ç½®ä¸åŒçš„ä¼šè¯IDå‰ç¼€
2. é€šè¿‡ä½¿ç”¨ç»Ÿè®¡åˆ†æå„æˆå‘˜çš„ä½¿ç”¨æƒ…å†µ
3. åˆ¶å®šä½¿ç”¨è§„èŒƒå’Œé¢„ç®—åˆ†é…

## âš ï¸ æ³¨æ„äº‹é¡¹

### æ•°æ®å®‰å…¨
- **APIå¯†é’¥åŠ å¯†å­˜å‚¨**: ç³»ç»Ÿä¼šå®‰å…¨å­˜å‚¨æ‚¨çš„APIå¯†é’¥
- **æœ¬åœ°æ•°æ®**: æ‰€æœ‰é…ç½®å’Œä½¿ç”¨è®°å½•éƒ½å­˜å‚¨åœ¨æœ¬åœ°
- **å®šæœŸå¤‡ä»½**: å»ºè®®å®šæœŸå¯¼å‡ºé…ç½®è¿›è¡Œå¤‡ä»½

### æˆæœ¬æ§åˆ¶
- **å®æ—¶ç›‘æ§**: å®šæœŸæŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡
- **åˆç†è®¾ç½®**: æ ¹æ®éœ€æ±‚è®¾ç½®åˆé€‚çš„Tokené™åˆ¶
- **æ¨¡å‹é€‰æ‹©**: é€‰æ‹©é€‚åˆä»»åŠ¡çš„æ¨¡å‹ï¼Œé¿å…è¿‡åº¦ä½¿ç”¨é«˜æˆæœ¬æ¨¡å‹

### æ•…éšœæ’é™¤
- **é…ç½®ä¸¢å¤±**: ä½¿ç”¨"é‡ç½®é…ç½®"åŠŸèƒ½æ¢å¤é»˜è®¤è®¾ç½®
- **æˆæœ¬å¼‚å¸¸**: æ£€æŸ¥å®šä»·è®¾ç½®æ˜¯å¦æ­£ç¡®
- **ç»Ÿè®¡é”™è¯¯**: æ¸…ç©ºä½¿ç”¨è®°å½•åé‡æ–°å¼€å§‹ç»Ÿè®¡

## ğŸ”® æœªæ¥åŠŸèƒ½

### è®¡åˆ’ä¸­çš„åŠŸèƒ½
- **å¤šè´§å¸æ±‡ç‡è½¬æ¢**: è‡ªåŠ¨è½¬æ¢ä¸åŒè´§å¸çš„æˆæœ¬
- **æˆæœ¬é¢„æµ‹**: åŸºäºå†å²æ•°æ®é¢„æµ‹æœªæ¥æˆæœ¬
- **ä½¿ç”¨æŠ¥å‘Š**: ç”Ÿæˆè¯¦ç»†çš„ä½¿ç”¨æŠ¥å‘Š
- **å›¢é˜Ÿç®¡ç†**: æ”¯æŒå¤šç”¨æˆ·å’Œæƒé™ç®¡ç†
- **APIé›†æˆ**: æä¾›é…ç½®ç®¡ç†çš„APIæ¥å£

---

**é€šè¿‡é…ç½®ç®¡ç†ç³»ç»Ÿï¼Œæ‚¨å¯ä»¥æ›´å¥½åœ°æ§åˆ¶AIä½¿ç”¨æˆæœ¬ï¼Œä¼˜åŒ–åˆ†ææ•ˆæœï¼** ğŸ’°ğŸ“Š


<!-- docs/localization/chinese-social-media-integration.md -->

# ä¸­å›½ç¤¾äº¤åª’ä½“å¹³å°é›†æˆæ–¹æ¡ˆ

## ğŸ¯ æ¦‚è¿°

ä¸ºäº†æ›´å¥½åœ°æœåŠ¡ä¸­å›½ç”¨æˆ·ï¼ŒTradingAgents-CN éœ€è¦é›†æˆä¸­å›½æœ¬åœŸçš„ç¤¾äº¤åª’ä½“å’Œè´¢ç»å¹³å°ï¼Œä»¥è·å–æ›´å‡†ç¡®çš„å¸‚åœºæƒ…ç»ªå’ŒæŠ•èµ„è€…è§‚ç‚¹ã€‚

## ğŸŒ å¹³å°å¯¹åº”å…³ç³»

### å›½å¤– vs å›½å†…å¹³å°æ˜ å°„

| å›½å¤–å¹³å° | å›½å†…å¯¹åº”å¹³å° | ä¸»è¦åŠŸèƒ½ | æ•°æ®ä»·å€¼ |
|----------|-------------|----------|----------|
| **Reddit** | **å¾®åš** | è¯é¢˜è®¨è®ºã€çƒ­ç‚¹è¿½è¸ª | å¸‚åœºæƒ…ç»ªã€çƒ­ç‚¹äº‹ä»¶ |
| **Twitter** | **å¾®åš** | å®æ—¶åŠ¨æ€ã€æ–°é—»ä¼ æ’­ | å³æ—¶ååº”ã€èˆ†è®ºè¶‹åŠ¿ |
| **Discord** | **å¾®ä¿¡ç¾¤/QQç¾¤** | ç¤¾åŒºè®¨è®º | æ·±åº¦äº¤æµã€ä¸“ä¸šè§‚ç‚¹ |
| **Telegram** | **é’‰é’‰/ä¼ä¸šå¾®ä¿¡** | ä¸“ä¸šäº¤æµ | æœºæ„è§‚ç‚¹ã€å†…éƒ¨æ¶ˆæ¯ |

### ä¸­å›½ç‰¹è‰²è´¢ç»å¹³å°

| å¹³å°ç±»å‹ | ä¸»è¦å¹³å° | ç‰¹è‰²åŠŸèƒ½ | æ•°æ®è·å–éš¾åº¦ |
|----------|----------|----------|-------------|
| **ä¸“ä¸šæŠ•èµ„ç¤¾åŒº** | é›ªçƒã€ä¸œæ–¹è´¢å¯Œè‚¡å§ | è‚¡ç¥¨è®¨è®ºã€æŠ•èµ„ç­–ç•¥ | ä¸­ç­‰ |
| **ç»¼åˆç¤¾äº¤åª’ä½“** | å¾®åšã€çŸ¥ä¹ | è´¢ç»å¤§Vã€ä¸“ä¸šåˆ†æ | è¾ƒé«˜ |
| **æ–°é—»èµ„è®¯å¹³å°** | è´¢è”ç¤¾ã€æ–°æµªè´¢ç» | å®æ—¶å¿«è®¯ã€æ·±åº¦æŠ¥é“ | ä¸­ç­‰ |
| **çŸ­è§†é¢‘å¹³å°** | æŠ–éŸ³ã€å¿«æ‰‹ | è´¢ç»ç§‘æ™®ã€æŠ•èµ„æ•™è‚² | è¾ƒé«˜ |
| **ä¸“ä¸šé—®ç­”** | çŸ¥ä¹ | æ·±åº¦åˆ†æã€ä¸“ä¸šè§£ç­” | ä¸­ç­‰ |

## ğŸ”§ æŠ€æœ¯å®ç°æ–¹æ¡ˆ

### é˜¶æ®µä¸€ï¼šåŸºç¡€é›†æˆ (å½“å‰å¯å®ç°)

#### 1. å¾®åšæƒ…ç»ªåˆ†æ
```python
# å¾®åšAPIé›†æˆç¤ºä¾‹
class WeiboSentimentAnalyzer:
    def __init__(self, api_key):
        self.api_key = api_key
        
    def get_stock_sentiment(self, stock_symbol, days=7):
        """è·å–è‚¡ç¥¨ç›¸å…³å¾®åšæƒ…ç»ª"""
        # æœç´¢ç›¸å…³å¾®åš
        keywords = [stock_symbol, self.get_company_name(stock_symbol)]
        weibo_posts = self.search_weibo(keywords, days)
        
        # æƒ…ç»ªåˆ†æ
        sentiment_scores = []
        for post in weibo_posts:
            score = self.analyze_sentiment(post['text'])
            sentiment_scores.append({
                'date': post['date'],
                'sentiment': score,
                'influence': post['repost_count'] + post['comment_count']
            })
        
        return self.aggregate_sentiment(sentiment_scores)
```

#### 2. é›ªçƒæ•°æ®é›†æˆ
```python
# é›ªçƒè‚¡ç¥¨è®¨è®ºåˆ†æ
class XueqiuAnalyzer:
    def get_stock_discussions(self, stock_code):
        """è·å–é›ªçƒè‚¡ç¥¨è®¨è®º"""
        # é›ªçƒè‚¡ç¥¨é¡µé¢çˆ¬å–
        discussions = self.crawl_xueqiu_discussions(stock_code)
        
        # åˆ†ææŠ•èµ„è€…è§‚ç‚¹
        bullish_count = 0
        bearish_count = 0
        
        for discussion in discussions:
            sentiment = self.classify_sentiment(discussion['content'])
            if sentiment > 0.6:
                bullish_count += 1
            elif sentiment < 0.4:
                bearish_count += 1
        
        return {
            'bullish_ratio': bullish_count / len(discussions),
            'bearish_ratio': bearish_count / len(discussions),
            'total_discussions': len(discussions)
        }
```

#### 3. è´¢ç»æ–°é—»èšåˆ
```python
# ä¸­å›½è´¢ç»æ–°é—»é›†æˆ
class ChineseFinanceNews:
    def __init__(self):
        self.sources = [
            'cailianshe',  # è´¢è”ç¤¾
            'sina_finance',  # æ–°æµªè´¢ç»
            'eastmoney',   # ä¸œæ–¹è´¢å¯Œ
            'tencent_finance'  # è…¾è®¯è´¢ç»
        ]
    
    def get_stock_news(self, stock_symbol, days=7):
        """è·å–è‚¡ç¥¨ç›¸å…³æ–°é—»"""
        all_news = []
        
        for source in self.sources:
            news = self.fetch_news_from_source(source, stock_symbol, days)
            all_news.extend(news)
        
        # å»é‡å’Œæ’åº
        unique_news = self.deduplicate_news(all_news)
        return sorted(unique_news, key=lambda x: x['publish_time'], reverse=True)
```

### é˜¶æ®µäºŒï¼šæ·±åº¦é›†æˆ (éœ€è¦APIæ”¯æŒ)

#### 1. çŸ¥ä¹ä¸“ä¸šåˆ†æ
- æœç´¢è‚¡ç¥¨ç›¸å…³çš„ä¸“ä¸šå›ç­”
- åˆ†æçŸ¥ä¹å¤§Vçš„æŠ•èµ„è§‚ç‚¹
- æå–é«˜è´¨é‡çš„æŠ•èµ„åˆ†æå†…å®¹

#### 2. æŠ–éŸ³/å¿«æ‰‹è´¢ç»å†…å®¹
- åˆ†æè´¢ç»åšä¸»çš„è§‚ç‚¹
- ç»Ÿè®¡æŠ•èµ„æ•™è‚²å†…å®¹çš„è¶‹åŠ¿
- ç›‘æ§æ•£æˆ·æŠ•èµ„è€…çš„æƒ…ç»ªå˜åŒ–

#### 3. å¾®ä¿¡å…¬ä¼—å·åˆ†æ
- è·Ÿè¸ªçŸ¥åè´¢ç»å…¬ä¼—å·
- åˆ†ææœºæ„ç ”æŠ¥å’ŒæŠ•èµ„å»ºè®®
- ç›‘æ§æ”¿ç­–è§£è¯»å’Œå¸‚åœºåˆ†æ

## ğŸ“Š æ•°æ®æºä¼˜å…ˆçº§å»ºè®®

### é«˜ä¼˜å…ˆçº§ (ç«‹å³å®ç°)
1. **è´¢è”ç¤¾API** - ä¸“ä¸šè´¢ç»å¿«è®¯
2. **æ–°æµªè´¢ç»RSS** - å…è´¹æ–°é—»æº
3. **ä¸œæ–¹è´¢å¯Œè‚¡å§çˆ¬è™«** - æ•£æˆ·æƒ…ç»ª
4. **é›ªçƒå…¬å¼€æ•°æ®** - æŠ•èµ„è€…è®¨è®º

### ä¸­ä¼˜å…ˆçº§ (ä¸­æœŸå®ç°)
1. **å¾®åšå¼€æ”¾å¹³å°** - éœ€è¦ç”³è¯·API
2. **çŸ¥ä¹çˆ¬è™«** - ä¸“ä¸šåˆ†æå†…å®¹
3. **è…¾è®¯è´¢ç»API** - ç»¼åˆè´¢ç»æ•°æ®

### ä½ä¼˜å…ˆçº§ (é•¿æœŸè§„åˆ’)
1. **æŠ–éŸ³/å¿«æ‰‹** - æŠ€æœ¯éš¾åº¦é«˜
2. **å¾®ä¿¡å…¬ä¼—å·** - è·å–å›°éš¾
3. **ç§åŸŸç¤¾ç¾¤** - éœ€è¦ç‰¹æ®Šæ¸ é“

## ğŸ”§ å®ç°å»ºè®®

### å½“å‰å¯è¡Œçš„æ”¹è¿›

#### 1. æ›´æ–°ç¤¾äº¤åª’ä½“åˆ†æå¸ˆæç¤ºè¯
```python
# ä¿®æ”¹ social_media_analyst.py
system_message = """
æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¸­å›½å¸‚åœºç¤¾äº¤åª’ä½“åˆ†æå¸ˆï¼Œè´Ÿè´£åˆ†æä¸­å›½æŠ•èµ„è€…åœ¨å„å¤§å¹³å°ä¸Šå¯¹ç‰¹å®šè‚¡ç¥¨çš„è®¨è®ºå’Œæƒ…ç»ªã€‚

ä¸»è¦åˆ†æå¹³å°åŒ…æ‹¬ï¼š
- å¾®åšï¼šè´¢ç»å¤§Vè§‚ç‚¹ã€çƒ­æœè¯é¢˜ã€æ•£æˆ·æƒ…ç»ª
- é›ªçƒï¼šä¸“ä¸šæŠ•èµ„è€…è®¨è®ºã€è‚¡ç¥¨è¯„çº§ã€æŠ•èµ„ç­–ç•¥
- ä¸œæ–¹è´¢å¯Œè‚¡å§ï¼šæ•£æˆ·æŠ•èµ„è€…æƒ…ç»ªã€è®¨è®ºçƒ­åº¦
- çŸ¥ä¹ï¼šæ·±åº¦åˆ†ææ–‡ç« ã€ä¸“ä¸šé—®ç­”
- è´¢ç»æ–°é—»ï¼šè´¢è”ç¤¾ã€æ–°æµªè´¢ç»ã€ä¸œæ–¹è´¢å¯Œç­‰

è¯·é‡ç‚¹å…³æ³¨ï¼š
1. æŠ•èµ„è€…æƒ…ç»ªå˜åŒ–è¶‹åŠ¿
2. å…³é”®æ„è§é¢†è¢–(KOL)çš„è§‚ç‚¹
3. æ•£æˆ·ä¸æœºæ„æŠ•èµ„è€…çš„è§‚ç‚¹å·®å¼‚
4. çƒ­ç‚¹äº‹ä»¶å¯¹è‚¡ä»·çš„æ½œåœ¨å½±å“
5. æ”¿ç­–è§£è¯»å’Œå¸‚åœºé¢„æœŸ

è¯·ç”¨ä¸­æ–‡æ’°å†™è¯¦ç»†çš„åˆ†ææŠ¥å‘Šã€‚
"""
```

#### 2. æ·»åŠ ä¸­å›½ç‰¹è‰²çš„æ•°æ®å·¥å…·
```python
# æ–°å¢å·¥å…·å‡½æ•°
def get_chinese_social_sentiment(stock_symbol):
    """è·å–ä¸­å›½ç¤¾äº¤åª’ä½“æƒ…ç»ª"""
    # æ•´åˆå¤šä¸ªä¸­å›½å¹³å°çš„æ•°æ®
    pass

def get_chinese_finance_news(stock_symbol):
    """è·å–ä¸­å›½è´¢ç»æ–°é—»"""
    # èšåˆä¸­å›½ä¸»è¦è´¢ç»åª’ä½“
    pass
```

### é…ç½®æ–‡ä»¶æ›´æ–°

#### ç¯å¢ƒå˜é‡é…ç½®
```bash
# ä¸­å›½ç¤¾äº¤åª’ä½“å¹³å°APIå¯†é’¥
WEIBO_API_KEY=your_weibo_api_key
WEIBO_API_SECRET=your_weibo_api_secret

# è´¢ç»æ•°æ®æº
CAILIANSHE_API_KEY=your_cailianshe_key
EASTMONEY_API_KEY=your_eastmoney_key

# æ›¿ä»£Redditçš„é…ç½®
USE_CHINESE_SOCIAL_MEDIA=true
SOCIAL_MEDIA_PLATFORMS=weibo,xueqiu,eastmoney_guba
```

## ğŸ’¡ å®æ–½å»ºè®®

### çŸ­æœŸç›®æ ‡ (1-2ä¸ªæœˆ)
1. âœ… é›†æˆè´¢è”ç¤¾æ–°é—»API
2. âœ… å¼€å‘é›ªçƒæ•°æ®çˆ¬è™«
3. âœ… æ›´æ–°ç¤¾äº¤åª’ä½“åˆ†æå¸ˆæç¤ºè¯
4. âœ… æ·»åŠ ä¸­æ–‡è´¢ç»æœ¯è¯­åº“

### ä¸­æœŸç›®æ ‡ (3-6ä¸ªæœˆ)
1. ğŸ”„ ç”³è¯·å¾®åšå¼€æ”¾å¹³å°API
2. ğŸ”„ å¼€å‘çŸ¥ä¹å†…å®¹åˆ†æå·¥å…·
3. ğŸ”„ å»ºç«‹ä¸­å›½è´¢ç»KOLæ•°æ®åº“
4. ğŸ”„ ä¼˜åŒ–ä¸­æ–‡æƒ…ç»ªåˆ†æç®—æ³•

### é•¿æœŸç›®æ ‡ (6-12ä¸ªæœˆ)
1. ğŸ¯ å»ºç«‹å®Œæ•´çš„ä¸­å›½ç¤¾äº¤åª’ä½“ç›‘æ§ä½“ç³»
2. ğŸ¯ å¼€å‘å®æ—¶æƒ…ç»ªæŒ‡æ•°
3. ğŸ¯ é›†æˆæ›´å¤šä¸­å›½ç‰¹è‰²æ•°æ®æº
4. ğŸ¯ å»ºç«‹ä¸­å›½å¸‚åœºä¸“ç”¨çš„åˆ†ææ¨¡å‹

## ğŸš¨ æ³¨æ„äº‹é¡¹

### æ³•å¾‹åˆè§„
- éµå®ˆä¸­å›½ç½‘ç»œå®‰å…¨æ³•å’Œæ•°æ®ä¿æŠ¤æ³•è§„
- å°Šé‡å„å¹³å°çš„robots.txtå’Œä½¿ç”¨æ¡æ¬¾
- é¿å…è¿‡åº¦çˆ¬å–ï¼Œä½¿ç”¨åˆç†çš„è¯·æ±‚é¢‘ç‡
- ä¿æŠ¤ç”¨æˆ·éšç§ï¼Œä¸å­˜å‚¨ä¸ªäººæ•æ„Ÿä¿¡æ¯

### æŠ€æœ¯æŒ‘æˆ˜
- åçˆ¬è™«æœºåˆ¶ï¼šéœ€è¦ä½¿ç”¨ä»£ç†å’Œè¯·æ±‚å¤´è½®æ¢
- æ•°æ®è´¨é‡ï¼šéœ€è¦è¿‡æ»¤åƒåœ¾ä¿¡æ¯å’Œæœºå™¨äººè´¦å·
- å®æ—¶æ€§ï¼šå¹³è¡¡æ•°æ®æ–°é²œåº¦å’Œç³»ç»Ÿæ€§èƒ½
- å‡†ç¡®æ€§ï¼šä¸­æ–‡æƒ…ç»ªåˆ†æçš„å‡†ç¡®æ€§æœ‰å¾…æå‡

### æˆæœ¬è€ƒè™‘
- APIè°ƒç”¨è´¹ç”¨ï¼šä¼˜å…ˆä½¿ç”¨å…è´¹æˆ–ä½æˆæœ¬æ•°æ®æº
- æœåŠ¡å™¨èµ„æºï¼šçˆ¬è™«å’Œæ•°æ®å¤„ç†éœ€è¦é¢å¤–è®¡ç®—èµ„æº
- ç»´æŠ¤æˆæœ¬ï¼šéœ€è¦æŒç»­ç›‘æ§å’Œæ›´æ–°æ•°æ®æº

## ğŸ¯ æ€»ç»“

é€šè¿‡é›†æˆä¸­å›½æœ¬åœŸçš„ç¤¾äº¤åª’ä½“å’Œè´¢ç»å¹³å°ï¼ŒTradingAgents-CN å°†èƒ½å¤Ÿï¼š

1. **æä¾›æ›´å‡†ç¡®çš„å¸‚åœºæƒ…ç»ªåˆ†æ**
2. **æ›´å¥½åœ°ç†è§£ä¸­å›½æŠ•èµ„è€…è¡Œä¸º**
3. **åŠæ—¶æ•æ‰ä¸­å›½å¸‚åœºçš„çƒ­ç‚¹äº‹ä»¶**
4. **æä¾›æ›´ç¬¦åˆä¸­å›½ç”¨æˆ·ä¹ æƒ¯çš„åˆ†ææŠ¥å‘Š**

è¿™å°†æ˜¾è‘—æå‡ç³»ç»Ÿåœ¨ä¸­å›½å¸‚åœºçš„é€‚ç”¨æ€§å’Œå‡†ç¡®æ€§ã€‚


<!-- docs/maintenance/upstream-sync.md -->

# ä¸Šæ¸¸åŒæ­¥ç­–ç•¥

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•ä¿æŒ TradingAgents-CN ä¸åŸé¡¹ç›® [TauricResearch/TradingAgents](https://github.com/TauricResearch/TradingAgents) çš„åŒæ­¥ã€‚

## ğŸ¯ åŒæ­¥ç›®æ ‡

### ä¸»è¦ç›®æ ‡
- **ä¿æŒæŠ€æœ¯å…ˆè¿›æ€§**: åŠæ—¶è·å¾—åŸé¡¹ç›®çš„æ–°åŠŸèƒ½å’Œæ”¹è¿›
- **ä¿®å¤å®‰å…¨é—®é¢˜**: å¿«é€ŸåŒæ­¥å®‰å…¨è¡¥ä¸å’ŒBugä¿®å¤
- **ç»´æŠ¤å…¼å®¹æ€§**: ç¡®ä¿ä¸­æ–‡å¢å¼ºåŠŸèƒ½ä¸åŸé¡¹ç›®å…¼å®¹
- **å‡å°‘ç»´æŠ¤æˆæœ¬**: é¿å…é‡å¤å¼€å‘å·²æœ‰åŠŸèƒ½

### å¹³è¡¡åŸåˆ™
- **æ ¸å¿ƒåŠŸèƒ½åŒæ­¥**: åŒæ­¥æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ›´æ–°
- **æ–‡æ¡£ä¿æŒç‹¬ç«‹**: ä¿æŒæˆ‘ä»¬çš„ä¸­æ–‡æ–‡æ¡£ä½“ç³»
- **å¢å¼ºåŠŸèƒ½ä¿æŠ¤**: ä¿æŠ¤æˆ‘ä»¬çš„ä¸­æ–‡å¢å¼ºåŠŸèƒ½
- **å†²çªä¼˜é›…å¤„ç†**: å¦¥å–„å¤„ç†åˆå¹¶å†²çª

## ğŸ”„ åŒæ­¥ç­–ç•¥

### 1. ç›‘æ§ç­–ç•¥

#### è‡ªåŠ¨ç›‘æ§
```bash
# è®¾ç½®GitHubé€šçŸ¥
# 1. è®¿é—® https://github.com/TauricResearch/TradingAgents
# 2. ç‚¹å‡» "Watch" -> "Custom" -> é€‰æ‹© "Releases" å’Œ "Issues"
# 3. å¯ç”¨é‚®ä»¶é€šçŸ¥
```

#### å®šæœŸæ£€æŸ¥
- **æ¯å‘¨æ£€æŸ¥**: æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æäº¤å’Œå‘å¸ƒ
- **æ¯æœˆæ·±åº¦åŒæ­¥**: è¿›è¡Œå®Œæ•´çš„åŒæ­¥å’Œæµ‹è¯•
- **é‡è¦æ›´æ–°ç«‹å³åŒæ­¥**: å®‰å…¨è¡¥ä¸å’Œé‡å¤§Bugä¿®å¤

### 2. åˆ†æ”¯ç­–ç•¥

```
main (æˆ‘ä»¬çš„ä¸»åˆ†æ”¯)
â”œâ”€â”€ upstream-sync-YYYYMMDD (åŒæ­¥åˆ†æ”¯)
â”œâ”€â”€ feature/chinese-enhancement (ä¸­æ–‡å¢å¼ºåŠŸèƒ½)
â””â”€â”€ hotfix/urgent-fixes (ç´§æ€¥ä¿®å¤)

upstream/main (åŸé¡¹ç›®ä¸»åˆ†æ”¯)
```

#### åˆ†æ”¯è¯´æ˜
- **main**: æˆ‘ä»¬çš„ç¨³å®šä¸»åˆ†æ”¯ï¼ŒåŒ…å«æ‰€æœ‰ä¸­æ–‡å¢å¼º
- **upstream-sync-YYYYMMDD**: ä¸´æ—¶åŒæ­¥åˆ†æ”¯ï¼Œç”¨äºåˆå¹¶ä¸Šæ¸¸æ›´æ–°
- **feature/chinese-enhancement**: æˆ‘ä»¬çš„åŠŸèƒ½å¢å¼ºåˆ†æ”¯
- **hotfix/urgent-fixes**: ç´§æ€¥ä¿®å¤åˆ†æ”¯

### 3. åŒæ­¥æµç¨‹

#### æ ‡å‡†åŒæ­¥æµç¨‹

```bash
# 1. æ£€æŸ¥å½“å‰çŠ¶æ€
git status
git log --oneline -5

# 2. è·å–ä¸Šæ¸¸æ›´æ–°
git fetch upstream

# 3. æ£€æŸ¥æ–°æäº¤
git log --oneline HEAD..upstream/main

# 4. ä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬åŒæ­¥
python scripts/sync_upstream.py

# 5. è§£å†³å†²çªï¼ˆå¦‚æœæœ‰ï¼‰
# æ‰‹åŠ¨ç¼–è¾‘å†²çªæ–‡ä»¶
git add <resolved_files>
git commit

# 6. æµ‹è¯•åŒæ­¥ç»“æœ
python -m pytest tests/
python examples/basic_example.py

# 7. æ¨é€æ›´æ–°
git push origin main
```

#### ä½¿ç”¨è‡ªåŠ¨åŒ–è„šæœ¬

```bash
# åŸºæœ¬åŒæ­¥
python scripts/sync_upstream.py

# ä½¿ç”¨rebaseç­–ç•¥
python scripts/sync_upstream.py --strategy rebase

# è‡ªåŠ¨æ¨¡å¼ï¼ˆä¸è¯¢é—®ç¡®è®¤ï¼‰
python scripts/sync_upstream.py --auto
```

## âš ï¸ å†²çªå¤„ç†ç­–ç•¥

### å¸¸è§å†²çªç±»å‹

#### 1. æ–‡æ¡£å†²çª
**åŸå› **: æˆ‘ä»¬æœ‰å®Œæ•´çš„ä¸­æ–‡æ–‡æ¡£ï¼ŒåŸé¡¹ç›®å¯èƒ½æ›´æ–°è‹±æ–‡æ–‡æ¡£

**å¤„ç†ç­–ç•¥**:
```bash
# ä¿æŒæˆ‘ä»¬çš„ä¸­æ–‡æ–‡æ¡£ï¼Œå‚è€ƒåŸé¡¹ç›®æ›´æ–°å†…å®¹
# å†²çªæ–‡ä»¶: README.md, docs/
# è§£å†³æ–¹æ¡ˆ: ä¿ç•™æˆ‘ä»¬çš„ç‰ˆæœ¬ï¼Œæ‰‹åŠ¨åŒæ­¥æœ‰ä»·å€¼çš„å†…å®¹
```

#### 2. é…ç½®æ–‡ä»¶å†²çª
**åŸå› **: é…ç½®æ–‡ä»¶æ ¼å¼æˆ–é»˜è®¤å€¼å˜æ›´

**å¤„ç†ç­–ç•¥**:
```bash
# ä»”ç»†æ¯”è¾ƒå·®å¼‚ï¼Œåˆå¹¶æœ‰ä»·å€¼çš„é…ç½®
git diff HEAD upstream/main -- config/
# æ‰‹åŠ¨åˆå¹¶é…ç½®æ›´æ”¹
```

#### 3. ä»£ç åŠŸèƒ½å†²çª
**åŸå› **: æ ¸å¿ƒä»£ç é€»è¾‘å˜æ›´

**å¤„ç†ç­–ç•¥**:
```bash
# ä¼˜å…ˆé‡‡ç”¨ä¸Šæ¸¸ç‰ˆæœ¬ï¼Œç„¶åé‡æ–°åº”ç”¨æˆ‘ä»¬çš„å¢å¼º
# 1. æ¥å—ä¸Šæ¸¸ç‰ˆæœ¬
git checkout --theirs <conflicted_file>
# 2. é‡æ–°åº”ç”¨æˆ‘ä»¬çš„å¢å¼ºåŠŸèƒ½
# 3. æµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸
```

### å†²çªè§£å†³ä¼˜å…ˆçº§

1. **å®‰å…¨ä¿®å¤**: æœ€é«˜ä¼˜å…ˆçº§ï¼Œç«‹å³é‡‡ç”¨ä¸Šæ¸¸ç‰ˆæœ¬
2. **Bugä¿®å¤**: é«˜ä¼˜å…ˆçº§ï¼Œé€šå¸¸é‡‡ç”¨ä¸Šæ¸¸ç‰ˆæœ¬
3. **æ–°åŠŸèƒ½**: ä¸­ç­‰ä¼˜å…ˆçº§ï¼Œè¯„ä¼°åå†³å®šæ˜¯å¦é‡‡ç”¨
4. **æ–‡æ¡£æ›´æ–°**: ä½ä¼˜å…ˆçº§ï¼Œä¿æŒæˆ‘ä»¬çš„ä¸­æ–‡ç‰ˆæœ¬
5. **é…ç½®å˜æ›´**: ä½ä¼˜å…ˆçº§ï¼Œè°¨æ…åˆå¹¶

## ğŸ“‹ åŒæ­¥æ£€æŸ¥æ¸…å•

### åŒæ­¥å‰æ£€æŸ¥
- [ ] å½“å‰åˆ†æ”¯æ˜¯å¦å¹²å‡€ï¼ˆæ— æœªæäº¤æ›´æ”¹ï¼‰
- [ ] æ˜¯å¦æœ‰æ­£åœ¨è¿›è¡Œçš„åŠŸèƒ½å¼€å‘
- [ ] æ˜¯å¦æœ‰æœªè§£å†³çš„Issueéœ€è¦è€ƒè™‘
- [ ] å¤‡ä»½å½“å‰çŠ¶æ€ï¼ˆåˆ›å»ºæ ‡ç­¾ï¼‰

### åŒæ­¥è¿‡ç¨‹æ£€æŸ¥
- [ ] ä¸Šæ¸¸æ›´æ–°æ˜¯å¦è·å–æˆåŠŸ
- [ ] æ–°æäº¤æ˜¯å¦åŒ…å«é‡å¤§å˜æ›´
- [ ] æ˜¯å¦å­˜åœ¨åˆå¹¶å†²çª
- [ ] å†²çªæ˜¯å¦æ­£ç¡®è§£å†³

### åŒæ­¥åæ£€æŸ¥
- [ ] ä»£ç æ˜¯å¦èƒ½æ­£å¸¸è¿è¡Œ
- [ ] æµ‹è¯•æ˜¯å¦å…¨éƒ¨é€šè¿‡
- [ ] æ–‡æ¡£æ˜¯å¦éœ€è¦æ›´æ–°
- [ ] ä¸­æ–‡å¢å¼ºåŠŸèƒ½æ˜¯å¦æ­£å¸¸
- [ ] é…ç½®æ–‡ä»¶æ˜¯å¦æ­£ç¡®

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### è‡ªåŠ¨åŒ–æµ‹è¯•
```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
python -m pytest tests/ -v

# è¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•
python examples/basic_example.py

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python tests/performance_test.py
```

### æ‰‹åŠ¨æµ‹è¯•
```bash
# æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½
python -c "
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

ta = TradingAgentsGraph(debug=True, config=DEFAULT_CONFIG.copy())
state, decision = ta.propagate('AAPL', '2024-01-15')
print(f'Decision: {decision}')
"

# æµ‹è¯•ä¸­æ–‡æ–‡æ¡£
# æ£€æŸ¥ docs/ ç›®å½•ä¸‹çš„æ–‡æ¡£æ˜¯å¦æ­£å¸¸æ˜¾ç¤º
```

## ğŸ“Š åŒæ­¥è®°å½•

### åŒæ­¥æ—¥å¿—æ ¼å¼
```json
{
  "sync_time": "2024-01-15T10:30:00Z",
  "upstream_commits": 5,
  "conflicts_resolved": 2,
  "files_changed": ["tradingagents/core.py", "config/default.yaml"],
  "tests_passed": true,
  "notes": "åŒæ­¥äº†æ–°çš„é£é™©ç®¡ç†åŠŸèƒ½"
}
```

### ç‰ˆæœ¬æ ‡è®°ç­–ç•¥
```bash
# åŒæ­¥å‰åˆ›å»ºæ ‡ç­¾
git tag -a v1.0.0-cn-pre-sync -m "åŒæ­¥å‰çŠ¶æ€"

# åŒæ­¥ååˆ›å»ºæ ‡ç­¾
git tag -a v1.0.1-cn -m "åŒæ­¥ä¸Šæ¸¸æ›´æ–° v1.2.3"

# æ¨é€æ ‡ç­¾
git push origin --tags
```

## ğŸš¨ åº”æ€¥å¤„ç†

### åŒæ­¥å¤±è´¥å›æ»š
```bash
# å›æ»šåˆ°åŒæ­¥å‰çŠ¶æ€
git reset --hard v1.0.0-cn-pre-sync

# æˆ–è€…å›æ»šåˆ°ä¸Šä¸€ä¸ªæäº¤
git reset --hard HEAD~1

# å¼ºåˆ¶æ¨é€ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
git push origin main --force-with-lease
```

### ç´§æ€¥çƒ­ä¿®å¤
```bash
# åˆ›å»ºçƒ­ä¿®å¤åˆ†æ”¯
git checkout -b hotfix/urgent-fix

# åº”ç”¨ä¿®å¤
# ... ä¿®å¤ä»£ç  ...

# å¿«é€Ÿåˆå¹¶
git checkout main
git merge hotfix/urgent-fix
git push origin main

# åˆ é™¤çƒ­ä¿®å¤åˆ†æ”¯
git branch -d hotfix/urgent-fix
```

## ğŸ“… åŒæ­¥è®¡åˆ’

### å®šæœŸåŒæ­¥è®¡åˆ’
- **æ¯å‘¨ä¸€**: æ£€æŸ¥ä¸Šæ¸¸æ›´æ–°ï¼Œè¯„ä¼°åŒæ­¥éœ€æ±‚
- **æ¯æœˆç¬¬ä¸€å‘¨**: è¿›è¡Œå®Œæ•´åŒæ­¥å’Œæµ‹è¯•
- **é‡å¤§ç‰ˆæœ¬å‘å¸ƒå**: ç«‹å³è¯„ä¼°å’ŒåŒæ­¥

### ç‰¹æ®Šæƒ…å†µå¤„ç†
- **å®‰å…¨æ¼æ´**: 24å°æ—¶å†…åŒæ­¥
- **é‡å¤§Bug**: 48å°æ—¶å†…åŒæ­¥
- **æ–°åŠŸèƒ½**: 1å‘¨å†…è¯„ä¼°ï¼Œ2å‘¨å†…åŒæ­¥

## ğŸ¤ ç¤¾åŒºåä½œ

### ä¸åŸé¡¹ç›®äº’åŠ¨
- **IssueæŠ¥å‘Š**: å‘åŸé¡¹ç›®æŠ¥å‘Šå‘ç°çš„Bug
- **åŠŸèƒ½å»ºè®®**: æå‡ºæœ‰ä»·å€¼çš„åŠŸèƒ½å»ºè®®
- **ä»£ç è´¡çŒ®**: å°†é€šç”¨æ”¹è¿›è´¡çŒ®å›åŸé¡¹ç›®

### ç»´æŠ¤é€æ˜åº¦
- **åŒæ­¥æ—¥å¿—**: å…¬å¼€åŒæ­¥è®°å½•å’Œå†³ç­–è¿‡ç¨‹
- **å˜æ›´è¯´æ˜**: è¯¦ç»†è¯´æ˜æ¯æ¬¡åŒæ­¥çš„å†…å®¹
- **ç”¨æˆ·é€šçŸ¥**: åŠæ—¶é€šçŸ¥ç”¨æˆ·é‡è¦æ›´æ–°

é€šè¿‡è¿™å¥—å®Œæ•´çš„åŒæ­¥ç­–ç•¥ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿ TradingAgents-CN å§‹ç»ˆä¿æŒä¸åŸé¡¹ç›®çš„æŠ€æœ¯åŒæ­¥ï¼ŒåŒæ—¶ç»´æŠ¤æˆ‘ä»¬ç‹¬ç‰¹çš„ä¸­æ–‡å¢å¼ºä»·å€¼ã€‚


<!-- docs/overview/installation.md -->

# è¯¦ç»†å®‰è£…æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—æä¾›äº† TradingAgents æ¡†æ¶çš„è¯¦ç»†å®‰è£…è¯´æ˜ï¼ŒåŒ…æ‹¬ä¸åŒæ“ä½œç³»ç»Ÿçš„å®‰è£…æ­¥éª¤ã€ä¾èµ–ç®¡ç†ã€ç¯å¢ƒé…ç½®å’Œå¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆã€‚

## ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **CPU**: åŒæ ¸ 2.0GHz æˆ–æ›´é«˜ (æ¨èå››æ ¸)
- **å†…å­˜**: æœ€å°‘ 4GB RAM (æ¨è 8GB æˆ–æ›´é«˜)
- **å­˜å‚¨**: è‡³å°‘ 5GB å¯ç”¨ç£ç›˜ç©ºé—´
- **ç½‘ç»œ**: ç¨³å®šçš„äº’è”ç½‘è¿æ¥ (ç”¨äºAPIè°ƒç”¨å’Œæ•°æ®è·å–)

### è½¯ä»¶è¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: 
  - Windows 10/11 (64ä½)
  - macOS 10.15 (Catalina) æˆ–æ›´é«˜ç‰ˆæœ¬
  - Linux (Ubuntu 18.04+, CentOS 7+, æˆ–å…¶ä»–ä¸»æµå‘è¡Œç‰ˆ)
- **Python**: 3.10, 3.11, æˆ– 3.12 (æ¨è 3.11)
- **Git**: ç”¨äºå…‹éš†ä»£ç ä»“åº“

## å®‰è£…æ­¥éª¤

### 1. å®‰è£… Python

#### Windows
```powershell
# æ–¹æ³•1: ä»å®˜ç½‘ä¸‹è½½å®‰è£…åŒ…
# è®¿é—® https://www.python.org/downloads/windows/
# ä¸‹è½½ Python 3.11.x å®‰è£…åŒ…å¹¶è¿è¡Œ

# æ–¹æ³•2: ä½¿ç”¨ Chocolatey
choco install python311

# æ–¹æ³•3: ä½¿ç”¨ Microsoft Store
# åœ¨ Microsoft Store æœç´¢ "Python 3.11" å¹¶å®‰è£…

# éªŒè¯å®‰è£…
python --version
pip --version
```

#### macOS
```bash
# æ–¹æ³•1: ä½¿ç”¨ Homebrew (æ¨è)
brew install python@3.11

# æ–¹æ³•2: ä½¿ç”¨ pyenv
brew install pyenv
pyenv install 3.11.7
pyenv global 3.11.7

# æ–¹æ³•3: ä»å®˜ç½‘ä¸‹è½½
# è®¿é—® https://www.python.org/downloads/macos/

# éªŒè¯å®‰è£…
python3 --version
pip3 --version
```

#### Linux (Ubuntu/Debian)
```bash
# æ›´æ–°åŒ…åˆ—è¡¨
sudo apt update

# å®‰è£… Python 3.11
sudo apt install python3.11 python3.11-pip python3.11-venv

# è®¾ç½®é»˜è®¤ Python ç‰ˆæœ¬ (å¯é€‰)
sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1

# éªŒè¯å®‰è£…
python3 --version
pip3 --version
```

#### Linux (CentOS/RHEL)
```bash
# å®‰è£… EPEL ä»“åº“
sudo yum install epel-release

# å®‰è£… Python 3.11
sudo yum install python311 python311-pip

# æˆ–ä½¿ç”¨ dnf (è¾ƒæ–°ç‰ˆæœ¬)
sudo dnf install python3.11 python3.11-pip

# éªŒè¯å®‰è£…
python3.11 --version
pip3.11 --version
```

### 2. å…‹éš†é¡¹ç›®

```bash
# å…‹éš†é¡¹ç›®ä»“åº“
git clone https://github.com/TauricResearch/TradingAgents.git

# è¿›å…¥é¡¹ç›®ç›®å½•
cd TradingAgents

# æŸ¥çœ‹é¡¹ç›®ç»“æ„
ls -la
```

### 3. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

#### ä½¿ç”¨ venv (æ¨è)
```bash
# Windows
python -m venv tradingagents
tradingagents\Scripts\activate

# macOS/Linux
python3 -m venv tradingagents
source tradingagents/bin/activate

# éªŒè¯è™šæ‹Ÿç¯å¢ƒ
which python  # åº”è¯¥æŒ‡å‘è™šæ‹Ÿç¯å¢ƒä¸­çš„ Python
```

#### ä½¿ç”¨ conda
```bash
# åˆ›å»ºç¯å¢ƒ
conda create -n tradingagents python=3.11

# æ¿€æ´»ç¯å¢ƒ
conda activate tradingagents

# éªŒè¯ç¯å¢ƒ
conda info --envs
```

#### ä½¿ç”¨ pipenv
```bash
# å®‰è£… pipenv
pip install pipenv

# åˆ›å»ºç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
pipenv install

# æ¿€æ´»ç¯å¢ƒ
pipenv shell
```

### 4. å®‰è£…ä¾èµ–

#### åŸºç¡€å®‰è£…
```bash
# å‡çº§ pip
pip install --upgrade pip

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt

# éªŒè¯å®‰è£…
pip list | grep langchain
pip list | grep tradingagents
```

#### å¼€å‘ç¯å¢ƒå®‰è£…
```bash
# å®‰è£…å¼€å‘ä¾èµ– (å¦‚æœæœ‰ requirements-dev.txt)
pip install -r requirements-dev.txt

# æˆ–å®‰è£…å¯ç¼–è¾‘æ¨¡å¼
pip install -e .

# å®‰è£…é¢å¤–çš„å¼€å‘å·¥å…·
pip install pytest black flake8 mypy jupyter
```

#### å¯é€‰ä¾èµ–
```bash
# Redis æ”¯æŒ (ç”¨äºé«˜çº§ç¼“å­˜)
pip install redis

# æ•°æ®åº“æ”¯æŒ
pip install sqlalchemy psycopg2-binary

# å¯è§†åŒ–æ”¯æŒ
pip install matplotlib seaborn plotly

# Jupyter æ”¯æŒ
pip install jupyter ipykernel
python -m ipykernel install --user --name=tradingagents
```

### 5. é…ç½® API å¯†é’¥

#### è·å– API å¯†é’¥

**OpenAI API**
1. è®¿é—® [OpenAI Platform](https://platform.openai.com/)
2. æ³¨å†Œè´¦æˆ·å¹¶ç™»å½•
3. å¯¼èˆªåˆ° API Keys é¡µé¢
4. åˆ›å»ºæ–°çš„ API å¯†é’¥
5. å¤åˆ¶å¯†é’¥ (æ³¨æ„: åªæ˜¾ç¤ºä¸€æ¬¡)

**FinnHub API**
1. è®¿é—® [FinnHub](https://finnhub.io/)
2. æ³¨å†Œå…è´¹è´¦æˆ·
3. åœ¨ä»ªè¡¨æ¿ä¸­æ‰¾åˆ° API å¯†é’¥
4. å¤åˆ¶å¯†é’¥

**å…¶ä»–å¯é€‰ API**
- **Anthropic**: [console.anthropic.com](https://console.anthropic.com/)
- **Google AI**: [ai.google.dev](https://ai.google.dev/)

#### è®¾ç½®ç¯å¢ƒå˜é‡

**Windows (PowerShell)**
```powershell
# ä¸´æ—¶è®¾ç½® (å½“å‰ä¼šè¯)
$env:OPENAI_API_KEY="your_openai_api_key"
$env:FINNHUB_API_KEY="your_finnhub_api_key"

# æ°¸ä¹…è®¾ç½® (ç³»ç»Ÿç¯å¢ƒå˜é‡)
[Environment]::SetEnvironmentVariable("OPENAI_API_KEY", "your_openai_api_key", "User")
[Environment]::SetEnvironmentVariable("FINNHUB_API_KEY", "your_finnhub_api_key", "User")
```

**Windows (Command Prompt)**
```cmd
# ä¸´æ—¶è®¾ç½®
set OPENAI_API_KEY=your_openai_api_key
set FINNHUB_API_KEY=your_finnhub_api_key

# æ°¸ä¹…è®¾ç½® (éœ€è¦é‡å¯)
setx OPENAI_API_KEY "your_openai_api_key"
setx FINNHUB_API_KEY "your_finnhub_api_key"
```

**macOS/Linux**
```bash
# ä¸´æ—¶è®¾ç½® (å½“å‰ä¼šè¯)
export OPENAI_API_KEY="your_openai_api_key"
export FINNHUB_API_KEY="your_finnhub_api_key"

# æ°¸ä¹…è®¾ç½® (æ·»åŠ åˆ° ~/.bashrc æˆ– ~/.zshrc)
echo 'export OPENAI_API_KEY="your_openai_api_key"' >> ~/.bashrc
echo 'export FINNHUB_API_KEY="your_finnhub_api_key"' >> ~/.bashrc
source ~/.bashrc
```

#### ä½¿ç”¨ .env æ–‡ä»¶ (æ¨è)
```bash
# åˆ›å»º .env æ–‡ä»¶
cat > .env << EOF
OPENAI_API_KEY=your_openai_api_key
FINNHUB_API_KEY=your_finnhub_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
GOOGLE_API_KEY=your_google_api_key
TRADINGAGENTS_RESULTS_DIR=./results
TRADINGAGENTS_LOG_LEVEL=INFO
EOF

# å®‰è£… python-dotenv (å¦‚æœæœªå®‰è£…)
pip install python-dotenv
```

### 6. éªŒè¯å®‰è£…

#### åŸºæœ¬éªŒè¯
```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬
python --version

# æ£€æŸ¥å·²å®‰è£…çš„åŒ…
pip list | grep -E "(langchain|tradingagents|openai|finnhub)"

# æ£€æŸ¥ç¯å¢ƒå˜é‡
python -c "import os; print('OpenAI:', bool(os.getenv('OPENAI_API_KEY'))); print('FinnHub:', bool(os.getenv('FINNHUB_API_KEY')))"
```

#### åŠŸèƒ½éªŒè¯
```python
# test_installation.py
import sys
import os

def test_installation():
    """æµ‹è¯•å®‰è£…æ˜¯å¦æˆåŠŸ"""
    
    print("=== TradingAgents å®‰è£…éªŒè¯ ===\n")
    
    # 1. Python ç‰ˆæœ¬æ£€æŸ¥
    print(f"Python ç‰ˆæœ¬: {sys.version}")
    if sys.version_info < (3, 10):
        print("âŒ Python ç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦ 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬")
        return False
    else:
        print("âœ… Python ç‰ˆæœ¬ç¬¦åˆè¦æ±‚")
    
    # 2. ä¾èµ–åŒ…æ£€æŸ¥
    required_packages = [
        'langchain_openai',
        'langgraph',
        'finnhub',
        'pandas',
        'requests'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package} å·²å®‰è£…")
        except ImportError:
            print(f"âŒ {package} æœªå®‰è£…")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nç¼ºå°‘ä¾èµ–åŒ…: {missing_packages}")
        return False
    
    # 3. API å¯†é’¥æ£€æŸ¥
    api_keys = {
        'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY'),
        'FINNHUB_API_KEY': os.getenv('FINNHUB_API_KEY')
    }
    
    for key_name, key_value in api_keys.items():
        if key_value:
            print(f"âœ… {key_name} å·²è®¾ç½®")
        else:
            print(f"âŒ {key_name} æœªè®¾ç½®")
    
    # 4. TradingAgents å¯¼å…¥æµ‹è¯•
    try:
        from tradingagents.graph.trading_graph import TradingAgentsGraph
        from tradingagents.default_config import DEFAULT_CONFIG
        print("âœ… TradingAgents æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ TradingAgents å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    print("\nğŸ‰ å®‰è£…éªŒè¯å®Œæˆ!")
    return True

if __name__ == "__main__":
    success = test_installation()
    sys.exit(0 if success else 1)
```

è¿è¡ŒéªŒè¯è„šæœ¬:
```bash
python test_installation.py
```

## å¸¸è§é—®é¢˜è§£å†³

### 1. Python ç‰ˆæœ¬é—®é¢˜
```bash
# é—®é¢˜: python å‘½ä»¤æ‰¾ä¸åˆ°æˆ–ç‰ˆæœ¬é”™è¯¯
# è§£å†³æ–¹æ¡ˆ:

# Windows: ä½¿ç”¨ py å¯åŠ¨å™¨
py -3.11 --version

# macOS/Linux: ä½¿ç”¨å…·ä½“ç‰ˆæœ¬
python3.11 --version

# åˆ›å»ºåˆ«å (Linux/macOS)
alias python=python3.11
```

### 2. æƒé™é—®é¢˜
```bash
# é—®é¢˜: pip å®‰è£…æ—¶æƒé™è¢«æ‹’ç»
# è§£å†³æ–¹æ¡ˆ:

# ä½¿ç”¨ç”¨æˆ·å®‰è£…
pip install --user -r requirements.txt

# æˆ–ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ (æ¨è)
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate  # Windows
```

### 3. ç½‘ç»œè¿æ¥é—®é¢˜
```bash
# é—®é¢˜: pip å®‰è£…è¶…æ—¶æˆ–è¿æ¥å¤±è´¥
# è§£å†³æ–¹æ¡ˆ:

# ä½¿ç”¨å›½å†…é•œåƒæº
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/

# æˆ–é…ç½®æ°¸ä¹…é•œåƒæº
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple/
```

### 4. ä¾èµ–å†²çªé—®é¢˜
```bash
# é—®é¢˜: åŒ…ç‰ˆæœ¬å†²çª
# è§£å†³æ–¹æ¡ˆ:

# æ¸…ç†ç¯å¢ƒé‡æ–°å®‰è£…
pip freeze > installed_packages.txt
pip uninstall -r installed_packages.txt -y
pip install -r requirements.txt

# æˆ–ä½¿ç”¨æ–°çš„è™šæ‹Ÿç¯å¢ƒ
deactivate
rm -rf tradingagents  # åˆ é™¤æ—§ç¯å¢ƒ
python -m venv tradingagents
source tradingagents/bin/activate
pip install -r requirements.txt
```

### 5. API å¯†é’¥é—®é¢˜
```bash
# é—®é¢˜: API å¯†é’¥æ— æ•ˆæˆ–æœªè®¾ç½®
# è§£å†³æ–¹æ¡ˆ:

# æ£€æŸ¥å¯†é’¥æ ¼å¼
echo $OPENAI_API_KEY | wc -c  # åº”è¯¥æ˜¯ 51 å­—ç¬¦ (sk-...)

# é‡æ–°è®¾ç½®å¯†é’¥
unset OPENAI_API_KEY
export OPENAI_API_KEY="your_correct_api_key"

# æµ‹è¯• API è¿æ¥
python -c "
import openai
import os
client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
print('API è¿æ¥æµ‹è¯•æˆåŠŸ')
"
```

## é«˜çº§å®‰è£…é€‰é¡¹

### 1. Docker å®‰è£…
```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

ENV PYTHONPATH=/app

CMD ["python", "-m", "cli.main"]
```

```bash
# æ„å»ºé•œåƒ
docker build -t tradingagents .

# è¿è¡Œå®¹å™¨
docker run -e OPENAI_API_KEY=$OPENAI_API_KEY -e FINNHUB_API_KEY=$FINNHUB_API_KEY tradingagents
```

### 2. å¼€å‘ç¯å¢ƒè®¾ç½®
```bash
# å®‰è£…å¼€å‘å·¥å…·
pip install pre-commit black isort flake8 mypy pytest

# è®¾ç½® pre-commit hooks
pre-commit install

# é…ç½® IDE (VS Code)
code --install-extension ms-python.python
code --install-extension ms-python.black-formatter
```

### 3. æ€§èƒ½ä¼˜åŒ–
```bash
# å®‰è£…åŠ é€Ÿåº“
pip install numpy scipy numba

# GPU æ”¯æŒ (å¦‚æœéœ€è¦)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

## å¸è½½æŒ‡å—

### å®Œå…¨å¸è½½
```bash
# åœç”¨è™šæ‹Ÿç¯å¢ƒ
deactivate

# åˆ é™¤è™šæ‹Ÿç¯å¢ƒ
rm -rf tradingagents  # Linux/macOS
rmdir /s tradingagents  # Windows

# åˆ é™¤é¡¹ç›®æ–‡ä»¶
cd ..
rm -rf TradingAgents

# æ¸…ç†ç¯å¢ƒå˜é‡ (å¯é€‰)
unset OPENAI_API_KEY
unset FINNHUB_API_KEY
```

å®‰è£…å®Œæˆåï¼Œæ‚¨å¯ä»¥ç»§ç»­é˜…è¯» [å¿«é€Ÿå¼€å§‹æŒ‡å—](quick-start.md) æ¥å¼€å§‹ä½¿ç”¨ TradingAgentsã€‚


<!-- docs/overview/project-overview.md -->

# TradingAgents é¡¹ç›®æ¦‚è¿°

## é¡¹ç›®ç®€ä»‹

TradingAgents æ˜¯ä¸€ä¸ªåŸºäºå¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é‡‘èäº¤æ˜“æ¡†æ¶ï¼Œç”± Tauric Research å¼€å‘å¹¶å¼€æºã€‚æœ¬é¡¹ç›®ä¸ºä¸­æ–‡å¢å¼ºç‰ˆï¼ˆv0.1.4ï¼‰ï¼Œä¸“ä¸ºä¸­å›½ç”¨æˆ·æä¾›å®Œæ•´çš„Aè‚¡æ”¯æŒã€å›½äº§LLMé›†æˆå’Œä¸­æ–‡æ–‡æ¡£ä½“ç³»ã€‚

è¯¥é¡¹ç›®æ¨¡æ‹ŸçœŸå®ä¸–ç•Œäº¤æ˜“å…¬å¸çš„è¿ä½œæ¨¡å¼ï¼Œé€šè¿‡éƒ¨ç½²å¤šä¸ªä¸“ä¸šåŒ–çš„AIæ™ºèƒ½ä½“æ¥åä½œè¯„ä¼°å¸‚åœºæ¡ä»¶å¹¶åšå‡ºäº¤æ˜“å†³ç­–ã€‚

## é¡¹ç›®èƒŒæ™¯

### ç ”ç©¶åŠ¨æœº
ä¼ ç»Ÿçš„ç®—æ³•äº¤æ˜“ç³»ç»Ÿé€šå¸¸ä¾èµ–å•ä¸€çš„åˆ†ææ¨¡å‹æˆ–ç­–ç•¥ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚å¤šå˜çš„é‡‘èå¸‚åœºã€‚è€ŒçœŸå®çš„äº¤æ˜“å…¬å¸é€šå¸¸é‡‡ç”¨å›¢é˜Ÿåä½œçš„æ–¹å¼ï¼Œç”±ä¸åŒä¸“ä¸šèƒŒæ™¯çš„åˆ†æå¸ˆã€ç ”ç©¶å‘˜ã€äº¤æ˜“å‘˜å’Œé£é™©ç®¡ç†äººå‘˜å…±åŒå‚ä¸å†³ç­–è¿‡ç¨‹ã€‚

TradingAgents é¡¹ç›®çš„æ ¸å¿ƒç†å¿µæ˜¯å°†è¿™ç§äººç±»ä¸“å®¶å›¢é˜Ÿçš„åä½œæ¨¡å¼æ•°å­—åŒ–ï¼Œé€šè¿‡å¤šä¸ªä¸“ä¸šåŒ–çš„AIæ™ºèƒ½ä½“æ¥é‡ç°è¿™ç§åä½œå†³ç­–è¿‡ç¨‹ã€‚

### æŠ€æœ¯åˆ›æ–°
- **å¤šæ™ºèƒ½ä½“åä½œ**: é¦–æ¬¡å°†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåº”ç”¨äºé‡‘èäº¤æ˜“å†³ç­–
- **ä¸“ä¸šåŒ–åˆ†å·¥**: æ¯ä¸ªæ™ºèƒ½ä½“ä¸“æ³¨äºç‰¹å®šçš„åˆ†æé¢†åŸŸ
- **ç»“æ„åŒ–è¾©è®º**: é€šè¿‡æ™ºèƒ½ä½“é—´çš„è¾©è®ºæœºåˆ¶æé«˜å†³ç­–è´¨é‡
- **åŠ¨æ€é£é™©ç®¡ç†**: å®æ—¶è¯„ä¼°å’Œè°ƒæ•´æŠ•èµ„é£é™©

## æ ¸å¿ƒç‰¹æ€§

### 1. å¤šç»´åº¦å¸‚åœºåˆ†æ
- **åŸºæœ¬é¢åˆ†æ**: æ·±å…¥åˆ†æå…¬å¸è´¢åŠ¡æ•°æ®å’ŒåŸºæœ¬é¢æŒ‡æ ‡
- **æŠ€æœ¯åˆ†æ**: è¿ç”¨æŠ€æœ¯æŒ‡æ ‡è¯†åˆ«ä»·æ ¼è¶‹åŠ¿å’Œäº¤æ˜“ä¿¡å·
- **æ–°é—»åˆ†æ**: å®æ—¶ç›‘æ§å’Œåˆ†æå¸‚åœºæ–°é—»åŠå®è§‚äº‹ä»¶
- **æƒ…ç»ªåˆ†æ**: åˆ†æç¤¾äº¤åª’ä½“å’ŒæŠ•èµ„è€…æƒ…ç»ª

### 2. æ™ºèƒ½ä½“åä½œæœºåˆ¶
- **å¹¶è¡Œåˆ†æ**: å¤šä¸ªåˆ†æå¸ˆåŒæ—¶å·¥ä½œï¼Œæé«˜æ•ˆç‡
- **ç»“æ„åŒ–è¾©è®º**: çœ‹æ¶¨å’Œçœ‹è·Œç ”ç©¶å‘˜è¿›è¡Œè§‚ç‚¹äº¤é”‹
- **å…±è¯†å½¢æˆ**: é€šè¿‡åå•†æœºåˆ¶è¾¾æˆæŠ•èµ„å…±è¯†
- **é£é™©è¯„ä¼°**: å¤šå±‚æ¬¡é£é™©ç®¡ç†å’Œæ§åˆ¶

### 3. çµæ´»çš„æ¶æ„è®¾è®¡
- **æ¨¡å—åŒ–ç»„ä»¶**: æ˜“äºæ‰©å±•å’Œå®šåˆ¶
- **å¤šLLMæ”¯æŒ**: ğŸ‡¨ğŸ‡³ é˜¿é‡Œç™¾ç‚¼ã€Google AIã€OpenAIã€Anthropicç­‰
- **ç»Ÿä¸€é…ç½®**: ç®€åŒ–çš„.envé…ç½®ç³»ç»Ÿï¼Œå¯ç”¨å¼€å…³å®Œå…¨ç”Ÿæ•ˆ
- **æ™ºèƒ½é™çº§**: æ•°æ®åº“ä¸å¯ç”¨æ—¶è‡ªåŠ¨ä½¿ç”¨æ–‡ä»¶ç¼“å­˜

### 4. ä¸°å¯Œçš„æ•°æ®é›†æˆ
- **ğŸ‡¨ğŸ‡³ Aè‚¡æ•°æ®**: é€šè¾¾ä¿¡APIå®æ—¶è¡Œæƒ…å’Œå†å²æ•°æ® âœ…
- **ç¾è‚¡æ•°æ®**: FinnHubã€Yahoo Financeå®æ—¶æ•°æ® âœ…
- **æ–°é—»æ•°æ®**: Google Newsã€è´¢ç»æ–°é—»é›†æˆ âœ…
- **ç¤¾äº¤æ•°æ®**: Redditæƒ…ç»ªåˆ†æ âœ…
- **æ•°æ®åº“æ”¯æŒ**: MongoDB + Redis + æ™ºèƒ½ç¼“å­˜ âœ…

### 5. ç°ä»£åŒ–Webç•Œé¢ âœ… **v0.1.2æ–°å¢**
- **Streamlitç•Œé¢**: ç›´è§‚çš„Webç®¡ç†å¹³å°
- **å®æ—¶è¿›åº¦**: åˆ†æè¿‡ç¨‹å¯è§†åŒ–è·Ÿè¸ª
- **é…ç½®ç®¡ç†**: APIå¯†é’¥å’Œç³»ç»Ÿé…ç½®ç®¡ç†
- **Tokenç»Ÿè®¡**: å®æ—¶æˆæœ¬è¿½è¸ªå’Œä¼˜åŒ–å»ºè®®
- **å“åº”å¼è®¾è®¡**: æ”¯æŒæ¡Œé¢å’Œç§»åŠ¨ç«¯è®¿é—®

## åº”ç”¨åœºæ™¯

### 1. é‡åŒ–æŠ•èµ„ç ”ç©¶
- ç­–ç•¥å¼€å‘å’Œå›æµ‹
- å› å­æŒ–æ˜å’ŒéªŒè¯
- é£é™©æ¨¡å‹æ„å»º
- æŠ•èµ„ç»„åˆä¼˜åŒ–

### 2. é‡‘èç§‘æŠ€åº”ç”¨
- æ™ºèƒ½æŠ•é¡¾ç³»ç»Ÿ
- é£é™©ç®¡ç†å¹³å°
- å¸‚åœºåˆ†æå·¥å…·
- äº¤æ˜“å†³ç­–æ”¯æŒ

### 3. å­¦æœ¯ç ”ç©¶
- å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç ”ç©¶
- é‡‘èAIåº”ç”¨ç ”ç©¶
- è¡Œä¸ºé‡‘èå­¦ç ”ç©¶
- å¸‚åœºå¾®è§‚ç»“æ„ç ”ç©¶

### 4. æ•™è‚²åŸ¹è®­
- é‡‘èåˆ†ææ•™å­¦
- äº¤æ˜“ç­–ç•¥å­¦ä¹ 
- é£é™©ç®¡ç†åŸ¹è®­
- AIåº”ç”¨ç¤ºä¾‹

## æŠ€æœ¯ä¼˜åŠ¿

### 1. å…ˆè¿›çš„AIæŠ€æœ¯
- **å¤§è¯­è¨€æ¨¡å‹**: åˆ©ç”¨æœ€æ–°çš„LLMæŠ€æœ¯è¿›è¡Œé‡‘èåˆ†æ
- **å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**: å¤æ‚çš„åä½œå’Œå†³ç­–æœºåˆ¶
- **è‡ªç„¶è¯­è¨€å¤„ç†**: é«˜è´¨é‡çš„æ–‡æœ¬åˆ†æå’Œç†è§£
- **æœºå™¨å­¦ä¹ **: æŒç»­å­¦ä¹ å’Œä¼˜åŒ–èƒ½åŠ›

### 2. ä¸“ä¸šçš„é‡‘èçŸ¥è¯†
- **å…¨é¢çš„åˆ†ææ¡†æ¶**: è¦†ç›–åŸºæœ¬é¢ã€æŠ€æœ¯é¢ã€æ¶ˆæ¯é¢ç­‰å¤šä¸ªç»´åº¦
- **é£é™©ç®¡ç†**: å®Œå–„çš„é£é™©è¯†åˆ«ã€è¯„ä¼°å’Œæ§åˆ¶æœºåˆ¶
- **å¸‚åœºç†è§£**: æ·±å…¥çš„é‡‘èå¸‚åœºçŸ¥è¯†å’Œç»éªŒ
- **å®æˆ˜å¯¼å‘**: è´´è¿‘çœŸå®äº¤æ˜“ç¯å¢ƒçš„è®¾è®¡

### 3. å¼€æ”¾çš„ç”Ÿæ€ç³»ç»Ÿ
- **å¼€æºæ¡†æ¶**: å®Œå…¨å¼€æºï¼Œæ”¯æŒç¤¾åŒºè´¡çŒ®
- **æ ‡å‡†æ¥å£**: æ˜“äºé›†æˆå’Œæ‰©å±•
- **ä¸°å¯Œæ–‡æ¡£**: è¯¦ç»†çš„æŠ€æœ¯æ–‡æ¡£å’Œä½¿ç”¨æŒ‡å—
- **æ´»è·ƒç¤¾åŒº**: æŒç»­çš„ç»´æŠ¤å’Œæ”¹è¿›

## æ€§èƒ½è¡¨ç°

### 1. åˆ†æå‡†ç¡®æ€§
- å¤šç»´åº¦åˆ†ææé«˜é¢„æµ‹å‡†ç¡®æ€§
- æ™ºèƒ½ä½“åä½œå‡å°‘å•ç‚¹åå·®
- ç»“æ„åŒ–è¾©è®ºæå‡å†³ç­–è´¨é‡

### 2. ç³»ç»Ÿæ•ˆç‡
- å¹¶è¡Œå¤„ç†æé«˜åˆ†æé€Ÿåº¦
- æ™ºèƒ½ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—
- ä¼˜åŒ–çš„æ•°æ®æµæå‡æ€§èƒ½

### 3. é£é™©æ§åˆ¶
- å¤šå±‚æ¬¡é£é™©è¯„ä¼°
- å®æ—¶é£é™©ç›‘æ§
- åŠ¨æ€é£é™©è°ƒæ•´

## å‘å±•è·¯çº¿å›¾

### çŸ­æœŸç›®æ ‡ (3-6ä¸ªæœˆ)
- å®Œå–„æ ¸å¿ƒåŠŸèƒ½
- ä¼˜åŒ–æ€§èƒ½è¡¨ç°
- æ‰©å±•æ•°æ®æºæ”¯æŒ
- å¢å¼ºç”¨æˆ·ä½“éªŒ

### ä¸­æœŸç›®æ ‡ (6-12ä¸ªæœˆ)
- æ”¯æŒæ›´å¤šèµ„äº§ç±»åˆ«
- å¢åŠ é«˜çº§åˆ†æåŠŸèƒ½
- å¼€å‘å¯è§†åŒ–ç•Œé¢
- æ„å»ºæ’ä»¶ç”Ÿæ€

### é•¿æœŸç›®æ ‡ (1-2å¹´)
- å®ç°å®ç›˜äº¤æ˜“æ”¯æŒ
- å¼€å‘ç§»åŠ¨ç«¯åº”ç”¨
- å»ºç«‹å•†ä¸šåŒ–æ¨¡å¼
- æ‹“å±•å›½é™…å¸‚åœº

## ç¤¾åŒºä¸ç”Ÿæ€

### å¼€æºç¤¾åŒº
- **GitHub**: ä»£ç æ‰˜ç®¡å’Œåä½œå¼€å‘
- **Discord**: å®æ—¶äº¤æµå’ŒæŠ€æœ¯æ”¯æŒ
- **è®ºå›**: æ·±åº¦è®¨è®ºå’Œç»éªŒåˆ†äº«
- **æ–‡æ¡£**: æŒç»­æ›´æ–°çš„æŠ€æœ¯æ–‡æ¡£

### åˆä½œä¼™ä¼´
- **å­¦æœ¯æœºæ„**: ä¸é«˜æ ¡å’Œç ”ç©¶é™¢æ‰€åˆä½œ
- **é‡‘èæœºæ„**: ä¸é“¶è¡Œã€åŸºé‡‘ç­‰æœºæ„åˆä½œ
- **æŠ€æœ¯å…¬å¸**: ä¸AIå’Œé‡‘èç§‘æŠ€å…¬å¸åˆä½œ
- **æ•°æ®æä¾›å•†**: ä¸æ•°æ®ä¾›åº”å•†å»ºç«‹åˆä½œ

### è´¡çŒ®æ–¹å¼
- **ä»£ç è´¡çŒ®**: æäº¤ä»£ç æ”¹è¿›å’Œæ–°åŠŸèƒ½
- **æ–‡æ¡£å®Œå–„**: æ”¹è¿›æ–‡æ¡£å’Œæ•™ç¨‹
- **é—®é¢˜åé¦ˆ**: æŠ¥å‘Šbugå’Œæå‡ºå»ºè®®
- **ç¤¾åŒºå»ºè®¾**: å‚ä¸è®¨è®ºå’Œå¸®åŠ©ä»–äºº

## å…è´£å£°æ˜

TradingAgents æ¡†æ¶ä»…ç”¨äºç ”ç©¶å’Œæ•™è‚²ç›®çš„ã€‚äº¤æ˜“è¡¨ç°å¯èƒ½å› å¤šç§å› ç´ è€Œå¼‚ï¼ŒåŒ…æ‹¬æ‰€é€‰æ‹©çš„éª¨å¹²è¯­è¨€æ¨¡å‹ã€æ¨¡å‹æ¸©åº¦ã€äº¤æ˜“å‘¨æœŸã€æ•°æ®è´¨é‡å’Œå…¶ä»–éç¡®å®šæ€§å› ç´ ã€‚

**æœ¬æ¡†æ¶ä¸æ„æˆè´¢åŠ¡ã€æŠ•èµ„æˆ–äº¤æ˜“å»ºè®®ã€‚** ç”¨æˆ·åœ¨ä½¿ç”¨æœ¬æ¡†æ¶è¿›è¡Œä»»ä½•æŠ•èµ„å†³ç­–æ—¶ï¼Œåº”å½“è°¨æ…è¯„ä¼°é£é™©ï¼Œå¹¶å’¨è¯¢ä¸“ä¸šçš„è´¢åŠ¡é¡¾é—®ã€‚

## è”ç³»æˆ‘ä»¬

- **å®˜æ–¹ç½‘ç«™**: [https://tauric.ai](https://tauric.ai)
- **GitHub**: [https://github.com/TauricResearch/TradingAgents](https://github.com/TauricResearch/TradingAgents)
- **Discord**: [TradingResearch](https://discord.com/invite/hk9PGKShPK)
- **Twitter**: [@TauricResearch](https://x.com/TauricResearch)
- **é‚®ç®±**: contact@tauric.ai

TradingAgents ä»£è¡¨äº†é‡‘èAIæŠ€æœ¯çš„å‰æ²¿æ¢ç´¢ï¼Œæˆ‘ä»¬æœŸå¾…ä¸å…¨çƒçš„ç ”ç©¶è€…ã€å¼€å‘è€…å’Œé‡‘èä¸“å®¶ä¸€èµ·ï¼Œæ¨åŠ¨è¿™ä¸€é¢†åŸŸçš„å‘å±•å’Œåˆ›æ–°ã€‚


<!-- docs/overview/quick-start.md -->

# å¿«é€Ÿå¼€å§‹æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹ TradingAgents æ¡†æ¶ï¼Œä»å®‰è£…åˆ°è¿è¡Œç¬¬ä¸€ä¸ªäº¤æ˜“åˆ†æï¼Œåªéœ€å‡ åˆ†é’Ÿæ—¶é—´ã€‚

## å‰ç½®è¦æ±‚

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Windows 10+, macOS 10.15+, æˆ– Linux
- **Python**: 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬
- **å†…å­˜**: è‡³å°‘ 4GB RAM (æ¨è 8GB+)
- **å­˜å‚¨**: è‡³å°‘ 2GB å¯ç”¨ç©ºé—´

### API å¯†é’¥
åœ¨å¼€å§‹ä¹‹å‰ï¼Œæ‚¨éœ€è¦è·å–ä»¥ä¸‹APIå¯†é’¥ï¼š

1. **ğŸ‡¨ğŸ‡³ é˜¿é‡Œç™¾ç‚¼ API Key** (æ¨è)
   - è®¿é—® [é˜¿é‡Œäº‘ç™¾ç‚¼å¹³å°](https://dashscope.aliyun.com/)
   - æ³¨å†Œè´¦æˆ·å¹¶è·å–APIå¯†é’¥
   - å›½äº§æ¨¡å‹ï¼Œæ— éœ€ç§‘å­¦ä¸Šç½‘ï¼Œå“åº”é€Ÿåº¦å¿«

2. **FinnHub API Key** (å¿…éœ€)
   - è®¿é—® [FinnHub](https://finnhub.io/)
   - æ³¨å†Œå…è´¹è´¦æˆ·å¹¶è·å–APIå¯†é’¥

3. **Google AI API Key** (æ¨è)
   - è®¿é—® [Google AI Studio](https://aistudio.google.com/)
   - è·å–å…è´¹APIå¯†é’¥ï¼Œæ”¯æŒGeminiæ¨¡å‹

4. **å…¶ä»–APIå¯†é’¥** (å¯é€‰)
   - OpenAI API (éœ€è¦ç§‘å­¦ä¸Šç½‘)
   - Anthropic API (éœ€è¦ç§‘å­¦ä¸Šç½‘)

## å¿«é€Ÿå®‰è£…

### 1. å…‹éš†é¡¹ç›®
```bash
# å…‹éš†ä¸­æ–‡å¢å¼ºç‰ˆ
git clone https://github.com/hsliuping/TradingAgents-CN.git
cd TradingAgents-CN
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
# ä½¿ç”¨ conda
conda create -n tradingagents python=3.13
conda activate tradingagents

# æˆ–ä½¿ç”¨ venv
python -m venv tradingagents
source tradingagents/bin/activate  # Linux/macOS
# tradingagents\Scripts\activate  # Windows
```

### 3. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 4. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼ˆæ¨èæ–¹å¼ï¼‰ï¼š
```bash
# å¤åˆ¶é…ç½®æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œé…ç½®ä»¥ä¸‹APIå¯†é’¥ï¼š

# ğŸ‡¨ğŸ‡³ é˜¿é‡Œç™¾ç‚¼ (æ¨è)
DASHSCOPE_API_KEY=your_dashscope_api_key_here

# FinnHub (å¿…éœ€)
FINNHUB_API_KEY=your_finnhub_api_key_here

# Google AI (å¯é€‰)
GOOGLE_API_KEY=your_google_api_key_here

# æ•°æ®åº“é…ç½® (å¯é€‰ï¼Œé»˜è®¤ç¦ç”¨)
MONGODB_ENABLED=false
REDIS_ENABLED=false
```

## ç¬¬ä¸€æ¬¡è¿è¡Œ

### ğŸŒ ä½¿ç”¨Webç•Œé¢ (æ¨è)

æœ€ç®€å•çš„å¼€å§‹æ–¹å¼æ˜¯ä½¿ç”¨Webç®¡ç†ç•Œé¢ï¼š

```bash
# å¯åŠ¨Webç•Œé¢
streamlit run web/app.py
```

ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—® `http://localhost:8501`

Webç•Œé¢æä¾›ï¼š
1. ğŸ›ï¸ ç›´è§‚çš„è‚¡ç¥¨åˆ†æç•Œé¢
2. âš™ï¸ APIå¯†é’¥å’Œé…ç½®ç®¡ç†
3. ğŸ“Š å®æ—¶åˆ†æè¿›åº¦æ˜¾ç¤º
4. ğŸ’° Tokenä½¿ç”¨ç»Ÿè®¡
5. ğŸ‡¨ğŸ‡³ å®Œæ•´çš„ä¸­æ–‡ç•Œé¢

### ä½¿ç”¨å‘½ä»¤è¡Œç•Œé¢ (CLI)

å¦‚æœæ‚¨åå¥½å‘½ä»¤è¡Œï¼š

```bash
python -m cli.main
```

### ä½¿ç”¨ Python API

åˆ›å»ºä¸€ä¸ªç®€å•çš„Pythonè„šæœ¬ï¼š

```python
# quick_start.py
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

# åˆ›å»ºé…ç½®
config = DEFAULT_CONFIG.copy()
config["deep_think_llm"] = "gpt-4o-mini"  # ä½¿ç”¨è¾ƒä¾¿å®œçš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
config["quick_think_llm"] = "gpt-4o-mini"
config["max_debate_rounds"] = 1  # å‡å°‘è¾©è®ºè½®æ¬¡ä»¥èŠ‚çœæˆæœ¬
config["online_tools"] = True  # ä½¿ç”¨åœ¨çº¿æ•°æ®

# åˆå§‹åŒ–äº¤æ˜“æ™ºèƒ½ä½“å›¾
ta = TradingAgentsGraph(debug=True, config=config)

# æ‰§è¡Œåˆ†æ
print("å¼€å§‹åˆ†æ AAPL...")
state, decision = ta.propagate("AAPL", "2024-01-15")

# è¾“å‡ºç»“æœ
print("\n=== åˆ†æç»“æœ ===")
print(f"æ¨èåŠ¨ä½œ: {decision.get('action', 'hold')}")
print(f"ç½®ä¿¡åº¦: {decision.get('confidence', 0.5):.2f}")
print(f"é£é™©è¯„åˆ†: {decision.get('risk_score', 0.5):.2f}")
print(f"æ¨ç†è¿‡ç¨‹: {decision.get('reasoning', 'N/A')}")
```

è¿è¡Œè„šæœ¬ï¼š
```bash
python quick_start.py
```

## é…ç½®é€‰é¡¹

### åŸºæœ¬é…ç½®
```python
config = {
    # LLM è®¾ç½®
    "llm_provider": "openai",           # æˆ– "anthropic", "google"
    "deep_think_llm": "gpt-4o-mini",    # æ·±åº¦æ€è€ƒæ¨¡å‹
    "quick_think_llm": "gpt-4o-mini",   # å¿«é€Ÿæ€è€ƒæ¨¡å‹
    
    # è¾©è®ºè®¾ç½®
    "max_debate_rounds": 1,             # è¾©è®ºè½®æ¬¡ (1-5)
    "max_risk_discuss_rounds": 1,       # é£é™©è®¨è®ºè½®æ¬¡
    
    # æ•°æ®è®¾ç½®
    "online_tools": True,               # ä½¿ç”¨åœ¨çº¿æ•°æ®
}
```

### æ™ºèƒ½ä½“é€‰æ‹©
```python
# é€‰æ‹©è¦ä½¿ç”¨çš„åˆ†æå¸ˆ
selected_analysts = [
    "market",        # æŠ€æœ¯åˆ†æå¸ˆ
    "fundamentals",  # åŸºæœ¬é¢åˆ†æå¸ˆ
    "news",         # æ–°é—»åˆ†æå¸ˆ
    "social"        # ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ
]

ta = TradingAgentsGraph(
    selected_analysts=selected_analysts,
    debug=True,
    config=config
)
```

## ç¤ºä¾‹åˆ†ææµç¨‹

### å®Œæ•´çš„åˆ†æç¤ºä¾‹
```python
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG
import json

def analyze_stock(symbol, date):
    """åˆ†ææŒ‡å®šè‚¡ç¥¨"""
    
    # é…ç½®
    config = DEFAULT_CONFIG.copy()
    config["deep_think_llm"] = "gpt-4o-mini"
    config["quick_think_llm"] = "gpt-4o-mini"
    config["max_debate_rounds"] = 2
    config["online_tools"] = True
    
    # åˆ›å»ºåˆ†æå™¨
    ta = TradingAgentsGraph(
        selected_analysts=["market", "fundamentals", "news", "social"],
        debug=True,
        config=config
    )
    
    print(f"æ­£åœ¨åˆ†æ {symbol} ({date})...")
    
    try:
        # æ‰§è¡Œåˆ†æ
        state, decision = ta.propagate(symbol, date)
        
        # è¾“å‡ºè¯¦ç»†ç»“æœ
        print("\n" + "="*50)
        print(f"è‚¡ç¥¨: {symbol}")
        print(f"æ—¥æœŸ: {date}")
        print("="*50)
        
        print(f"\nğŸ“Š æœ€ç»ˆå†³ç­–:")
        print(f"  åŠ¨ä½œ: {decision.get('action', 'hold').upper()}")
        print(f"  æ•°é‡: {decision.get('quantity', 0)}")
        print(f"  ç½®ä¿¡åº¦: {decision.get('confidence', 0.5):.1%}")
        print(f"  é£é™©è¯„åˆ†: {decision.get('risk_score', 0.5):.1%}")
        
        print(f"\nğŸ’­ æ¨ç†è¿‡ç¨‹:")
        print(f"  {decision.get('reasoning', 'N/A')}")
        
        # åˆ†æå¸ˆæŠ¥å‘Šæ‘˜è¦
        if hasattr(state, 'analyst_reports'):
            print(f"\nğŸ“ˆ åˆ†æå¸ˆæŠ¥å‘Šæ‘˜è¦:")
            for analyst, report in state.analyst_reports.items():
                score = report.get('overall_score', report.get('score', 0.5))
                print(f"  {analyst}: {score:.1%}")
        
        return decision
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return None

# è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    # åˆ†æè‹¹æœå…¬å¸è‚¡ç¥¨
    result = analyze_stock("AAPL", "2024-01-15")
    
    if result:
        print("\nâœ… åˆ†æå®Œæˆ!")
    else:
        print("\nâŒ åˆ†æå¤±è´¥!")
```

## å¸¸è§é—®é¢˜è§£å†³

### 1. API å¯†é’¥é”™è¯¯
```
é”™è¯¯: OpenAI API key not found
è§£å†³: ç¡®ä¿æ­£ç¡®è®¾ç½®äº† OPENAI_API_KEY ç¯å¢ƒå˜é‡
```

### 2. ç½‘ç»œè¿æ¥é—®é¢˜
```
é”™è¯¯: Connection timeout
è§£å†³: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–ä½¿ç”¨ä»£ç†è®¾ç½®
```

### 3. å†…å­˜ä¸è¶³
```
é”™è¯¯: Out of memory
è§£å†³: å‡å°‘ max_debate_rounds æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹
```

### 4. æ•°æ®è·å–å¤±è´¥
```
é”™è¯¯: Failed to fetch data
è§£å†³: æ£€æŸ¥ FINNHUB_API_KEY æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç¨åé‡è¯•
```

## æˆæœ¬æ§åˆ¶å»ºè®®

### 1. ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
```python
config["deep_think_llm"] = "gpt-4o-mini"    # è€Œä¸æ˜¯ "gpt-4o"
config["quick_think_llm"] = "gpt-4o-mini"   # è€Œä¸æ˜¯ "gpt-4o"
```

### 2. å‡å°‘è¾©è®ºè½®æ¬¡
```python
config["max_debate_rounds"] = 1              # è€Œä¸æ˜¯ 3-5
config["max_risk_discuss_rounds"] = 1        # è€Œä¸æ˜¯ 2-3
```

### 3. é€‰æ‹©æ€§ä½¿ç”¨åˆ†æå¸ˆ
```python
# åªä½¿ç”¨æ ¸å¿ƒåˆ†æå¸ˆ
selected_analysts = ["market", "fundamentals"]  # è€Œä¸æ˜¯å…¨éƒ¨å››ä¸ª
```

### 4. ä½¿ç”¨ç¼“å­˜æ•°æ®
```python
config["online_tools"] = False  # ä½¿ç”¨ç¼“å­˜æ•°æ®è€Œä¸æ˜¯å®æ—¶æ•°æ®
```

## ä¸‹ä¸€æ­¥

ç°åœ¨æ‚¨å·²ç»æˆåŠŸè¿è¡Œäº†ç¬¬ä¸€ä¸ªåˆ†æï¼Œå¯ä»¥ï¼š

1. **æ¢ç´¢æ›´å¤šåŠŸèƒ½**: æŸ¥çœ‹ [APIå‚è€ƒæ–‡æ¡£](../api/core-api.md)
2. **è‡ªå®šä¹‰é…ç½®**: é˜…è¯» [é…ç½®æŒ‡å—](../configuration/config-guide.md)
3. **å¼€å‘è‡ªå®šä¹‰æ™ºèƒ½ä½“**: å‚è€ƒ [æ‰©å±•å¼€å‘æŒ‡å—](../development/extending.md)
4. **æŸ¥çœ‹æ›´å¤šç¤ºä¾‹**: æµè§ˆ [ç¤ºä¾‹å’Œæ•™ç¨‹](../examples/basic-examples.md)

## è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ï¼š
- æŸ¥çœ‹ [å¸¸è§é—®é¢˜](../faq/faq.md)
- è®¿é—® [GitHub Issues](https://github.com/TauricResearch/TradingAgents/issues)
- åŠ å…¥ [Discord ç¤¾åŒº](https://discord.com/invite/hk9PGKShPK)
- æŸ¥çœ‹ [æ•…éšœæ’é™¤æŒ‡å—](../faq/troubleshooting.md)

ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼ğŸš€


<!-- docs/research-depth-guide.md -->

# ç ”ç©¶æ·±åº¦é…ç½®æŒ‡å—

## ğŸ“Š ç ”ç©¶æ·±åº¦çº§åˆ«è¯´æ˜

TradingAgents-CN æä¾›5ä¸ªç ”ç©¶æ·±åº¦çº§åˆ«ï¼Œæ¯ä¸ªçº§åˆ«åœ¨åˆ†æè´¨é‡ã€è€—æ—¶å’Œèµ„æºæ¶ˆè€—æ–¹é¢æœ‰ä¸åŒçš„å¹³è¡¡ã€‚

### ğŸš€ 1çº§ - å¿«é€Ÿåˆ†æ
**é€‚ç”¨åœºæ™¯**: æ—¥å¸¸å¿«é€Ÿå†³ç­–ã€å¸‚åœºæ¦‚è§ˆ

**é…ç½®ç‰¹ç‚¹**:
- âš¡ **è¾©è®ºè½®æ¬¡**: 1è½® (æœ€å°‘)
- ğŸ§  **æ¨¡å‹é€‰æ‹©**: qwen-turbo + qwen-plus (æœ€å¿«)
- ğŸ’¾ **è®°å¿†åŠŸèƒ½**: ç¦ç”¨ (åŠ é€Ÿ)
- ğŸŒ **åœ¨çº¿å·¥å…·**: ç¦ç”¨ (ä½¿ç”¨ç¼“å­˜æ•°æ®)
- â±ï¸ **é¢„æœŸè€—æ—¶**: 2-4åˆ†é’Ÿ
- ğŸ’° **æˆæœ¬**: æœ€ä½

**ä¼˜ç‚¹**:
- é€Ÿåº¦æœ€å¿«
- æˆæœ¬æœ€ä½
- é€‚åˆé¢‘ç¹æŸ¥è¯¢

**ç¼ºç‚¹**:
- åˆ†ææ·±åº¦æœ‰é™
- å¯èƒ½é”™è¿‡ç»†èŠ‚ä¿¡æ¯

---

### ğŸ“ˆ 2çº§ - åŸºç¡€åˆ†æ
**é€‚ç”¨åœºæ™¯**: å¸¸è§„æŠ•èµ„å†³ç­–ã€åŸºç¡€ç ”ç©¶

**é…ç½®ç‰¹ç‚¹**:
- âš¡ **è¾©è®ºè½®æ¬¡**: 1è½®
- ğŸ§  **æ¨¡å‹é€‰æ‹©**: qwen-plus + qwen-plus (å¹³è¡¡)
- ğŸ’¾ **è®°å¿†åŠŸèƒ½**: å¯ç”¨
- ğŸŒ **åœ¨çº¿å·¥å…·**: å¯ç”¨ (è·å–æœ€æ–°æ•°æ®)
- â±ï¸ **é¢„æœŸè€—æ—¶**: 4-6åˆ†é’Ÿ
- ğŸ’° **æˆæœ¬**: è¾ƒä½

**ä¼˜ç‚¹**:
- é€Ÿåº¦è¾ƒå¿«
- åŒ…å«æœ€æ–°æ•°æ®
- æˆæœ¬å¯æ§

**ç¼ºç‚¹**:
- è¾©è®ºæ·±åº¦æœ‰é™

---

### ğŸ¯ 3çº§ - æ ‡å‡†åˆ†æ (é»˜è®¤æ¨è)
**é€‚ç”¨åœºæ™¯**: é‡è¦æŠ•èµ„å†³ç­–ã€æ ‡å‡†ç ”ç©¶æµç¨‹

**é…ç½®ç‰¹ç‚¹**:
- âš¡ **è¾©è®ºè½®æ¬¡**: 1è½® (ç ”ç©¶å‘˜) + 2è½® (é£é™©è¯„ä¼°)
- ğŸ§  **æ¨¡å‹é€‰æ‹©**: qwen-plus + qwen-max (è´¨é‡ä¼˜å…ˆ)
- ğŸ’¾ **è®°å¿†åŠŸèƒ½**: å¯ç”¨
- ğŸŒ **åœ¨çº¿å·¥å…·**: å¯ç”¨
- â±ï¸ **é¢„æœŸè€—æ—¶**: 6-10åˆ†é’Ÿ
- ğŸ’° **æˆæœ¬**: ä¸­ç­‰

**ä¼˜ç‚¹**:
- å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡
- é£é™©è¯„ä¼°æ›´æ·±å…¥
- é€‚åˆå¤§å¤šæ•°åœºæ™¯

**ç¼ºç‚¹**:
- è€—æ—¶é€‚ä¸­

---

### ğŸ”¬ 4çº§ - æ·±åº¦åˆ†æ
**é€‚ç”¨åœºæ™¯**: é‡å¤§æŠ•èµ„å†³ç­–ã€è¯¦ç»†ç ”ç©¶æŠ¥å‘Š

**é…ç½®ç‰¹ç‚¹**:
- âš¡ **è¾©è®ºè½®æ¬¡**: 2è½® (ç ”ç©¶å‘˜) + 2è½® (é£é™©è¯„ä¼°)
- ğŸ§  **æ¨¡å‹é€‰æ‹©**: qwen-plus + qwen-max (é«˜è´¨é‡)
- ğŸ’¾ **è®°å¿†åŠŸèƒ½**: å¯ç”¨
- ğŸŒ **åœ¨çº¿å·¥å…·**: å¯ç”¨
- â±ï¸ **é¢„æœŸè€—æ—¶**: 10-15åˆ†é’Ÿ
- ğŸ’° **æˆæœ¬**: è¾ƒé«˜

**ä¼˜ç‚¹**:
- åˆ†ææ·±åº¦é«˜
- å¤šè½®è¾©è®ºç¡®ä¿å…¨é¢æ€§
- é€‚åˆé‡è¦å†³ç­–

**ç¼ºç‚¹**:
- è€—æ—¶è¾ƒé•¿
- æˆæœ¬è¾ƒé«˜

---

### ğŸ† 5çº§ - å…¨é¢åˆ†æ
**é€‚ç”¨åœºæ™¯**: æœ€é‡è¦çš„æŠ•èµ„å†³ç­–ã€å®Œæ•´ç ”ç©¶æŠ¥å‘Š

**é…ç½®ç‰¹ç‚¹**:
- âš¡ **è¾©è®ºè½®æ¬¡**: 3è½® (ç ”ç©¶å‘˜) + 3è½® (é£é™©è¯„ä¼°)
- ğŸ§  **æ¨¡å‹é€‰æ‹©**: qwen-max + qwen-max (æœ€é«˜è´¨é‡)
- ğŸ’¾ **è®°å¿†åŠŸèƒ½**: å¯ç”¨
- ğŸŒ **åœ¨çº¿å·¥å…·**: å¯ç”¨
- â±ï¸ **é¢„æœŸè€—æ—¶**: 15-25åˆ†é’Ÿ
- ğŸ’° **æˆæœ¬**: æœ€é«˜

**ä¼˜ç‚¹**:
- æœ€å…¨é¢çš„åˆ†æ
- æœ€é«˜è´¨é‡çš„æ¨ç†
- æœ€å¯é çš„ç»“æœ

**ç¼ºç‚¹**:
- è€—æ—¶æœ€é•¿
- æˆæœ¬æœ€é«˜

## ğŸ“‹ é€‰æ‹©å»ºè®®

### ğŸ¯ æ ¹æ®ä½¿ç”¨åœºæ™¯é€‰æ‹©

| åœºæ™¯ | æ¨èçº§åˆ« | ç†ç”± |
|------|----------|------|
| æ—¥å¸¸å¸‚åœºç›‘æ§ | 1-2çº§ | å¿«é€Ÿè·å–å¸‚åœºæ¦‚å†µ |
| å¸¸è§„æŠ•èµ„å†³ç­– | 2-3çº§ | å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡ |
| é‡è¦æŠ•èµ„å†³ç­– | 3-4çº§ | ç¡®ä¿åˆ†æè´¨é‡ |
| é‡å¤§èµ„é‡‘æŠ•å…¥ | 4-5çº§ | æœ€å…¨é¢çš„é£é™©è¯„ä¼° |
| ç ”ç©¶æŠ¥å‘Šæ’°å†™ | 4-5çº§ | éœ€è¦è¯¦ç»†çš„åˆ†æå†…å®¹ |

### â° æ ¹æ®æ—¶é—´é¢„ç®—é€‰æ‹©

| å¯ç”¨æ—¶é—´ | æ¨èçº§åˆ« | é¢„æœŸç»“æœ |
|----------|----------|----------|
| 2-5åˆ†é’Ÿ | 1-2çº§ | å¿«é€Ÿå†³ç­–å‚è€ƒ |
| 5-10åˆ†é’Ÿ | 2-3çº§ | æ ‡å‡†æŠ•èµ„å»ºè®® |
| 10-15åˆ†é’Ÿ | 3-4çº§ | æ·±åº¦åˆ†ææŠ¥å‘Š |
| 15åˆ†é’Ÿä»¥ä¸Š | 4-5çº§ | æœ€å…¨é¢çš„ç ”ç©¶ |

### ğŸ’° æ ¹æ®æˆæœ¬è€ƒè™‘é€‰æ‹©

| é¢„ç®—è€ƒè™‘ | æ¨èçº§åˆ« | æˆæœ¬æ•ˆç›Š |
|----------|----------|----------|
| æˆæœ¬æ•æ„Ÿ | 1-2çº§ | æœ€ç»æµçš„é€‰æ‹© |
| å¹³è¡¡è€ƒè™‘ | 2-3çº§ | æ€§ä»·æ¯”æœ€é«˜ |
| è´¨é‡ä¼˜å…ˆ | 3-4çº§ | é«˜è´¨é‡åˆ†æ |
| ä¸è®¡æˆæœ¬ | 4-5çº§ | æœ€ä½³è´¨é‡ |

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### è¾©è®ºè½®æ¬¡å½±å“
- **1è½®**: åŸºç¡€è§‚ç‚¹äº¤æ¢
- **2è½®**: æ·±å…¥è®¨è®ºå’Œåé©³
- **3è½®**: å…¨é¢è¾©è®ºå’Œå…±è¯†

### æ¨¡å‹é€‰æ‹©å½±å“
- **qwen-turbo**: é€Ÿåº¦æœ€å¿«ï¼Œé€‚åˆå¿«é€Ÿåˆ†æ
- **qwen-plus**: å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡
- **qwen-max**: æœ€é«˜è´¨é‡ï¼Œé€‚åˆæ·±åº¦åˆ†æ

### è®°å¿†åŠŸèƒ½å½±å“
- **å¯ç”¨**: ä»å†å²å†³ç­–ä¸­å­¦ä¹ ï¼Œæé«˜å‡†ç¡®æ€§
- **ç¦ç”¨**: åŠ å¿«åˆ†æé€Ÿåº¦ï¼Œé™ä½æˆæœ¬

### åœ¨çº¿å·¥å…·å½±å“
- **å¯ç”¨**: è·å–æœ€æ–°å¸‚åœºæ•°æ®
- **ç¦ç”¨**: ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼ŒåŠ å¿«é€Ÿåº¦

## ğŸ’¡ æœ€ä½³å®è·µ

1. **é¦–æ¬¡ä½¿ç”¨**: å»ºè®®ä»3çº§å¼€å§‹ï¼Œäº†è§£ç³»ç»Ÿèƒ½åŠ›
2. **æ—¥å¸¸ç›‘æ§**: ä½¿ç”¨1-2çº§è¿›è¡Œå¿«é€Ÿæ‰«æ
3. **é‡è¦å†³ç­–**: ä½¿ç”¨3-4çº§ç¡®ä¿è´¨é‡
4. **å…³é”®æŠ•èµ„**: ä½¿ç”¨4-5çº§è·å¾—æœ€å…¨é¢åˆ†æ
5. **æˆæœ¬æ§åˆ¶**: æ ¹æ®æŠ•èµ„é‡‘é¢è°ƒæ•´åˆ†æçº§åˆ«

## ğŸ¯ æ€»ç»“

ç ”ç©¶æ·±åº¦çº§åˆ«æ˜¯æ§åˆ¶åˆ†æè´¨é‡ã€é€Ÿåº¦å’Œæˆæœ¬çš„æ ¸å¿ƒå‚æ•°ã€‚é€‰æ‹©åˆé€‚çš„çº§åˆ«å¯ä»¥ï¼š

- âœ… ä¼˜åŒ–åˆ†ææ—¶é—´
- âœ… æ§åˆ¶ä½¿ç”¨æˆæœ¬  
- âœ… è·å¾—é€‚å½“çš„åˆ†ææ·±åº¦
- âœ… æ»¡è¶³ä¸åŒåœºæ™¯éœ€æ±‚

å»ºè®®æ ¹æ®å…·ä½“çš„æŠ•èµ„åœºæ™¯ã€æ—¶é—´é¢„ç®—å’Œè´¨é‡è¦æ±‚æ¥é€‰æ‹©æœ€é€‚åˆçš„ç ”ç©¶æ·±åº¦çº§åˆ«ã€‚


<!-- docs/security/api_keys_security.md -->

# APIå¯†é’¥å®‰å…¨æŒ‡å—

## ğŸš¨ é‡è¦å®‰å…¨æé†’

### âš ï¸ ç»å¯¹ä¸è¦åšçš„äº‹æƒ…

1. **ä¸è¦å°†.envæ–‡ä»¶æäº¤åˆ°Gitä»“åº“**
   - .envæ–‡ä»¶åŒ…å«æ•æ„Ÿçš„APIå¯†é’¥
   - ä¸€æ—¦æäº¤åˆ°å…¬å¼€ä»“åº“ï¼Œå¯†é’¥å¯èƒ½è¢«æ¶æ„ä½¿ç”¨
   - å³ä½¿åˆ é™¤æäº¤ï¼ŒGitå†å²ä¸­ä»ç„¶å­˜åœ¨

2. **ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç APIå¯†é’¥**
   ```python
   # âŒ é”™è¯¯åšæ³•
   api_key = "sk-1234567890abcdef"
   
   # âœ… æ­£ç¡®åšæ³•
   api_key = os.getenv("DASHSCOPE_API_KEY")
   ```

3. **ä¸è¦åœ¨æ—¥å¿—ä¸­è¾“å‡ºå®Œæ•´çš„APIå¯†é’¥**
   ```python
   # âŒ é”™è¯¯åšæ³•
   print(f"Using API key: {api_key}")
   
   # âœ… æ­£ç¡®åšæ³•
   print(f"Using API key: {api_key[:12]}...")
   ```

### âœ… å®‰å…¨æœ€ä½³å®è·µ

#### 1. ä½¿ç”¨ç¯å¢ƒå˜é‡
```bash
# åœ¨.envæ–‡ä»¶ä¸­é…ç½®
DASHSCOPE_API_KEY=your_real_api_key_here
FINNHUB_API_KEY=your_real_finnhub_key_here
```

#### 2. æ­£ç¡®çš„æ–‡ä»¶æƒé™
```bash
# è®¾ç½®.envæ–‡ä»¶åªæœ‰æ‰€æœ‰è€…å¯è¯»å†™
chmod 600 .env
```

#### 3. ä½¿ç”¨.gitignore
ç¡®ä¿.gitignoreåŒ…å«ï¼š
```
.env
.env.local
.env.*.local
```

#### 4. å®šæœŸè½®æ¢APIå¯†é’¥
- å®šæœŸæ›´æ¢APIå¯†é’¥
- å¦‚æœæ€€ç–‘å¯†é’¥æ³„éœ²ï¼Œç«‹å³æ›´æ¢
- ç›‘æ§APIä½¿ç”¨æƒ…å†µï¼Œå‘ç°å¼‚å¸¸ç«‹å³å¤„ç†

## ğŸ”§ é…ç½®æ­¥éª¤

### 1. å¤åˆ¶ç¤ºä¾‹æ–‡ä»¶
```bash
cp .env.example .env
```

### 2. ç¼–è¾‘.envæ–‡ä»¶
```bash
# ä½¿ç”¨æ‚¨å–œæ¬¢çš„ç¼–è¾‘å™¨
notepad .env        # Windows
nano .env           # Linux/Mac
code .env           # VS Code
```

### 3. å¡«å…¥çœŸå®APIå¯†é’¥
```bash
# é˜¿é‡Œç™¾ç‚¼APIå¯†é’¥ (æ¨è)
DASHSCOPE_API_KEY=sk-your-real-dashscope-key

# é‡‘èæ•°æ®APIå¯†é’¥ (å¿…éœ€)
FINNHUB_API_KEY=your-real-finnhub-key
```

### 4. éªŒè¯é…ç½®
```bash
python -m cli.main config
```

## ğŸ” APIå¯†é’¥è·å–æŒ‡å—

### é˜¿é‡Œç™¾ç‚¼ (æ¨è)
1. è®¿é—® https://dashscope.aliyun.com/
2. æ³¨å†Œ/ç™»å½•é˜¿é‡Œäº‘è´¦å·
3. å¼€é€šç™¾ç‚¼æœåŠ¡
4. åœ¨æ§åˆ¶å°è·å–APIå¯†é’¥

### FinnHub (å¿…éœ€)
1. è®¿é—® https://finnhub.io/
2. æ³¨å†Œå…è´¹è´¦å·
3. åœ¨Dashboardè·å–APIå¯†é’¥
4. å…è´¹è´¦æˆ·æ¯åˆ†é’Ÿ60æ¬¡è¯·æ±‚

### OpenAI (å¯é€‰)
1. è®¿é—® https://platform.openai.com/
2. æ³¨å†Œè´¦å·å¹¶å……å€¼
3. åœ¨API Keysé¡µé¢åˆ›å»ºå¯†é’¥

## ğŸš¨ å¦‚æœAPIå¯†é’¥æ³„éœ²äº†æ€ä¹ˆåŠï¼Ÿ

### ç«‹å³è¡ŒåŠ¨
1. **ç«‹å³æ’¤é”€æ³„éœ²çš„APIå¯†é’¥**
   - ç™»å½•å¯¹åº”çš„APIæä¾›å•†æ§åˆ¶å°
   - åˆ é™¤æˆ–ç¦ç”¨æ³„éœ²çš„å¯†é’¥

2. **ç”Ÿæˆæ–°çš„APIå¯†é’¥**
   - åˆ›å»ºæ–°çš„APIå¯†é’¥
   - æ›´æ–°.envæ–‡ä»¶ä¸­çš„é…ç½®

3. **æ£€æŸ¥ä½¿ç”¨è®°å½•**
   - æŸ¥çœ‹APIä½¿ç”¨æ—¥å¿—
   - ç¡®è®¤æ˜¯å¦æœ‰å¼‚å¸¸ä½¿ç”¨

4. **æ›´æ–°ä»£ç é…ç½®**
   - æ›´æ–°æœ¬åœ°.envæ–‡ä»¶
   - é€šçŸ¥å›¢é˜Ÿæˆå‘˜æ›´æ–°é…ç½®

### é¢„é˜²æªæ–½
1. **ä½¿ç”¨Git hooks**
   - è®¾ç½®pre-commit hooksæ£€æŸ¥æ•æ„Ÿæ–‡ä»¶
   - é˜²æ­¢æ„å¤–æäº¤.envæ–‡ä»¶

2. **å®šæœŸå®¡è®¡**
   - å®šæœŸæ£€æŸ¥Gitå†å²
   - ç¡®ä¿æ²¡æœ‰æ•æ„Ÿä¿¡æ¯æ³„éœ²

3. **å›¢é˜ŸåŸ¹è®­**
   - åŸ¹è®­å›¢é˜Ÿæˆå‘˜å®‰å…¨æ„è¯†
   - å»ºç«‹å®‰å…¨æ“ä½œè§„èŒƒ

## ğŸ“‹ å®‰å…¨æ£€æŸ¥æ¸…å•

- [ ] .envæ–‡ä»¶å·²æ·»åŠ åˆ°.gitignore
- [ ] æ²¡æœ‰åœ¨ä»£ç ä¸­ç¡¬ç¼–ç APIå¯†é’¥
- [ ] .envæ–‡ä»¶æƒé™è®¾ç½®æ­£ç¡® (600)
- [ ] å®šæœŸè½®æ¢APIå¯†é’¥
- [ ] ç›‘æ§APIä½¿ç”¨æƒ…å†µ
- [ ] å›¢é˜Ÿæˆå‘˜äº†è§£å®‰å…¨è§„èŒƒ
- [ ] è®¾ç½®äº†pre-commit hooks (å¯é€‰)

## ğŸ”— ç›¸å…³èµ„æº

- [Gitå®‰å…¨æœ€ä½³å®è·µ](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure)
- [ç¯å¢ƒå˜é‡å®‰å…¨æŒ‡å—](https://12factor.net/config)
- [APIå¯†é’¥ç®¡ç†æœ€ä½³å®è·µ](https://owasp.org/www-project-api-security/)

---

**è®°ä½ï¼šå®‰å…¨æ— å°äº‹ï¼ŒAPIå¯†é’¥ä¿æŠ¤æ˜¯æ¯ä¸ªå¼€å‘è€…çš„è´£ä»»ï¼** ğŸ”


<!-- docs/troubleshooting/finnhub-news-data-setup.md -->

# Finnhubæ–°é—»æ•°æ®é…ç½®æŒ‡å—

## é—®é¢˜æè¿°

å¦‚æœæ‚¨é‡åˆ°ä»¥ä¸‹é”™è¯¯ä¿¡æ¯ï¼š

```
[DEBUG] FinnhubNewsToolè°ƒç”¨ï¼Œè‚¡ç¥¨ä»£ç : AAPL 
è·å–æ–°é—»æ•°æ®å¤±è´¥: [Errno 2] No such file or directory: '/Users/yluo/Documents/Code/ScAI/FR1-data\\finnhub_data\\news_data\\AAPL_data_formatted.json'
```

è¿™è¡¨æ˜å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
1. **è·¯å¾„é…ç½®é”™è¯¯**ï¼šæ··åˆäº†Unixå’ŒWindowsè·¯å¾„åˆ†éš”ç¬¦
2. **æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨**ï¼šç¼ºå°‘Finnhubæ–°é—»æ•°æ®æ–‡ä»¶
3. **æ•°æ®ç›®å½•é…ç½®**ï¼šæ•°æ®ç›®å½•è·¯å¾„ä¸æ­£ç¡®

## è§£å†³æ–¹æ¡ˆ

### 1. è·¯å¾„ä¿®å¤ï¼ˆå·²è‡ªåŠ¨ä¿®å¤ï¼‰

æˆ‘ä»¬å·²ç»ä¿®å¤äº† `tradingagents/default_config.py` ä¸­çš„è·¯å¾„é…ç½®ï¼š

```python
# ä¿®å¤å‰ï¼ˆç¡¬ç¼–ç Unixè·¯å¾„ï¼‰
"data_dir": "/Users/yluo/Documents/Code/ScAI/FR1-data",

# ä¿®å¤åï¼ˆè·¨å¹³å°å…¼å®¹è·¯å¾„ï¼‰
"data_dir": os.path.join(os.path.expanduser("~"), "Documents", "TradingAgents", "data"),
```

### 2. æ•°æ®ç›®å½•ç»“æ„

æ­£ç¡®çš„æ•°æ®ç›®å½•ç»“æ„åº”è¯¥æ˜¯ï¼š

```
~/Documents/TradingAgents/data/
â”œâ”€â”€ finnhub_data/
â”‚   â”œâ”€â”€ news_data/
â”‚   â”‚   â”œâ”€â”€ AAPL_data_formatted.json
â”‚   â”‚   â”œâ”€â”€ TSLA_data_formatted.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ insider_senti/
â”‚   â”œâ”€â”€ insider_trans/
â”‚   â””â”€â”€ ...
â””â”€â”€ other_data/
```

### 3. è·å–Finnhubæ•°æ®

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨APIä¸‹è½½ï¼ˆæ¨èï¼‰

1. **é…ç½®Finnhub APIå¯†é’¥**
   ```bash
   # åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ 
   FINNHUB_API_KEY=your_finnhub_api_key_here
   ```

2. **è¿è¡Œæ•°æ®ä¸‹è½½è„šæœ¬**
   ```bash
   # ä¸‹è½½æ–°é—»æ•°æ®
   python scripts/download_finnhub_data.py --data-type news --symbols AAPL,TSLA,MSFT
   
   # æˆ–è€…ä¸‹è½½æ‰€æœ‰æ•°æ®
   python scripts/download_finnhub_data.py --all
   ```

#### æ–¹æ³•äºŒï¼šæ‰‹åŠ¨åˆ›å»ºæµ‹è¯•æ•°æ®

å¦‚æœæ‚¨åªæ˜¯æƒ³æµ‹è¯•åŠŸèƒ½ï¼Œå¯ä»¥åˆ›å»ºç¤ºä¾‹æ•°æ®ï¼š

```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºç¤ºä¾‹æ•°æ®
python tests/test_finnhub_news_fix.py
```

### 4. éªŒè¯é…ç½®

è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®ï¼š

```bash
# éªŒè¯è·¯å¾„ä¿®å¤
python tests/test_finnhub_news_fix.py

# æµ‹è¯•æ–°é—»æ•°æ®è·å–
python -c "
from tradingagents.dataflows.interface import get_finnhub_news
result = get_finnhub_news('AAPL', '2025-01-02', 7)
print(result[:200])
"
```

## é”™è¯¯å¤„ç†æ”¹è¿›

æˆ‘ä»¬å·²ç»æ”¹è¿›äº†é”™è¯¯å¤„ç†ï¼Œç°åœ¨å½“æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æ—¶ï¼Œä¼šæ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼š

```
âš ï¸ æ— æ³•è·å–AAPLçš„æ–°é—»æ•°æ® (2024-12-26 åˆ° 2025-01-02)
å¯èƒ½çš„åŸå› ï¼š
1. æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„é…ç½®é”™è¯¯
2. æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ–°é—»æ•°æ®
3. éœ€è¦å…ˆä¸‹è½½æˆ–æ›´æ–°Finnhubæ–°é—»æ•°æ®
å»ºè®®ï¼šæ£€æŸ¥æ•°æ®ç›®å½•é…ç½®æˆ–é‡æ–°è·å–æ–°é—»æ•°æ®
```

## é…ç½®é€‰é¡¹

### è‡ªå®šä¹‰æ•°æ®ç›®å½•

å¦‚æœæ‚¨æƒ³ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®ç›®å½•ï¼Œå¯ä»¥åœ¨ä»£ç ä¸­è®¾ç½®ï¼š

```python
from tradingagents.dataflows.config import set_config

# è®¾ç½®è‡ªå®šä¹‰æ•°æ®ç›®å½•
config = {
    "data_dir": "C:/your/custom/data/directory"
}
set_config(config)
```

### ç¯å¢ƒå˜é‡é…ç½®

æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®ï¼š

```bash
# Windows
set TRADINGAGENTS_DATA_DIR=C:\your\custom\data\directory

# Linux/Mac
export TRADINGAGENTS_DATA_DIR=/your/custom/data/directory
```

## å¸¸è§é—®é¢˜

### Q1: æ•°æ®ç›®å½•æƒé™é—®é¢˜

**é—®é¢˜**ï¼šæ— æ³•åˆ›å»ºæˆ–å†™å…¥æ•°æ®ç›®å½•

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# Windowsï¼ˆä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œï¼‰
mkdir "C:\Users\%USERNAME%\Documents\TradingAgents\data"

# Linux/Mac
mkdir -p ~/Documents/TradingAgents/data
chmod 755 ~/Documents/TradingAgents/data
```

### Q2: Finnhub APIé…é¢é™åˆ¶

**é—®é¢˜**ï¼šAPIè°ƒç”¨æ¬¡æ•°è¶…é™

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å‡çº§Finnhub APIè®¡åˆ’
2. ä½¿ç”¨ç¼“å­˜å‡å°‘APIè°ƒç”¨
3. é™åˆ¶æ•°æ®è·å–é¢‘ç‡

### Q3: æ•°æ®æ ¼å¼é”™è¯¯

**é—®é¢˜**ï¼šJSONæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# éªŒè¯JSONæ ¼å¼
python -c "import json; print(json.load(open('path/to/file.json')))"

# é‡æ–°ä¸‹è½½æ•°æ®
python scripts/download_finnhub_data.py --force-refresh
```

## æŠ€æœ¯ç»†èŠ‚

### ä¿®å¤çš„æ–‡ä»¶

1. **`tradingagents/default_config.py`**
   - ä¿®å¤ç¡¬ç¼–ç çš„Unixè·¯å¾„
   - ä½¿ç”¨è·¨å¹³å°å…¼å®¹çš„è·¯å¾„æ„å»º

2. **`tradingagents/dataflows/finnhub_utils.py`**
   - æ·»åŠ æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
   - æ”¹è¿›é”™è¯¯å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯
   - ä½¿ç”¨UTF-8ç¼–ç è¯»å–æ–‡ä»¶

3. **`tradingagents/dataflows/interface.py`**
   - æ”¹è¿›get_finnhub_newså‡½æ•°çš„é”™è¯¯æç¤º
   - æä¾›è¯¦ç»†çš„æ•…éšœæ’é™¤å»ºè®®

### è·¯å¾„å¤„ç†é€»è¾‘

```python
# è·¨å¹³å°è·¯å¾„æ„å»º
data_path = os.path.join(
    data_dir, 
    "finnhub_data", 
    "news_data", 
    f"{ticker}_data_formatted.json"
)

# æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
if not os.path.exists(data_path):
    print(f"âš ï¸ [DEBUG] æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
    return {}
```

## è”ç³»æ”¯æŒ

å¦‚æœæ‚¨ä»ç„¶é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š

1. è¿è¡Œè¯Šæ–­è„šæœ¬ï¼š`python tests/test_finnhub_news_fix.py`
2. æ£€æŸ¥æ—¥å¿—è¾“å‡ºä¸­çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯
3. ç¡®è®¤Finnhub APIå¯†é’¥é…ç½®æ­£ç¡®
4. æä¾›å®Œæ•´çš„é”™è¯¯å †æ ˆä¿¡æ¯

---

**æ›´æ–°æ—¥æœŸ**ï¼š2025-01-02  
**ç‰ˆæœ¬**ï¼šv1.0  
**é€‚ç”¨èŒƒå›´**ï¼šTradingAgents-CN v0.1.3+

<!-- docs/troubleshooting/streamlit-file-watcher-fix.md -->

# Streamlitæ–‡ä»¶ç›‘æ§é”™è¯¯è§£å†³æ–¹æ¡ˆ

## é—®é¢˜æè¿°

åœ¨è¿è¡ŒStreamlit Webåº”ç”¨æ—¶ï¼Œå¯èƒ½ä¼šé‡åˆ°ä»¥ä¸‹é”™è¯¯ï¼š

```
Exception in thread Thread-9:
Traceback (most recent call last):
  File "C:\Users\PC\AppData\Local\Programs\Python\Python310\lib\threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "C:\code\TradingAgentsCN\env\lib\site-packages\watchdog\observers\api.py", line 213, in run
    self.dispatch_events(self.event_queue)
  ...
FileNotFoundError: [WinError 2] ç³»ç»Ÿæ‰¾ä¸åˆ°æŒ‡å®šçš„æ–‡ä»¶ã€‚: 'C:\\code\\TradingAgentsCN\\web\\pages\\__pycache__\\config_management.cpython-310.pyc.2375409084592'
```

## é—®é¢˜åŸå› 

è¿™ä¸ªé”™è¯¯æ˜¯ç”±Streamlitçš„æ–‡ä»¶ç›‘æ§ç³»ç»Ÿï¼ˆwatchdogï¼‰å¼•èµ·çš„ï¼š

1. **Pythonå­—èŠ‚ç æ–‡ä»¶ç”Ÿæˆ**ï¼šå½“Pythonè¿è¡Œæ—¶ï¼Œä¼šåœ¨`__pycache__`ç›®å½•ä¸­ç”Ÿæˆ`.pyc`å­—èŠ‚ç æ–‡ä»¶
2. **ä¸´æ—¶æ–‡ä»¶å‘½å**ï¼šPythonæœ‰æ—¶ä¼šåˆ›å»ºå¸¦æœ‰éšæœºåç¼€çš„ä¸´æ—¶å­—èŠ‚ç æ–‡ä»¶
3. **æ–‡ä»¶ç›‘æ§å†²çª**ï¼šStreamlitçš„watchdogç›‘æ§å™¨ä¼šå°è¯•ç›‘æ§è¿™äº›ä¸´æ—¶æ–‡ä»¶
4. **æ–‡ä»¶åˆ é™¤ç«äº‰**ï¼šå½“Pythonåˆ é™¤æˆ–é‡å‘½åè¿™äº›ä¸´æ—¶æ–‡ä»¶æ—¶ï¼Œwatchdogä»åœ¨å°è¯•è®¿é—®å®ƒä»¬
5. **FileNotFoundError**ï¼šå¯¼è‡´æ–‡ä»¶æœªæ‰¾åˆ°é”™è¯¯

## è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šStreamlité…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰

æˆ‘ä»¬å·²ç»åˆ›å»ºäº†`.streamlit/config.toml`é…ç½®æ–‡ä»¶æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼š

```toml
[server.fileWatcher]
# ç¦ç”¨å¯¹ä¸´æ—¶æ–‡ä»¶å’Œç¼“å­˜æ–‡ä»¶çš„ç›‘æ§
watcherType = "auto"
# æ’é™¤__pycache__ç›®å½•å’Œ.pycæ–‡ä»¶
excludePatterns = [
    "**/__pycache__/**",
    "**/*.pyc",
    "**/*.pyo",
    "**/*.pyd",
    "**/.git/**",
    "**/node_modules/**",
    "**/.env",
    "**/venv/**",
    "**/env/**"
]
```

### æ–¹æ¡ˆ2ï¼šæ¸…ç†ç¼“å­˜æ–‡ä»¶

å®šæœŸæ¸…ç†Pythonç¼“å­˜æ–‡ä»¶ï¼š

```bash
# Windows PowerShell
Get-ChildItem -Path . -Recurse -Name "__pycache__" | Remove-Item -Recurse -Force

# Linux/macOS
find . -type d -name "__pycache__" -exec rm -rf {} +
```

### æ–¹æ¡ˆ3ï¼šç¯å¢ƒå˜é‡è®¾ç½®

è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨Pythonå­—èŠ‚ç ç”Ÿæˆï¼š

```bash
# åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ 
PYTHONDONTWRITEBYTECODE=1
```

æˆ–åœ¨å¯åŠ¨è„šæœ¬ä¸­ï¼š

```python
import os
os.environ['PYTHONDONTWRITEBYTECODE'] = '1'
```

## éªŒè¯è§£å†³æ–¹æ¡ˆ

1. **é‡å¯Streamlitåº”ç”¨**ï¼š
   ```bash
   python web/run_web.py
   ```

2. **æ£€æŸ¥é…ç½®ç”Ÿæ•ˆ**ï¼š
   - ç¡®è®¤`.streamlit/config.toml`æ–‡ä»¶å­˜åœ¨
   - è§‚å¯Ÿæ˜¯å¦è¿˜æœ‰æ–‡ä»¶ç›‘æ§é”™è¯¯

3. **ç›‘æ§æ—¥å¿—**ï¼š
   - æŸ¥çœ‹æ§åˆ¶å°è¾“å‡º
   - ç¡®è®¤æ²¡æœ‰FileNotFoundError

## é¢„é˜²æªæ–½

1. **ä¿æŒ.gitignoreæ›´æ–°**ï¼šç¡®ä¿`__pycache__/`å’Œ`*.pyc`åœ¨.gitignoreä¸­
2. **å®šæœŸæ¸…ç†**ï¼šå®šæœŸæ¸…ç†å¼€å‘ç¯å¢ƒä¸­çš„ç¼“å­˜æ–‡ä»¶
3. **é…ç½®ç›‘æ§**ï¼šä½¿ç”¨Streamlité…ç½®æ–‡ä»¶æ’é™¤ä¸å¿…è¦çš„æ–‡ä»¶ç›‘æ§
4. **ç¯å¢ƒéš”ç¦»**ï¼šä½¿ç”¨è™šæ‹Ÿç¯å¢ƒé¿å…å…¨å±€Pythonç¯å¢ƒæ±¡æŸ“

## ç›¸å…³æ–‡æ¡£

- [Streamlité…ç½®æ–‡æ¡£](https://docs.streamlit.io/library/advanced-features/configuration)
- [Pythonå­—èŠ‚ç æ–‡ä»¶è¯´æ˜](https://docs.python.org/3/tutorial/modules.html#compiled-python-files)
- [Watchdogæ–‡ä»¶ç›‘æ§åº“](https://python-watchdog.readthedocs.io/)

## å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆä¼šç”Ÿæˆè¿™äº›ä¸´æ—¶æ–‡ä»¶ï¼Ÿ**
A: Pythonåœ¨ç¼–è¯‘æ¨¡å—æ—¶ä¼šåˆ›å»ºå­—èŠ‚ç æ–‡ä»¶ä»¥æé«˜åŠ è½½é€Ÿåº¦ï¼Œæœ‰æ—¶ä¼šä½¿ç”¨ä¸´æ—¶æ–‡ä»¶åé¿å…å†²çªã€‚

**Q: è¿™ä¸ªé”™è¯¯ä¼šå½±å“åº”ç”¨åŠŸèƒ½å—ï¼Ÿ**
A: é€šå¸¸ä¸ä¼šå½±å“æ ¸å¿ƒåŠŸèƒ½ï¼Œä½†ä¼šåœ¨æ§åˆ¶å°äº§ç”Ÿé”™è¯¯æ—¥å¿—ï¼Œå½±å“å¼€å‘ä½“éªŒã€‚

**Q: å¯ä»¥å®Œå…¨ç¦ç”¨æ–‡ä»¶ç›‘æ§å—ï¼Ÿ**
A: ä¸å»ºè®®ï¼Œæ–‡ä»¶ç›‘æ§ç”¨äºçƒ­é‡è½½åŠŸèƒ½ã€‚å»ºè®®ä½¿ç”¨æ’é™¤æ¨¡å¼è€Œä¸æ˜¯å®Œå…¨ç¦ç”¨ã€‚

## æ›´æ–°æ—¥å¿—

- **2025-01-03**: åˆ›å»ºè§£å†³æ–¹æ¡ˆæ–‡æ¡£
- **2025-01-03**: æ·»åŠ Streamlité…ç½®æ–‡ä»¶
- **2025-01-03**: æ›´æ–°.gitignoreè§„åˆ™

<!-- docs/usage/investment_analysis_guide.md -->

# TradingAgents-CN æŠ•èµ„åˆ†æä½¿ç”¨æŒ‡å—

## ğŸ¯ æ¦‚è¿°

TradingAgents-CN æ˜¯ä¸€ä¸ªåŸºäºå¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹çš„æŠ•èµ„åˆ†ææ¡†æ¶ï¼Œèƒ½å¤Ÿä¸ºæ‚¨æä¾›ä¸“ä¸šçš„è‚¡ç¥¨åˆ†ææŠ¥å‘Šã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€é…ç½®

ç¡®ä¿æ‚¨å·²ç»é…ç½®äº†å¿…è¦çš„APIå¯†é’¥ï¼š

```bash
# æ£€æŸ¥é…ç½®çŠ¶æ€
python -m cli.main config

# è¿è¡Œé›†æˆæµ‹è¯•
python -m cli.main test
```

### 2. ä½¿ç”¨æ–¹å¼é€‰æ‹©

#### ğŸŒ Webç•Œé¢ (æ¨èæ–°æ‰‹)
```bash
# å¯åŠ¨Webç•Œé¢
python -m streamlit run web/app.py
```
ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—® `http://localhost:8501`

**ä¼˜ç‚¹**:
- ç›´è§‚æ˜“ç”¨çš„å›¾å½¢ç•Œé¢
- å®æ—¶è¿›åº¦æ˜¾ç¤º
- è¯¦ç»†çš„é…ç½®é€‰é¡¹
- ç»“æœå¯è§†åŒ–å±•ç¤º

**è¯¦ç»†ä½¿ç”¨è¯´æ˜**: è¯·å‚è€ƒ [Webç•Œé¢ä½¿ç”¨æŒ‡å—](web-interface-guide.md)

#### ğŸ’» å‘½ä»¤è¡Œç•Œé¢ (é€‚åˆå¼€å‘è€…)
```bash
# ä¸­æ–‡ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆæ¨èï¼‰
python examples/dashscope/demo_dashscope_chinese.py

# å®Œæ•´åŠŸèƒ½ç‰ˆæœ¬
python examples/dashscope/demo_dashscope.py

# ç®€åŒ–æµ‹è¯•ç‰ˆæœ¬
python examples/dashscope/demo_dashscope_simple.py
```

**ä¼˜ç‚¹**:
- å¿«é€Ÿæ‰§è¡Œ
- æ˜“äºè‡ªåŠ¨åŒ–
- é€‚åˆæ‰¹é‡å¤„ç†

## ğŸ“Š åˆ†æå†…å®¹è¯¦è§£

### æŠ€æœ¯é¢åˆ†æ
- **ä»·æ ¼è¶‹åŠ¿**: çŸ­æœŸã€ä¸­æœŸã€é•¿æœŸè¶‹åŠ¿åˆ¤æ–­
- **æŠ€æœ¯æŒ‡æ ‡**: MAã€MACDã€RSIã€å¸ƒæ—å¸¦ç­‰
- **æ”¯æ’‘é˜»åŠ›**: å…³é”®ä»·ä½å’Œäº¤æ˜“åŒºé—´
- **æˆäº¤é‡**: é‡ä»·å…³ç³»åˆ†æ

### åŸºæœ¬é¢åˆ†æ
- **è´¢åŠ¡çŠ¶å†µ**: è¥æ”¶ã€åˆ©æ¶¦ã€ç°é‡‘æµåˆ†æ
- **ä¸šåŠ¡ç»“æ„**: å„ä¸šåŠ¡æ¿å—è¡¨ç°
- **å¸‚åœºåœ°ä½**: ç«äº‰ä¼˜åŠ¿å’Œå¸‚åœºä»½é¢
- **å¢é•¿å‰æ™¯**: æœªæ¥å‘å±•æœºä¼š

### å¸‚åœºæƒ…ç»ªåˆ†æ
- **æŠ•èµ„è€…æƒ…ç»ª**: å¸‚åœºå‚ä¸è€…æ€åº¦
- **åˆ†æå¸ˆè¯„çº§**: ä¸“ä¸šæœºæ„è§‚ç‚¹
- **æœºæ„æŒä»“**: å¤§èµ„é‡‘åŠ¨å‘
- **çƒ­ç‚¹å…³æ³¨**: å¸‚åœºç„¦ç‚¹è¯é¢˜

### é£é™©è¯„ä¼°
- **å®è§‚é£é™©**: ç»æµç¯å¢ƒå½±å“
- **è¡Œä¸šé£é™©**: ç«äº‰å’Œå‘¨æœŸæ€§é£é™©
- **å…¬å¸é£é™©**: ç‰¹å®šç»è¥é£é™©
- **ç›‘ç®¡é£é™©**: æ”¿ç­–å˜åŒ–å½±å“

### æŠ•èµ„å»ºè®®
- **è¯„çº§å»ºè®®**: ä¹°å…¥/æŒæœ‰/å–å‡º
- **ç›®æ ‡ä»·ä½**: çŸ­æœŸå’Œé•¿æœŸç›®æ ‡
- **æ—¶é—´æ¡†æ¶**: æŠ•èµ„å‘¨æœŸå»ºè®®
- **é£é™©æ§åˆ¶**: æ­¢æŸå’Œä»“ä½ç®¡ç†

## ğŸ› ï¸ è‡ªå®šä¹‰åˆ†æ

### ä¿®æ”¹åˆ†æå‚æ•°

æ‚¨å¯ä»¥é€šè¿‡ä¿®æ”¹ç¤ºä¾‹ç¨‹åºæ¥è‡ªå®šä¹‰åˆ†æï¼š

```python
# åœ¨ demo_dashscope_chinese.py ä¸­ä¿®æ”¹
STOCK_SYMBOL = "TSLA"  # æ”¹ä¸ºæ‚¨æƒ³åˆ†æçš„è‚¡ç¥¨
ANALYSIS_DATE = "2024-06-26"  # ä¿®æ”¹åˆ†ææ—¥æœŸ
```

### æ”¯æŒçš„è‚¡ç¥¨ä»£ç 

- **ç¾è‚¡**: AAPL, TSLA, MSFT, GOOGL, AMZN, NVDA ç­‰
- **æŒ‡æ•°**: SPY, QQQ, DIA ç­‰ETF
- **å…¶ä»–**: å¤§éƒ¨åˆ†åœ¨ç¾å›½äº¤æ˜“æ‰€ä¸Šå¸‚çš„è‚¡ç¥¨

## ğŸ¯ ä½¿ç”¨æŠ€å·§

### 1. é€‰æ‹©åˆé€‚çš„æ¨¡å‹

```python
# åœ¨é…ç½®ä¸­é€‰æ‹©ä¸åŒçš„æ¨¡å‹
"deep_think_llm": "qwen-max",     # æœ€é«˜è´¨é‡ï¼Œé€‚åˆæ·±åº¦åˆ†æ
"quick_think_llm": "qwen-plus",   # å¹³è¡¡æ€§èƒ½ï¼Œæ—¥å¸¸ä½¿ç”¨
# "qwen-turbo" é€‚åˆå¿«é€ŸæŸ¥è¯¢
```

### 2. åˆ†æä¸åŒæ—¶é—´æ®µ

```python
# ä¿®æ”¹åˆ†ææ—¥æœŸæ¥åˆ†æå†å²è¡¨ç°
ANALYSIS_DATE = "2024-01-01"  # å¹´åˆåˆ†æ
ANALYSIS_DATE = "2024-06-01"  # åŠå¹´åº¦åˆ†æ
```

### 3. å…³æ³¨ç‰¹å®šæ–¹é¢

æ‚¨å¯ä»¥åœ¨æç¤ºè¯ä¸­å¼ºè°ƒç‰¹å®šåˆ†ææ–¹å‘ï¼š
- æŠ€æœ¯é¢åˆ†æ
- åŸºæœ¬é¢åˆ†æ
- é£é™©è¯„ä¼°
- è¡Œä¸šæ¯”è¾ƒ

## âš ï¸ é‡è¦æé†’

### æŠ•èµ„é£é™©æç¤º

1. **ä»…ä¾›å‚è€ƒ**: åˆ†æç»“æœä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®
2. **é£é™©è‡ªæ‹…**: æŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…
3. **å¤šæ–¹éªŒè¯**: å»ºè®®ç»“åˆå…¶ä»–ä¿¡æ¯æºè¿›è¡ŒéªŒè¯
4. **ä¸“ä¸šå’¨è¯¢**: é‡å¤§æŠ•èµ„å†³ç­–å»ºè®®å’¨è¯¢ä¸“ä¸šè´¢åŠ¡é¡¾é—®

### æ•°æ®å‡†ç¡®æ€§

1. **å®æ—¶æ€§**: æ•°æ®å¯èƒ½å­˜åœ¨å»¶è¿Ÿï¼Œè¯·ä»¥å®é™…å¸‚åœºæ•°æ®ä¸ºå‡†
2. **å®Œæ•´æ€§**: AIåˆ†æå¯èƒ½é—æ¼æŸäº›é‡è¦ä¿¡æ¯
3. **å‡†ç¡®æ€§**: é¢„æµ‹å’Œå»ºè®®å­˜åœ¨ä¸ç¡®å®šæ€§

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **APIå¯†é’¥é”™è¯¯**: æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„å¯†é’¥é…ç½®
2. **ç½‘ç»œè¿æ¥**: ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸
3. **æ¨¡å‹å“åº”æ…¢**: å¯ä»¥å°è¯•ä½¿ç”¨qwen-turboæ¨¡å‹

### è·å–å¸®åŠ©

```bash
# æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯
python -m cli.main help

# æŸ¥çœ‹ç¤ºä¾‹ç¨‹åº
python -m cli.main examples
```

## ğŸ“ˆ é«˜çº§ç”¨æ³•

### æ‰¹é‡åˆ†æ

æ‚¨å¯ä»¥ä¿®æ”¹ç¨‹åºæ¥åˆ†æå¤šåªè‚¡ç¥¨ï¼š

```python
stocks = ["AAPL", "MSFT", "GOOGL", "TSLA"]
for stock in stocks:
    # è¿è¡Œåˆ†æé€»è¾‘
    analyze_stock(stock)
```

### å®šæœŸåˆ†æ

è®¾ç½®å®šæ—¶ä»»åŠ¡æ¥å®šæœŸç”Ÿæˆåˆ†ææŠ¥å‘Šï¼š

```bash
# ä½¿ç”¨cronæˆ–Windowsä»»åŠ¡è®¡åˆ’ç¨‹åº
# æ¯æ—¥è¿è¡Œåˆ†æ
0 9 * * * python examples/dashscope/demo_dashscope_chinese.py
```

## ğŸ“ å­¦ä¹ èµ„æº

### æ¨èé˜…è¯»

1. **æŠ€æœ¯åˆ†æ**: å­¦ä¹ æŠ€æœ¯æŒ‡æ ‡çš„å«ä¹‰å’Œåº”ç”¨
2. **åŸºæœ¬é¢åˆ†æ**: äº†è§£è´¢åŠ¡æŠ¥è¡¨åˆ†ææ–¹æ³•
3. **é£é™©ç®¡ç†**: æŒæ¡æŠ•èµ„é£é™©æ§åˆ¶æŠ€å·§
4. **å¸‚åœºå¿ƒç†**: ç†è§£å¸‚åœºæƒ…ç»ªå’Œè¡Œä¸ºé‡‘èå­¦

### å®è·µå»ºè®®

1. **æ¨¡æ‹Ÿäº¤æ˜“**: å…ˆç”¨æ¨¡æ‹Ÿè´¦æˆ·ç»ƒä¹ 
2. **å°é¢è¯•éªŒ**: ä»å°é¢æŠ•èµ„å¼€å§‹
3. **æŒç»­å­¦ä¹ **: ä¸æ–­æå‡æŠ•èµ„çŸ¥è¯†å’ŒæŠ€èƒ½
4. **è®°å½•æ€»ç»“**: è®°å½•æŠ•èµ„å†³ç­–å’Œç»“æœï¼Œæ€»ç»“ç»éªŒ

---

*å…è´£å£°æ˜: æœ¬å·¥å…·ä»…ç”¨äºæ•™è‚²å’Œç ”ç©¶ç›®çš„ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…ã€‚*


<!-- docs/usage/web-interface-guide.md -->

# TradingAgents-CN Webç•Œé¢ä½¿ç”¨æŒ‡å— (v0.1.4)

## ğŸŒ æ¦‚è¿°

TradingAgents-CN æä¾›äº†ç›´è§‚æ˜“ç”¨çš„Webç•Œé¢ï¼Œè®©æ‚¨å¯ä»¥é€šè¿‡æµè§ˆå™¨è½»æ¾è¿›è¡Œè‚¡ç¥¨æŠ•èµ„åˆ†æã€‚v0.1.4ç‰ˆæœ¬æ–°å¢äº†é…ç½®ç®¡ç†ã€Tokenç»Ÿè®¡ç­‰åŠŸèƒ½ï¼Œæœ¬æŒ‡å—å°†è¯¦ç»†ä»‹ç»Webç•Œé¢çš„å„é¡¹åŠŸèƒ½å’Œé…ç½®é€‰é¡¹ã€‚

## âœ¨ v0.1.4 æ–°å¢åŠŸèƒ½

- ğŸ›ï¸ **é…ç½®ç®¡ç†**: APIå¯†é’¥ç®¡ç†ã€æ¨¡å‹é€‰æ‹©ã€ç³»ç»Ÿé…ç½®
- ğŸ’° **Tokenç»Ÿè®¡**: å®æ—¶Tokenä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬è¿½è¸ª
- ğŸ’¾ **ç¼“å­˜ç®¡ç†**: æ•°æ®ç¼“å­˜çŠ¶æ€ç›‘æ§å’Œç®¡ç†
- ğŸ‡¨ğŸ‡³ **Aè‚¡æ”¯æŒ**: å®Œæ•´çš„Aè‚¡è‚¡ç¥¨åˆ†æåŠŸèƒ½

## ğŸš€ å¯åŠ¨Webç•Œé¢

### 1. å¯åŠ¨å‘½ä»¤
```bash
# å¯åŠ¨Webç•Œé¢
python -m streamlit run web/app.py

# æˆ–è€…ä½¿ç”¨ç®€åŒ–å‘½ä»¤
streamlit run web/app.py
```

### 2. è®¿é—®åœ°å€
å¯åŠ¨åï¼Œåœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼š`http://localhost:8501`

## ğŸ“Š ç•Œé¢åŠŸèƒ½è¯¦è§£

### åˆ†æé…ç½®åŒºåŸŸ

#### åŸºæœ¬è®¾ç½®
- **è‚¡ç¥¨ä»£ç **: è¾“å…¥è¦åˆ†æçš„è‚¡ç¥¨ä»£ç 
  - ğŸ‡ºğŸ‡¸ **ç¾è‚¡**: AAPL, TSLA, NVDA, MSFT
  - ğŸ‡¨ğŸ‡³ **Aè‚¡**: 000001, 600036, 000002, 600519
- **åˆ†ææ—¥æœŸ**: é€‰æ‹©åˆ†æçš„åŸºå‡†æ—¥æœŸ
- **ç ”ç©¶æ·±åº¦**: é€‰æ‹©åˆ†æçš„è¯¦ç»†ç¨‹åº¦ï¼ˆ1-5çº§ï¼‰

#### ğŸ¯ ç ”ç©¶æ·±åº¦è¯¦ç»†è¯´æ˜

ç ”ç©¶æ·±åº¦æ˜¯æ§åˆ¶åˆ†æè´¨é‡ã€é€Ÿåº¦å’Œæˆæœ¬çš„æ ¸å¿ƒå‚æ•°ã€‚ä¸åŒçº§åˆ«çš„å…·ä½“é…ç½®å¦‚ä¸‹ï¼š

##### ğŸš€ 1çº§ - å¿«é€Ÿåˆ†æ (2-4åˆ†é’Ÿ)
**é€‚ç”¨åœºæ™¯**: æ—¥å¸¸å¿«é€Ÿå†³ç­–ã€å¸‚åœºæ¦‚è§ˆ

**æŠ€æœ¯é…ç½®**:
- **è¾©è®ºè½®æ¬¡**: 1è½® (æœ€å°‘)
- **AIæ¨¡å‹**: qwen-turbo + qwen-plus (æœ€å¿«)
- **è®°å¿†åŠŸèƒ½**: âŒ ç¦ç”¨ (åŠ é€Ÿ)
- **åœ¨çº¿å·¥å…·**: âŒ ç¦ç”¨ (ä½¿ç”¨ç¼“å­˜æ•°æ®)

**ç‰¹ç‚¹**:
- âœ… é€Ÿåº¦æœ€å¿«ã€æˆæœ¬æœ€ä½
- âœ… é€‚åˆé¢‘ç¹æŸ¥è¯¢
- âŒ åˆ†ææ·±åº¦æœ‰é™
- âŒ å¯èƒ½é”™è¿‡ç»†èŠ‚ä¿¡æ¯

##### ğŸ“ˆ 2çº§ - åŸºç¡€åˆ†æ (4-6åˆ†é’Ÿ)
**é€‚ç”¨åœºæ™¯**: å¸¸è§„æŠ•èµ„å†³ç­–ã€åŸºç¡€ç ”ç©¶

**æŠ€æœ¯é…ç½®**:
- **è¾©è®ºè½®æ¬¡**: 1è½®
- **AIæ¨¡å‹**: qwen-plus + qwen-plus (å¹³è¡¡)
- **è®°å¿†åŠŸèƒ½**: âœ… å¯ç”¨
- **åœ¨çº¿å·¥å…·**: âœ… å¯ç”¨ (è·å–æœ€æ–°æ•°æ®)

**ç‰¹ç‚¹**:
- âœ… é€Ÿåº¦è¾ƒå¿«ã€åŒ…å«æœ€æ–°æ•°æ®
- âœ… æˆæœ¬å¯æ§
- âŒ è¾©è®ºæ·±åº¦æœ‰é™

##### ğŸ¯ 3çº§ - æ ‡å‡†åˆ†æ (6-10åˆ†é’Ÿ) **[é»˜è®¤æ¨è]**
**é€‚ç”¨åœºæ™¯**: é‡è¦æŠ•èµ„å†³ç­–ã€æ ‡å‡†ç ”ç©¶æµç¨‹

**æŠ€æœ¯é…ç½®**:
- **è¾©è®ºè½®æ¬¡**: 1è½® (ç ”ç©¶å‘˜) + 2è½® (é£é™©è¯„ä¼°)
- **AIæ¨¡å‹**: qwen-plus + qwen-max (è´¨é‡ä¼˜å…ˆ)
- **è®°å¿†åŠŸèƒ½**: âœ… å¯ç”¨
- **åœ¨çº¿å·¥å…·**: âœ… å¯ç”¨

**ç‰¹ç‚¹**:
- âœ… å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡
- âœ… é£é™©è¯„ä¼°æ›´æ·±å…¥
- âœ… é€‚åˆå¤§å¤šæ•°åœºæ™¯
- âŒ è€—æ—¶é€‚ä¸­

##### ğŸ”¬ 4çº§ - æ·±åº¦åˆ†æ (10-15åˆ†é’Ÿ)
**é€‚ç”¨åœºæ™¯**: é‡å¤§æŠ•èµ„å†³ç­–ã€è¯¦ç»†ç ”ç©¶æŠ¥å‘Š

**æŠ€æœ¯é…ç½®**:
- **è¾©è®ºè½®æ¬¡**: 2è½® (ç ”ç©¶å‘˜) + 2è½® (é£é™©è¯„ä¼°)
- **AIæ¨¡å‹**: qwen-plus + qwen-max (é«˜è´¨é‡)
- **è®°å¿†åŠŸèƒ½**: âœ… å¯ç”¨
- **åœ¨çº¿å·¥å…·**: âœ… å¯ç”¨

**ç‰¹ç‚¹**:
- âœ… åˆ†ææ·±åº¦é«˜
- âœ… å¤šè½®è¾©è®ºç¡®ä¿å…¨é¢æ€§
- âœ… é€‚åˆé‡è¦å†³ç­–
- âŒ è€—æ—¶è¾ƒé•¿ã€æˆæœ¬è¾ƒé«˜

##### ğŸ† 5çº§ - å…¨é¢åˆ†æ (15-25åˆ†é’Ÿ)
**é€‚ç”¨åœºæ™¯**: æœ€é‡è¦çš„æŠ•èµ„å†³ç­–ã€å®Œæ•´ç ”ç©¶æŠ¥å‘Š

**æŠ€æœ¯é…ç½®**:
- **è¾©è®ºè½®æ¬¡**: 3è½® (ç ”ç©¶å‘˜) + 3è½® (é£é™©è¯„ä¼°)
- **AIæ¨¡å‹**: qwen-max + qwen-max (æœ€é«˜è´¨é‡)
- **è®°å¿†åŠŸèƒ½**: âœ… å¯ç”¨
- **åœ¨çº¿å·¥å…·**: âœ… å¯ç”¨

**ç‰¹ç‚¹**:
- âœ… æœ€å…¨é¢çš„åˆ†æ
- âœ… æœ€é«˜è´¨é‡çš„æ¨ç†
- âœ… æœ€å¯é çš„ç»“æœ
- âŒ è€—æ—¶æœ€é•¿ã€æˆæœ¬æœ€é«˜

#### ğŸ“‹ ç ”ç©¶æ·±åº¦é€‰æ‹©å»ºè®®

| ä½¿ç”¨åœºæ™¯ | æ¨èçº§åˆ« | é¢„æœŸè€—æ—¶ | æˆæœ¬ | é€‚ç”¨æƒ…å†µ |
|----------|----------|----------|------|----------|
| æ—¥å¸¸å¸‚åœºç›‘æ§ | 1-2çº§ | 2-6åˆ†é’Ÿ | ä½ | å¿«é€Ÿè·å–å¸‚åœºæ¦‚å†µ |
| å¸¸è§„æŠ•èµ„å†³ç­– | 2-3çº§ | 4-10åˆ†é’Ÿ | ä¸­ä½ | å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡ |
| é‡è¦æŠ•èµ„å†³ç­– | 3-4çº§ | 6-15åˆ†é’Ÿ | ä¸­é«˜ | ç¡®ä¿åˆ†æè´¨é‡ |
| é‡å¤§èµ„é‡‘æŠ•å…¥ | 4-5çº§ | 10-25åˆ†é’Ÿ | é«˜ | æœ€å…¨é¢çš„é£é™©è¯„ä¼° |
| ç ”ç©¶æŠ¥å‘Šæ’°å†™ | 4-5çº§ | 10-25åˆ†é’Ÿ | é«˜ | éœ€è¦è¯¦ç»†çš„åˆ†æå†…å®¹ |

### åˆ†æå¸ˆå›¢é˜Ÿé€‰æ‹©

#### å¯é€‰åˆ†æå¸ˆç±»å‹
- **ğŸ“Š å¸‚åœºæŠ€æœ¯åˆ†æå¸ˆ**: æŠ€æœ¯æŒ‡æ ‡ã€ä»·æ ¼è¶‹åŠ¿åˆ†æ
- **ğŸ’° åŸºæœ¬é¢åˆ†æå¸ˆ**: è´¢åŠ¡æ•°æ®ã€å…¬å¸åŸºæœ¬é¢åˆ†æ
- **ğŸ“° æ–°é—»åˆ†æå¸ˆ**: æ–°é—»äº‹ä»¶ã€å¸‚åœºåŠ¨æ€åˆ†æ
- **ğŸ’­ ç¤¾äº¤åª’ä½“åˆ†æå¸ˆ**: å¸‚åœºæƒ…ç»ªã€æŠ•èµ„è€…æ€åº¦åˆ†æ

#### åˆ†æå¸ˆç»„åˆå»ºè®®
- **æœ€å¿«ç»„åˆ**: åªé€‰æ‹©"å¸‚åœºæŠ€æœ¯åˆ†æå¸ˆ" (æœ€å¿«)
- **å¹³è¡¡ç»„åˆ**: "å¸‚åœºæŠ€æœ¯" + "åŸºæœ¬é¢åˆ†æå¸ˆ" (æ¨è)
- **å…¨é¢ç»„åˆ**: é€‰æ‹©æ‰€æœ‰åˆ†æå¸ˆ (æœ€å…¨é¢ä½†æœ€æ…¢)

### é«˜çº§é€‰é¡¹

#### æ¨¡å‹é…ç½®
- **LLMæä¾›å•†**: é€‰æ‹©AIæ¨¡å‹æä¾›å•† (é˜¿é‡Œç™¾ç‚¼/Google AI)
- **å…·ä½“æ¨¡å‹**: é€‰æ‹©ä½¿ç”¨çš„å…·ä½“AIæ¨¡å‹

#### åˆ†æé€‰é¡¹
- **åŒ…å«æƒ…ç»ªåˆ†æ**: æ˜¯å¦åŒ…å«å¸‚åœºæƒ…ç»ªåˆ†æ
- **åŒ…å«é£é™©è¯„ä¼°**: æ˜¯å¦åŒ…å«è¯¦ç»†é£é™©è¯„ä¼°
- **è‡ªå®šä¹‰æç¤º**: æ·»åŠ ç‰¹å®šçš„åˆ†æè¦æ±‚

## ğŸ“ˆ åˆ†æç»“æœè§£è¯»

### æ ¸å¿ƒå†³ç­–æŒ‡æ ‡
- **æŠ•èµ„å»ºè®®**: ä¹°å…¥/æŒæœ‰/å–å‡º
- **ç›®æ ‡ä»·ä½**: AIé¢„æµ‹çš„åˆç†ä»·æ ¼ç›®æ ‡
- **ç½®ä¿¡åº¦**: å¯¹å†³ç­–çš„ä¿¡å¿ƒç¨‹åº¦ (0-1)
- **é£é™©è¯„åˆ†**: æŠ•èµ„é£é™©ç­‰çº§ (0-1)

### è¯¦ç»†åˆ†ææŠ¥å‘Š
- **ğŸ§  AIåˆ†ææ¨ç†**: å†³ç­–çš„è¯¦ç»†é€»è¾‘
- **ğŸ“Š æŠ€æœ¯åˆ†æ**: æŠ€æœ¯æŒ‡æ ‡å’Œè¶‹åŠ¿åˆ†æ
- **ğŸ’° åŸºæœ¬é¢åˆ†æ**: è´¢åŠ¡çŠ¶å†µå’Œä¸šåŠ¡åˆ†æ
- **ğŸ“° æ–°é—»å½±å“**: ç›¸å…³æ–°é—»äº‹ä»¶åˆ†æ
- **ğŸ’­ å¸‚åœºæƒ…ç»ª**: æŠ•èµ„è€…æƒ…ç»ªå’Œæ€åº¦
- **âš–ï¸ é£é™©è¯„ä¼°**: è¯¦ç»†çš„é£é™©åˆ†æ

## ğŸ’¡ ä½¿ç”¨æŠ€å·§

### é€Ÿåº¦ä¼˜åŒ–
1. **å¿«é€ŸæŸ¥çœ‹**: ä½¿ç”¨1-2çº§ç ”ç©¶æ·±åº¦ + æœ€å°‘åˆ†æå¸ˆ
2. **å¹³è¡¡åˆ†æ**: ä½¿ç”¨2-3çº§ç ”ç©¶æ·±åº¦ + æ ¸å¿ƒåˆ†æå¸ˆ
3. **æ·±åº¦ç ”ç©¶**: ä½¿ç”¨4-5çº§ç ”ç©¶æ·±åº¦ + å…¨éƒ¨åˆ†æå¸ˆ

### æˆæœ¬æ§åˆ¶
1. **æ—¥å¸¸ç›‘æ§**: ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼Œé™ä½APIè°ƒç”¨æˆæœ¬
2. **é‡è¦å†³ç­–**: ä½¿ç”¨æ ‡å‡†æ¨¡å¼ï¼Œç¡®ä¿åˆ†æè´¨é‡
3. **å…³é”®æŠ•èµ„**: ä½¿ç”¨æ·±åº¦æ¨¡å¼ï¼Œè·å¾—æœ€å¯é ç»“æœ

### ç»“æœéªŒè¯
1. **å¤šæ¬¡åˆ†æ**: å¯¹é‡è¦è‚¡ç¥¨è¿›è¡Œå¤šæ¬¡åˆ†æå¯¹æ¯”
2. **ä¸åŒæ·±åº¦**: ä½¿ç”¨ä¸åŒç ”ç©¶æ·±åº¦éªŒè¯ä¸€è‡´æ€§
3. **å†å²å›æµ‹**: æŸ¥çœ‹å†å²åˆ†æçš„å‡†ç¡®æ€§

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜
1. **åˆ†ææ—¶é—´è¿‡é•¿**: é™ä½ç ”ç©¶æ·±åº¦æˆ–å‡å°‘åˆ†æå¸ˆæ•°é‡
2. **ç›®æ ‡ä»·ä½æ˜¾ç¤ºN/A**: æ£€æŸ¥AIæ¨¡å‹é…ç½®å’ŒAPIè¿æ¥
3. **åˆ†æå¤±è´¥**: æ£€æŸ¥APIå¯†é’¥é…ç½®å’Œç½‘ç»œè¿æ¥

### æ€§èƒ½ä¼˜åŒ–
1. **ä½¿ç”¨ç¼“å­˜**: å¯ç”¨æ•°æ®ç¼“å­˜åŠŸèƒ½
2. **é€‰æ‹©åˆé€‚æ¨¡å‹**: æ ¹æ®éœ€æ±‚é€‰æ‹©é€Ÿåº¦å’Œè´¨é‡å¹³è¡¡çš„æ¨¡å‹
3. **åˆç†é…ç½®**: æ ¹æ®ä½¿ç”¨åœºæ™¯é€‰æ‹©åˆé€‚çš„ç ”ç©¶æ·±åº¦

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœæ‚¨åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æ§åˆ¶å°é”™è¯¯ä¿¡æ¯
2. æ£€æŸ¥APIå¯†é’¥é…ç½®
3. å‚è€ƒFAQæ–‡æ¡£
4. æäº¤Issueåˆ°GitHubä»“åº“


